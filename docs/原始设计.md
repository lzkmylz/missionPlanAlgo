# 卫星星座任务规划算法研究平台 - 架构设计文档

**版本**: 1.0
**日期**: 2026-02-19
**参考**: SpaceSim (AerospaceHIT) 模块化设计思想

---

## 1. 项目概述

本项目面向大规模遥感卫星星座任务规划算法研究，支持：
- **50颗异构卫星**：光学1型、光学2型、SAR-1型、SAR-2型
- **两类目标**：点群目标、大区域目标
- **多成像模式**：聚束、滑动聚束、条带（SAR）；推扫、框幅（光学）
- **数传站资源**：多地理位置、多天线、单天线单任务约束
- **算法对比**：贪心、EDD、SPT、GA、SA、ACO、PSO、禁忌搜索 + 自定义新算法

---

## 2. 整体架构

参考SpaceSim的八大模块设计，本项目采用分层模块化架构：

```
mission-planning-research/
├── core/                    # 核心层（装备建模+轨道）
│   ├── models/             # 实体模型定义
│   │   ├── satellite.py    # 卫星（光学1/2型、SAR-1/2型）
│   │   ├── target.py       # 目标（点群、大区域）
│   │   ├── ground_station.py # 地面站（多天线）
│   │   └── mission.py      # 任务定义
│   ├── orbit/              # 轨道模块
│   │   ├── propagator/     # 轨道传播器
│   │   │   ├── sgp4_propagator.py
│   │   │   ├── hpop_stk.py       # STK HPOP接口
│   │   │   └── orekit_propagator.py # Orekit实现
│   │   └── visibility/     # 可见性分析
│   │       ├── base.py
│   │       ├── stk_visibility.py
│   │       └── orekit_visibility.py
│   └── resources/          # 资源管理
│       ├── satellite_pool.py
│       └── ground_station_pool.py
│
├── payload/                 # 载荷模块
│   ├── base.py
│   ├── optical_imager.py   # 光学成像器
│   └── sar_imager.py       # SAR成像器
│       ├── spotlight.py
│       ├── sliding_spotlight.py
│       └── stripmap.py
│
├── scheduler/              # 调度模块（研究核心）
│   ├── base_scheduler.py   # 调度器基类
│   ├── greedy/             # 启发式算法
│   │   ├── greedy_scheduler.py
│   │   ├── edd_scheduler.py
│   │   └── spt_scheduler.py
│   ├── metaheuristic/      # 元启发式算法
│   │   ├── ga_scheduler.py
│   │   ├── sa_scheduler.py
│   │   ├── aco_scheduler.py
│   │   ├── pso_scheduler.py
│   │   └── tabu_scheduler.py
│   └── custom/             # 新算法预留位置
│
├── simulator/              # 仿真引擎
│   ├── scenario.py
│   ├── event_engine.py
│   └── state_tracker.py
│
├── evaluation/             # 评估模块
│   ├── metrics.py          # 性能指标计算
│   └── analyzer.py         # 结果分析
│
├── experiments/            # 实验管理
│   ├── benchmark/          # 基准测试场景
│   ├── runner.py
│   └── report_generator.py
│
├── visualization/          # 可视化
│   ├── gantt_chart.py
│   ├── ground_track.py
│   └── coverage_map.py
│
└── utils/                  # 工具模块
    ├── config_loader.py
    ├── logger.py
    └── data_export.py
```

---

## 3. 核心设计特点

### 3.1 即插即用算法接口

所有调度算法必须继承 `BaseScheduler` 基类：

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import List, Dict, Any

@dataclass
class ScheduleResult:
    """调度结果"""
    scheduled_tasks: List[Dict]      # 被成功执行的任务
    unscheduled_tasks: List[str]     # 未调度的任务ID
    makespan: float                  # 总完成时间
    computation_time: float          # 算法求解用时
    iterations: int                  # 迭代次数
    convergence_curve: List[float]   # 收敛曲线

class BaseScheduler(ABC):
    """调度器基类 - 即插即用接口"""

    def __init__(self, name: str, config: Dict[str, Any] = None):
        self.name = name
        self.config = config or {}
        self.satellite_pool = None
        self.ground_station_pool = None
        self.mission = None

    def initialize(self, mission, satellite_pool, ground_station_pool):
        """初始化调度器"""
        self.mission = mission
        self.satellite_pool = satellite_pool
        self.ground_station_pool = ground_station_pool

    @abstractmethod
    def schedule(self) -> ScheduleResult:
        """执行调度"""
        pass

    @abstractmethod
    def get_parameters(self) -> Dict[str, Any]:
        """返回算法可调参数（用于敏感性分析）"""
        pass

    def validate_solution(self, result: ScheduleResult) -> bool:
        """验证解的可行性"""
        pass
```

### 3.2 双后端可见性计算

自动检测STK并切换至Orekit：

```python
class VisibilityCalculatorFactory:
    """可见性计算工厂"""

    _backends = {
        'stk': 'STKVisibilityCalculator',
        'orekit': 'OrekitVisibilityCalculator'
    }

    @classmethod
    def create(cls, preferred: str = 'auto', config: Dict = None):
        """
        创建可见性计算器
        auto模式：优先STK，fallback到Orekit
        """
        if preferred == 'auto':
            if cls._check_stk_available():
                return STKVisibilityCalculator(config)
            else:
                return OrekitVisibilityCalculator(config)
        # ...
```

**STK实现**（高精度）：
- 使用HPOP传播器
- 考虑大气阻力、太阳光压、三体引力
- 通过COM接口与STK交互

**Orekit实现**（自主可控）：
- 开源Java库Python绑定
- 支持数值/解析传播
- 自定义可见性几何计算

### 3.3 异构卫星建模

```python
from enum import Enum
from dataclasses import dataclass

class SatelliteType(Enum):
    OPTICAL_1 = "optical_1"
    OPTICAL_2 = "optical_2"
    SAR_1 = "sar_1"
    SAR_2 = "sar_2"

class ImagingMode(Enum):
    # SAR-1型特有
    SPOTLIGHT = "spotlight"
    SLIDING_SPOTLIGHT = "sliding_spotlight"
    STRIPMAP = "stripmap"
    # 光学型
    PUSH_BROOM = "push_broom"
    FRAME = "frame"

@dataclass
class SatelliteCapabilities:
    imaging_modes: List[ImagingMode]
    max_off_nadir: float          # 最大侧摆角
    agility: Dict                 # 姿态机动能力
    storage_capacity: float       # 存储容量(GB)
    power_capacity: float         # 电量(Wh)
    data_rate: float              # 数传速率(Mbps)
```

### 3.4 场景配置（YAML驱动）

```yaml
scenario:
  name: "中规模点群+区域观测场景"
  duration:
    start: "2024-01-01T00:00:00Z"
    end: "2024-01-02T00:00:00Z"

  satellites:
    - id: "OPT-01"
      type: "optical_1"
      orbit:
        type: "SSO"
        altitude: 500000
        inclination: 97.4
      capabilities:
        imaging_modes: ["push_broom"]
        max_off_nadir: 30.0
        storage_capacity: 500
        power_capacity: 2000

    - id: "SAR-01"
      type: "sar_1"
      capabilities:
        imaging_modes: ["spotlight", "sliding_spotlight", "stripmap"]

  targets:
    point_group:
      count: 300
      distribution: "clustered"
      regions:
        - name: "华东区域"
          bounds: [118.0, 30.0, 123.0, 35.0]
          density: "high"

    large_area:
      count: 5
      areas:
        - id: "AREA-01"
          vertices: [...]
          resolution_required: 10.0
          priority: 1

  ground_stations:
    - id: "GS-BEIJING"
      location: [116.4, 39.9, 0.0]
      antennas:
        - id: "ANT-01"
          elevation_min: 5.0
          data_rate: 300.0
```

---

## 4. 实验执行流程

### 4.1 横向对比实验

```python
class ExperimentRunner:
    """实验执行器"""

    def run_benchmark(self,
                      algorithms: List[BaseScheduler],
                      scenarios: List[str],
                      repetitions: int = 10) -> pd.DataFrame:
        """
        执行基准测试

        Args:
            algorithms: 待对比算法列表
            scenarios: 场景配置文件列表
            repetitions: 每种组合重复次数
        """
        all_results = []

        for scenario_file in scenarios:
            scenario = Scenario.load(scenario_file)

            for algorithm in algorithms:
                for run_id in range(repetitions):
                    set_seed(run_id)

                    algo_instance = algorithm()
                    algo_instance.initialize(...)

                    start_time = time.time()
                    result = algo_instance.schedule()
                    result.computation_time = time.time() - start_time

                    record = {
                        'scenario': scenario.name,
                        'algorithm': algorithm.__name__,
                        'run_id': run_id,
                        'demand_satisfaction_rate': ...,
                        'makespan': result.makespan,
                        'avg_revisit_time': ...,
                        'data_delivery_time': ...,
                        'computation_time': result.computation_time,
                        'solution_quality': ...,
                    }
                    all_results.append(record)

        return pd.DataFrame(all_results)
```

### 4.2 参数敏感性分析

```python
def run_sensitivity_analysis(self,
                              algorithm: BaseScheduler,
                              scenario: str,
                              parameters: Dict[str, List]) -> pd.DataFrame:
    """
    参数敏感性分析（针对新算法）

    Example:
        parameters = {
            'population_size': [50, 100, 200],
            'mutation_rate': [0.01, 0.05, 0.1],
            'crossover_rate': [0.6, 0.8, 0.9]
        }
    """
    from itertools import product

    param_names = list(parameters.keys())
    param_values = list(parameters.values())

    results = []
    for values in product(*param_values):
        param_set = dict(zip(param_names, values))
        algo = algorithm(**param_set)
        result = self._run_single(algo, scenario)
        results.append({**param_set, ...})

    return pd.DataFrame(results)
```

---

## 5. 性能指标体系

| 指标名称 | 符号 | 计算方式 | 用途 |
|---------|------|---------|------|
| 需求满足率 | DSR | 成功调度任务数/总任务数 | 衡量算法完成任务能力 |
| 全部完成用时 | Makespan | 最后一个任务完成时间 | 衡量整体效率 |
| 平均观测间隔 | ARI | 同一目标多次观测的平均间隔 | 衡量重访性能 |
| 数据回传用时 | DDT | 观测完成到数据下传完成时间 | 衡量时效性 |
| 算法求解用时 | CT | 算法运行时间 | 衡量计算效率 |
| 解质量 | SQ | 与理论下界或最优解的差距 | 衡量解的最优性 |

---

## 6. 可视化输出

### 6.1 调度甘特图
- 横轴：时间
- 纵轴：卫星/地面站
- 颜色：成像（红）、数传（蓝）、姿态调整（黄）

### 6.2 星下点轨迹
- 显示所有卫星轨道覆盖
- 标记观测时刻位置

### 6.3 覆盖热力图
- 显示区域目标的覆盖次数分布

### 6.4 算法对比图
- 箱线图：各算法性能指标分布
- 收敛曲线：元启发式算法迭代过程
- Pareto前沿：多目标优化结果

---

## 7. 与SpaceSim设计对比

| SpaceSim特点 | 本项目实现 |
|-------------|-----------|
| 八大模块 | core/payload/scheduler/simulator/evaluation/experiments/visualization/utils |
| 即插即用扩展 | BaseScheduler抽象基类 |
| 双轨道后端 | STK HPOP + Orekit自动切换 |
| JSON配置驱动 | YAML场景定义 |
| 载荷建模 | 光学/SAR多模式成像器 |
| GPU加速仿真 | 可选Numba/JIT优化 |

---

## 8. 后续开发计划

### Phase 1: 基础框架
- [ ] 核心数据模型（卫星、目标、地面站）
- [ ] 可见性计算接口（Orekit实现优先）
- [ ] 基础调度器框架

### Phase 2: 算法实现
- [ ] 贪心、EDD、SPT实现
- [ ] GA、SA实现
- [ ] ACO、PSO、Tabu实现

### Phase 3: 实验系统
- [ ] 场景生成器
- [ ] 实验运行器
- [ ] 结果分析器

### Phase 4: 新算法研究
- [ ] 改进的元启发式算法
- [ ] 参数敏感性分析
- [ ] 论文实验

---

## 9. 参考文献

1. 魏承, 乔彬, 刘天喜, 等. 航天器系统仿真软件SpaceSim设计与应用[J]. 宇航学报, 2024, 45(11): 1724-1731
2. SpaceSim官方文档: https://spacesim-ori.readthedocs.io/
3. Orekit文档: https://www.orekit.org/
4. STK HPOP技术文档

---

## 10. 数据持久化与存储设计

### 10.1 数据库架构总览

数据库名：`satellite_mission_planning`

```
satellite_mission_planning/
├── 配置层 (5表)
│   ├── satellites              # 卫星基础配置
│   ├── ground_stations         # 地面站配置
│   ├── antennas               # 天线配置
│   ├── targets                # 目标基础配置
│   └── scenarios              # 场景版本管理
│
├── 场景实例层 (3表)
│   ├── scenario_satellites      # 场景-卫星关联
│   ├── scenario_targets         # 场景-目标关联
│   └── scenario_ground_stations # 场景-地面站关联
│
├── 目标分解层 (2表)
│   ├── decomposition_configs    # 分解配置
│   └── sub_targets             # 分解后的子任务
│
├── 实验层 (4表)
│   ├── experiments             # 实验记录
│   ├── experiment_runs         # 单次运行记录
│   ├── algorithm_params        # 算法参数
│   └── convergence_data        # 收敛曲线数据
│
├── 结果层 (3表)
│   ├── schedule_tasks          # 调度任务详情
│   ├── performance_metrics     # 性能指标
│   └── task_sequences          # 任务执行序列
│
└── 状态层 (2表)
    ├── satellite_state_snapshots  # 状态快照
    └── constraint_violations      # 约束违反记录
```

### 10.2 配置层表结构

```sql
-- 卫星基础配置
CREATE TABLE satellites (
    id VARCHAR(32) PRIMARY KEY COMMENT '卫星ID，如 OPT-01, SAR-01',
    name VARCHAR(64) NOT NULL COMMENT '卫星名称',
    sat_type ENUM('optical_1', 'optical_2', 'sar_1', 'sar_2') NOT NULL,
    orbit_type ENUM('SSO', 'LEO', 'MEO', 'GEO') NOT NULL DEFAULT 'SSO',
    altitude INT COMMENT '轨道高度(米)',
    inclination DECIMAL(6,2) COMMENT '轨道倾角(度)',
    orbit_params JSON COMMENT '完整轨道参数JSON',
    max_off_nadir DECIMAL(5,2) COMMENT '最大侧摆角(度)',
    agility JSON COMMENT '姿态机动能力',
    storage_capacity INT COMMENT '存储容量(GB)',
    power_capacity INT COMMENT '电量(Wh)',
    data_rate INT COMMENT '数传速率(Mbps)',
    supported_modes JSON COMMENT '支持的成像模式列表',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_sat_type (sat_type)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='卫星基础配置表';

-- 地面站配置
CREATE TABLE ground_stations (
    id VARCHAR(32) PRIMARY KEY COMMENT '地面站ID',
    name VARCHAR(64) NOT NULL COMMENT '地面站名称',
    longitude DECIMAL(9,6) NOT NULL COMMENT '经度',
    latitude DECIMAL(8,6) NOT NULL COMMENT '纬度',
    altitude DECIMAL(8,2) DEFAULT 0 COMMENT '海拔高度(米)',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_location (latitude, longitude)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='地面站配置表';

-- 天线配置
CREATE TABLE antennas (
    id VARCHAR(32) PRIMARY KEY COMMENT '天线ID',
    ground_station_id VARCHAR(32) NOT NULL COMMENT '所属地面站',
    name VARCHAR(64) NOT NULL COMMENT '天线名称',
    elevation_min DECIMAL(5,2) DEFAULT 5.0 COMMENT '最小仰角(度)',
    elevation_max DECIMAL(5,2) DEFAULT 90.0 COMMENT '最大仰角(度)',
    data_rate INT COMMENT '数据传输速率(Mbps)',
    slew_rate DECIMAL(5,2) COMMENT '天线转动速率(度/s)',
    FOREIGN KEY (ground_station_id) REFERENCES ground_stations(id) ON DELETE CASCADE,
    INDEX idx_station (ground_station_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='天线配置表';

-- 目标基础配置
CREATE TABLE targets (
    id VARCHAR(32) PRIMARY KEY COMMENT '目标ID',
    name VARCHAR(128) COMMENT '目标名称或描述',
    target_type ENUM('point', 'area') NOT NULL COMMENT '目标类型',
    longitude DECIMAL(9,6) COMMENT '经度（点目标）',
    latitude DECIMAL(8,6) COMMENT '纬度（点目标）',
    area_vertices JSON COMMENT '区域顶点坐标列表',
    priority INT DEFAULT 1 COMMENT '优先级 1-10',
    required_observations INT DEFAULT 1 COMMENT '需要观测次数',
    time_window_start TIMESTAMP NULL COMMENT '观测时间窗口开始',
    time_window_end TIMESTAMP NULL COMMENT '观测时间窗口结束',
    immediate_downlink BOOLEAN DEFAULT FALSE COMMENT '是否立即回传',
    resolution_required DECIMAL(6,2) COMMENT '分辨率要求(米)',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_type (target_type),
    INDEX idx_location (latitude, longitude),
    INDEX idx_priority (priority)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='目标基础配置表';

-- 场景版本管理
CREATE TABLE scenarios (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(128) NOT NULL COMMENT '场景名称',
    version INT DEFAULT 1 COMMENT '版本号',
    description TEXT COMMENT '场景描述',
    start_time TIMESTAMP NOT NULL COMMENT '规划周期开始',
    end_time TIMESTAMP NOT NULL COMMENT '规划周期结束',
    satellite_count INT COMMENT '卫星数量',
    target_count INT COMMENT '目标数量',
    config_json JSON COMMENT '完整场景配置JSON',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_active BOOLEAN DEFAULT TRUE COMMENT '是否当前使用版本',
    UNIQUE KEY uk_name_version (name, version),
    INDEX idx_active (is_active)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='场景版本管理表';
```

### 10.3 场景实例层表结构

```sql
-- 场景-卫星关联
CREATE TABLE scenario_satellites (
    id INT AUTO_INCREMENT PRIMARY KEY,
    scenario_id INT NOT NULL COMMENT '场景ID',
    satellite_id VARCHAR(32) NOT NULL COMMENT '卫星ID',
    initial_storage_used DECIMAL(5,2) DEFAULT 0 COMMENT '初始已用存储(GB)',
    initial_power_used DECIMAL(5,2) DEFAULT 0 COMMENT '初始已用电量(Wh)',
    FOREIGN KEY (scenario_id) REFERENCES scenarios(id) ON DELETE CASCADE,
    FOREIGN KEY (satellite_id) REFERENCES satellites(id),
    UNIQUE KEY uk_scenario_satellite (scenario_id, satellite_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='场景卫星关联表';

-- 场景-目标关联
CREATE TABLE scenario_targets (
    id INT AUTO_INCREMENT PRIMARY KEY,
    scenario_id INT NOT NULL COMMENT '场景ID',
    target_id VARCHAR(32) NOT NULL COMMENT '目标ID',
    adjusted_priority INT COMMENT '场景调整后的优先级',
    adjusted_observations INT COMMENT '场景调整后的观测次数',
    FOREIGN KEY (scenario_id) REFERENCES scenarios(id) ON DELETE CASCADE,
    FOREIGN KEY (target_id) REFERENCES targets(id),
    UNIQUE KEY uk_scenario_target (scenario_id, target_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='场景目标关联表';

-- 场景-地面站关联
CREATE TABLE scenario_ground_stations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    scenario_id INT NOT NULL COMMENT '场景ID',
    ground_station_id VARCHAR(32) NOT NULL COMMENT '地面站ID',
    FOREIGN KEY (scenario_id) REFERENCES scenarios(id) ON DELETE CASCADE,
    FOREIGN KEY (ground_station_id) REFERENCES ground_stations(id),
    UNIQUE KEY uk_scenario_gs (scenario_id, ground_station_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='场景地面站关联表';
```

### 10.4 实验层表结构

```sql
-- 实验记录
CREATE TABLE experiments (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(128) NOT NULL COMMENT '实验名称',
    scenario_id INT NOT NULL COMMENT '使用的场景ID',
    description TEXT COMMENT '实验描述',
    algorithms JSON NOT NULL COMMENT '参与的算法列表',
    repetitions INT DEFAULT 10 COMMENT '每种算法重复运行次数',
    status ENUM('pending', 'running', 'completed', 'failed') DEFAULT 'pending',
    started_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL,
    best_algorithm VARCHAR(64) COMMENT '最佳算法',
    best_makespan DECIMAL(12,2) COMMENT '最优完成时间',
    FOREIGN KEY (scenario_id) REFERENCES scenarios(id),
    INDEX idx_status (status),
    INDEX idx_scenario (scenario_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='实验记录表';

-- 单次运行记录
CREATE TABLE experiment_runs (
    id INT AUTO_INCREMENT PRIMARY KEY,
    experiment_id INT NOT NULL COMMENT '所属实验ID',
    run_number INT NOT NULL COMMENT '运行序号',
    algorithm_name VARCHAR(64) NOT NULL COMMENT '算法名称',
    algorithm_version VARCHAR(32) COMMENT '算法版本',
    status ENUM('running', 'success', 'failed', 'timeout') DEFAULT 'running',
    started_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL,
    demand_satisfaction_rate DECIMAL(5,4) COMMENT '需求满足率 0-1',
    makespan DECIMAL(12,2) COMMENT '全部完成用时(秒)',
    avg_revisit_time DECIMAL(12,2) COMMENT '平均观测间隔(秒)',
    data_delivery_time DECIMAL(12,2) COMMENT '数据回传用时(秒)',
    computation_time DECIMAL(10,3) COMMENT '算法求解用时(秒)',
    solution_quality DECIMAL(5,4) COMMENT '解质量 0-1',
    FOREIGN KEY (experiment_id) REFERENCES experiments(id) ON DELETE CASCADE,
    UNIQUE KEY uk_exp_run (experiment_id, run_number, algorithm_name),
    INDEX idx_algorithm (algorithm_name)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='单次运行记录表';

-- 算法参数
CREATE TABLE algorithm_params (
    id INT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '所属运行ID',
    param_name VARCHAR(64) NOT NULL COMMENT '参数名',
    param_value VARCHAR(256) COMMENT '参数值',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    UNIQUE KEY uk_run_param (run_id, param_name)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='算法参数表';

-- 收敛曲线数据
CREATE TABLE convergence_data (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '所属运行ID',
    iteration INT NOT NULL COMMENT '迭代次数',
    best_fitness DECIMAL(15,6) COMMENT '当前最优适应度值',
    avg_fitness DECIMAL(15,6) COMMENT '种群平均适应度',
    diversity DECIMAL(10,6) COMMENT '种群多样性',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    UNIQUE KEY uk_run_iter (run_id, iteration),
    INDEX idx_iteration (iteration)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='收敛曲线数据表';
```

### 10.5 结果层表结构

```sql
-- 调度任务详情
CREATE TABLE schedule_tasks (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '所属运行ID',
    sub_target_id INT COMMENT '子任务ID（区域目标分解后）',
    target_id VARCHAR(32) COMMENT '原始目标ID（点目标）',
    satellite_id VARCHAR(32) NOT NULL COMMENT '执行卫星',
    antenna_id VARCHAR(32) COMMENT '数传天线',
    imaging_start TIMESTAMP NOT NULL COMMENT '成像开始时间',
    imaging_end TIMESTAMP NOT NULL COMMENT '成像结束时间',
    imaging_mode VARCHAR(32) COMMENT '使用的成像模式',
    slew_start TIMESTAMP COMMENT '姿态调整开始',
    slew_end TIMESTAMP COMMENT '姿态调整结束',
    slew_angle DECIMAL(6,2) COMMENT '侧摆角',
    downlink_start TIMESTAMP COMMENT '数传开始',
    downlink_end TIMESTAMP COMMENT '数传结束',
    downlink_station_id VARCHAR(32) COMMENT '数传地面站',
    storage_before DECIMAL(5,2) COMMENT '成像前存储使用(GB)',
    storage_after DECIMAL(5,2) COMMENT '成像后存储使用(GB)',
    sequence_number INT COMMENT '在该卫星上的执行序号',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    INDEX idx_run (run_id),
    INDEX idx_satellite (satellite_id),
    INDEX idx_time (imaging_start, imaging_end)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='调度任务详情表';

-- 性能指标
CREATE TABLE performance_metrics (
    id INT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '所属运行ID',
    total_tasks INT COMMENT '总任务数',
    scheduled_tasks INT COMMENT '成功调度任务数',
    unscheduled_tasks INT COMMENT '未调度任务数',
    demand_satisfaction_rate DECIMAL(5,4) COMMENT '需求满足率',
    makespan DECIMAL(12,2) COMMENT '总完成用时(秒)',
    avg_revisit_time DECIMAL(12,2) COMMENT '平均观测间隔(秒)',
    max_revisit_time DECIMAL(12,2) COMMENT '最大观测间隔(秒)',
    data_delivery_time DECIMAL(12,2) COMMENT '数据回传用时(秒)',
    computation_time DECIMAL(10,3) COMMENT '算法求解用时(秒)',
    solution_quality DECIMAL(5,4) COMMENT '解质量',
    avg_satellite_utilization DECIMAL(5,4) COMMENT '卫星平均利用率',
    max_satellite_load INT COMMENT '最大负载卫星的任务数',
    ground_station_utilization DECIMAL(5,4) COMMENT '地面站利用率',
    load_balance_std DECIMAL(10,4) COMMENT '卫星负载标准差',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    UNIQUE KEY uk_run (run_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='性能指标表';

-- 任务执行序列
CREATE TABLE task_sequences (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '所属运行ID',
    satellite_id VARCHAR(32) NOT NULL COMMENT '卫星ID',
    task_sequence JSON NOT NULL COMMENT '任务ID序列',
    total_idle_time INT COMMENT '总空闲时间(秒)',
    idle_segments INT COMMENT '空闲段数',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    UNIQUE KEY uk_run_satellite (run_id, satellite_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='任务执行序列表';
```

### 10.6 数据清理策略

```sql
-- 任务完成后清空分解结果的存储过程
DELIMITER //

CREATE PROCEDURE ClearDecompositionData(IN p_scenario_id INT)
BEGIN
    DELETE FROM sub_targets WHERE scenario_id = p_scenario_id;
    UPDATE targets SET status = 'pending'
    WHERE id IN (
        SELECT target_id FROM scenario_targets
        WHERE scenario_id = p_scenario_id
    );
END //

DELIMITER ;
```

---

## 11. 目标分解模块设计 (TargetDecomposer)

### 11.1 问题背景

卫星（尤其是光学和SAR条带模式）无法直接对"大不规则多边形"进行观测。需要在进入Scheduler之前，根据目标区域的几何边界、所需分辨率，以及不同类型卫星的幅宽约束，将大区域网格化（Gridding）或条带化（Striping），切分为具体的"点观测任务"或"线观测任务"。

### 11.2 模块架构

```
core/
├── decomposer/
│   ├── base_decomposer.py      # 分解器基类
│   ├── grid_decomposer.py      # 网格化分解（光学）
│   ├── strip_decomposer.py     # 条带化分解（SAR）
│   └── decomposer_factory.py   # 分解器工厂
```

### 11.3 分解策略

| 策略 | 适用卫星 | 说明 |
|------|----------|------|
| **网格化 (Grid)** | 光学卫星 | 将多边形按固定分辨率划分为规则网格，每个网格中心作为点目标 |
| **条带化 (Strip)** | SAR条带模式 | 沿卫星飞行方向或最优方向切割为平行条带，每条带作为一个线任务 |

### 11.4 数据库表结构

```sql
-- 分解配置
CREATE TABLE decomposition_configs (
    id INT AUTO_INCREMENT PRIMARY KEY,
    target_id VARCHAR(32) NOT NULL COMMENT '目标ID（区域目标）',
    scenario_id INT NOT NULL COMMENT '所属场景',
    strategy ENUM('grid', 'strip') NOT NULL COMMENT '分解策略',
    resolution DECIMAL(6,2) COMMENT '所需分辨率(米)',
    sat_type VARCHAR(16) COMMENT '针对的卫星类型（optical/sar）',
    strip_direction DECIMAL(6,2) COMMENT '条带方向(度)',
    strip_overlap DECIMAL(4,2) DEFAULT 0.1 COMMENT '条带重叠率 0-1',
    grid_size DECIMAL(8,2) COMMENT '网格大小(米)',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (target_id) REFERENCES targets(id),
    FOREIGN KEY (scenario_id) REFERENCES scenarios(id),
    UNIQUE KEY uk_target_scenario (target_id, scenario_id, sat_type)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='分解配置表';

-- 分解后的子任务
CREATE TABLE sub_targets (
    id INT AUTO_INCREMENT PRIMARY KEY,
    parent_target_id VARCHAR(32) NOT NULL COMMENT '父目标ID',
    scenario_id INT NOT NULL COMMENT '所属场景',
    sub_target_code VARCHAR(64) NOT NULL COMMENT '子任务编码，如 AREA-01-001',
    sub_type ENUM('grid_cell', 'strip') NOT NULL COMMENT '子任务类型',
    center_lon DECIMAL(9,6) COMMENT '中心经度',
    center_lat DECIMAL(8,6) COMMENT '中心纬度',
    vertices JSON COMMENT '顶点坐标',
    area_sqkm DECIMAL(10,2) COMMENT '面积(平方公里)',
    strip_length DECIMAL(10,2) COMMENT '条带长度(米)',
    required_mode VARCHAR(32) COMMENT '推荐的成像模式',
    estimated_duration INT COMMENT '预估成像时长(秒)',
    status ENUM('pending', 'scheduled', 'completed', 'failed') DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (parent_target_id) REFERENCES targets(id),
    FOREIGN KEY (scenario_id) REFERENCES scenarios(id),
    INDEX idx_parent (parent_target_id),
    INDEX idx_scenario (scenario_id),
    INDEX idx_status (status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='分解后的子任务表';
```

---

## 12. 连续状态演化跟踪器设计

### 12.1 问题背景

在离线调度中，电量和存储是强时间依赖的连续变量：

1. **太阳光照/阴影区计算**：卫星在阴影区成像耗电极快且无法充电，在光照区才能通过太阳能帆板充电。可见性模块需要补充对日可见性（地影计算）。

2. **存储与数传的耦合**：存储容量在成像时增加，在途径地面站下传时释放。调度算法在指派任务时，必须前向推演这段时间内的充放电和存储吞吐情况。

### 12.2 模块架构

```
simulator/
├── state_tracker.py          # 状态跟踪器主类
├── eclipse_calculator.py     # 地影计算器（对日可见性）
├── power_model.py            # 能源模型（分段常数）
├── storage_integrator.py     # 存储积分器
└── event_queue.py            # 事件队列
```

### 12.3 核心类设计

```python
class SatelliteState(Enum):
    IDLE = "idle"
    IMAGING = "imaging"
    SLEWING = "slewing"
    DOWNLINK = "downlink"
    ECLIPSE = "eclipse"

@dataclass
class ResourceState:
    timestamp: datetime
    power_level: float      # 当前电量 (Wh)
    storage_level: float    # 当前存储使用 (GB)
    is_eclipse: bool        # 是否在地影区
    charging_power: float   # 当前充电功率 (W)

class SatelliteStateTracker:
    """
    单颗卫星连续状态跟踪器

    核心功能：
    1. 地影区/光照区判断
    2. 电量积分（充电/放电）- 分段常数模型
    3. 存储积分（成像增加/数传释放）
    4. 前向推演验证
    """

    def __init__(self,
                 satellite_id: str,
                 initial_power: float,
                 initial_storage: float,
                 max_power: float,
                 max_storage: float,
                 charging_power: float,     # 光照区充电功率 W
                 imaging_power: float,      # 成像功耗 W
                 downlink_power: float,     # 数传功耗 W
                 slew_power: float,         # 姿态调整功耗 W
                 imaging_rate: float,       # 成像存储速率 GB/s
                 downlink_rate: float):     # 数传释放速率 GB/s
        # ... 初始化代码

    def is_in_eclipse(self, t: datetime) -> bool:
        """判断某时刻是否在地影区"""
        pass

    def compute_power_flow(self, t: datetime, activity: SatelliteState) -> float:
        """
        计算某时刻的净功率流 (W)
        正值: 充电, 负值: 耗电
        """
        pass

    def integrate(self, start_time: datetime, end_time: datetime,
                  activities: List[Tuple]) -> ResourceState:
        """状态积分器"""
        pass
```

### 12.4 前向推演验证器

```python
class ScheduleValidator:
    """
    调度方案验证器

    验证候选任务序列是否满足：
    1. 电量始终 >= 0
    2. 存储始终 <= max_storage
    3. 任务时间不冲突
    """

    def validate_forward(self, candidate_task: 'Task',
                        existing_tasks: List['Task'],
                        planning_horizon: datetime) -> Tuple[bool, str]:
        """
        前向推演验证

        将候选任务加入现有任务序列，验证到planning_horizon时刻
        资源约束始终满足

        Returns:
            (是否可行, 失败原因)
        """
        pass
```

### 12.5 地影计算器

```python
class EclipseCalculator:
    """
    地影计算器

    计算卫星在规划周期内的地影区间（本影+半影）
    简化模型：圆柱形地影
    """

    EARTH_RADIUS = 6371000  # 地球半径(m)
    SUN_RADIUS = 696340000  # 太阳半径(m)
    AU = 149597870700  # 天文单位(m)

    def calculate_eclipse_intervals(self,
                                     satellite_orbit: 'Orbit',
                                     start_time: datetime,
                                     end_time: datetime,
                                     time_step: int = 60) -> List[Tuple[datetime, datetime]]:
        """计算卫星在给定时间段内的地影区间"""
        pass

    def _is_in_eclipse(self, sat_pos: Tuple[float, float, float],
                       sun_pos: Tuple[float, float, float]) -> bool:
        """判断卫星是否在地影中（圆柱近似模型）"""
        pass
```

### 12.6 状态层数据库表结构

```sql
-- 卫星状态历史（记录关键时间点的状态，用于调试和分析）
CREATE TABLE satellite_state_snapshots (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '所属运行ID',
    satellite_id VARCHAR(32) NOT NULL COMMENT '卫星ID',
    snapshot_time TIMESTAMP NOT NULL COMMENT '快照时间',
    power_level DECIMAL(10,2) COMMENT '电量(Wh)',
    storage_level DECIMAL(10,2) COMMENT '存储(GB)',
    is_eclipse BOOLEAN COMMENT '是否地影',
    current_activity VARCHAR(32) COMMENT '当前活动',
    current_task_id BIGINT COMMENT '当前执行任务ID',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    INDEX idx_run_satellite (run_id, satellite_id),
    INDEX idx_time (snapshot_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='卫星状态快照表';

-- 资源约束违反记录（用于分析调度失败原因）
CREATE TABLE constraint_violations (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '所属运行ID',
    violation_type ENUM('power', 'storage', 'time') NOT NULL COMMENT '违反类型',
    satellite_id VARCHAR(32) COMMENT '涉及卫星',
    violation_time TIMESTAMP COMMENT '违反发生时间',
    expected_value DECIMAL(10,2) COMMENT '预期值',
    limit_value DECIMAL(10,2) COMMENT '限制值',
    description TEXT COMMENT '详细描述',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    INDEX idx_run (run_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='约束违反记录表';
```

### 12.7 关键设计决策

| 设计点 | 决策 | 说明 |
|--------|------|------|
| **能源模型** | 分段常数模型 | 光照区固定充电功率，阴影区零充电，各活动固定功耗 |
| **存储验证** | 精确推演 | 每个候选任务都前向推演到规划周期结束，验证存储始终不溢出 |
| **地影计算** | 圆柱近似 | 简化模型，精度足够用于调度约束验证 |
| **积分步长** | 60秒 | 平衡精度与性能，关键区间可细化 |

---

## 13. 性能优化：时间窗口缓存设计

### 13.1 问题背景

在元启发式算法（如GA、PSO）中，调度器通常需要迭代数万次来评估解的适应度。STK COM接口的进程间通信开销极大，如果实时计算可见性，会直接导致算法"卡死"。

**核心原则**：可见性计算绝不应该在算法迭代（schedule()）时实时计算。必须在实验初始化阶段预计算出所有"卫星-目标"和"卫星-地面站"的可见时间窗口（Time Windows）并缓存到内存，算法迭代时只做纯粹的集合与时间段的数学运算。

### 13.2 架构设计

```
core/
├── orbit/
│   ├── visibility/
│   │   ├── base.py                 # 可见性计算基类
│   │   ├── stk_visibility.py       # STK实现（仅预计算阶段使用）
│   │   ├── orekit_visibility.py    # Orekit实现
│   │   └── window_cache.py         # 时间窗口缓存管理器
```

**执行流程**：

```
实验初始化阶段:
  STK/Orekit ──▶ 预计算所有可见窗口 ──▶ 内存Dict缓存 (O(1)访问)
     (一次调用)
                     │
                     ▼
元启发式算法迭代阶段:
  for generation in range(10000):
      for individual in population:
          fitness = evaluate(individual)
          # 只访问内存缓存，O(1)复杂度，纳秒级延迟
          windows = cache.get_windows(sat_id, target_id)
```

### 13.3 内存缓存数据结构

```python
@dataclass(frozen=True, slots=True)
class VisibilityWindow:
    """
    可见时间窗口 - 不可变对象，支持哈希

    frozen=True: 保证线程安全，可哈希
    __slots__: 减少内存占用（约80字节/窗口）
    """
    satellite_id: str
    target_id: str
    start_time: datetime
    end_time: datetime
    max_elevation: float      # 最大仰角
    quality_score: float      # 窗口质量评分

    def duration(self) -> float:
        """窗口持续时间(秒)"""
        return (self.end_time - self.start_time).total_seconds()


class VisibilityWindowCache:
    """
    可见性窗口内存缓存管理器

    核心特性：
    1. O(1)时间复杂度查询
    2. 预计算阶段只执行一次
    3. 支持多维度索引（卫星、目标、时间）
    4. 内存占用优化
    """

    def __init__(self):
        # 主索引: (sat_id, target_id) -> List[VisibilityWindow]
        self._windows: Dict[Tuple[str, str], List[VisibilityWindow]] = {}

        # 辅助索引: sat_id -> Set[target_id]
        self._sat_to_targets: Dict[str, Set[str]] = {}

        # 辅助索引: target_id -> Set[sat_id]
        self._target_to_sats: Dict[str, Set[str]] = {}

        # 时间索引: (sat_id, target_id) -> List[start_time]（用于二分查找）
        self._time_index: Dict[Tuple[str, str], List[datetime]] = {}

    def precompute_all_windows(self, satellites, targets, ground_stations,
                               start_time, end_time, calculator) -> None:
        """
        预计算所有可见性窗口（实验初始化阶段调用一次）
        这是唯一会调用STK/Orekit的地方！
        """
        # 计算卫星-目标可见窗口
        for sat in satellites:
            for target in targets:
                windows = calculator.compute_satellite_target_windows(
                    sat, target, start_time, end_time
                )
                if windows:
                    key = (sat.id, target.id)
                    self._windows[key] = windows
                    self._time_index[key] = [w.start_time for w in windows]

        # 计算卫星-地面站可见窗口
        for sat in satellites:
            for gs in ground_stations:
                windows = calculator.compute_satellite_ground_station_windows(
                    sat, gs, start_time, end_time
                )
                if windows:
                    key = (sat.id, f"GS:{gs.id}")
                    self._windows[key] = windows

    def get_windows(self, satellite_id: str, target_id: str) -> List[VisibilityWindow]:
        """获取指定卫星-目标对的所有可见窗口 - O(1)复杂度"""
        return self._windows.get((satellite_id, target_id), [])

    def get_windows_in_range(self, satellite_id: str, target_id: str,
                             start: datetime, end: datetime) -> List[VisibilityWindow]:
        """
        获取指定时间范围内的可见窗口
        时间复杂度: O(log n + k)
        """
        all_windows = self.get_windows(satellite_id, target_id)
        if not all_windows:
            return []

        time_list = self._time_index.get((satellite_id, target_id), [])

        # 二分查找起始位置
        left = bisect.bisect_left(time_list, start)
        right = bisect.bisect_right(time_list, end)

        # 过滤出时间范围内的窗口
        result = []
        for i in range(left, min(right, len(all_windows))):
            window = all_windows[i]
            if window.start_time < end and window.end_time > start:
                result.append(window)

        return result
```

### 13.4 调度器集成

```python
class BaseScheduler(ABC):
    """调度器基类 - 集成高性能窗口缓存"""

    def __init__(self, name: str, config: Dict = None):
        self.name = name
        self.config = config or {}
        self.window_cache: Optional[VisibilityWindowCache] = None

    def set_window_cache(self, cache: VisibilityWindowCache) -> None:
        """设置窗口缓存（实验初始化时调用）"""
        self.window_cache = cache

    def get_feasible_windows(self, satellite_id: str, target_id: str,
                             earliest_start: datetime,
                             latest_end: datetime) -> List[VisibilityWindow]:
        """
        获取可行的时间窗口（调度算法迭代中高频调用）
        必须是O(1)或O(log n)复杂度！
        """
        if not self.window_cache:
            raise RuntimeError("Window cache not set")

        # 从缓存获取候选窗口（O(log n)）
        return self.window_cache.get_windows_in_range(
            satellite_id, target_id, earliest_start, latest_end
        )
```

### 13.5 实验运行器集成

```python
class ExperimentRunner:
    """实验执行器 - 集成预计算和缓存"""

    def run_benchmark(self, algorithms, scenarios, repetitions=10):
        for scenario_file in scenarios:
            scenario = Scenario.load(scenario_file)

            # ========== 阶段1: 预计算所有可见性窗口（一次） ==========
            visibility_calculator = self._create_visibility_calculator()
            window_cache = VisibilityWindowCache()

            window_cache.precompute_all_windows(
                satellites=scenario.satellites,
                targets=scenario.targets,
                ground_stations=scenario.ground_stations,
                start_time=scenario.start_time,
                end_time=scenario.end_time,
                calculator=visibility_calculator
            )

            # 预计算完成后可以关闭STK连接（节省资源）
            if hasattr(visibility_calculator, 'close'):
                visibility_calculator.close()

            # ========== 阶段2: 运行所有算法（只访问内存缓存） ==========
            for algorithm_class in algorithms:
                for run_id in range(repetitions):
                    algo = algorithm_class()
                    algo.set_window_cache(window_cache)  # 注入缓存

                    # 运行调度（此时所有可见性查询都是O(1)）
                    result = algo.schedule()

            # ========== 阶段3: 清理缓存 ==========
            window_cache.clear()
```

### 13.6 性能对比

| 方案 | 单次访问延迟 | 10万次迭代耗时 | 适用性 |
|------|-------------|---------------|--------|
| STK COM实时计算 | 100-500ms | 数小时 | ❌ 不可行 |
| Orekit实时计算 | 10-50ms | 数十分钟 | ❌ 太慢 |
| **内存缓存** | **<1μs** | **<1秒** | ✅ **推荐** |

### 13.7 内存占用预估

- 50颗卫星 × 1000目标 × 10窗口/天 = 50万个窗口
- 每个窗口约80字节（使用`__slots__`）
- Dict开销约3倍
- **总内存占用：约50-100MB**

完全在可接受范围内，现代服务器可轻松承载。

### 13.8 关键设计要点总结

1. **预计算一次**：实验初始化阶段调用STK/Orekit计算所有窗口
2. **内存缓存**：使用Python Dict存储，O(1)访问
3. **算法迭代零IO**：调度器只操作内存数据
4. **数据压缩**：使用`__slots__`和紧凑结构减少内存占用
5. **多维度索引**：支持卫星、目标、时间等多维度快速查询

---

**文档版本**: 1.2 (已更新)
**更新日期**: 2026-02-19
**更新内容**:
- 新增数据持久化与存储设计（第10章）
- 新增目标分解模块设计（第11章）
- 新增连续状态演化跟踪器设计（第12章）
- 新增性能优化：时间窗口缓存设计（第13章）

---

## 14. 失败原因追踪设计

### 14.1 问题背景

原设计中 `ScheduleResult.unscheduled_tasks` 为 `List[str]`，仅返回失败任务ID。这对于后续分析和算法改进毫无帮助。需要详细记录每个任务失败的具体原因（电量不足、存储溢出、时间冲突等），与第12章的 `constraint_violations` 表直接对应。

### 14.2 失败原因分类

```python
from enum import Enum
from dataclasses import dataclass
from typing import Optional, Dict, Any
from datetime import datetime

class TaskFailureReason(Enum):
    """任务失败原因枚举"""

    # 资源约束
    POWER_CONSTRAINT = "power_constraint"           # 电量不足
    STORAGE_CONSTRAINT = "storage_constraint"        # 存储溢出
    STORAGE_OVERFLOW_RISK = "storage_overflow_risk"  # 存储溢出风险

    # 时间约束
    NO_VISIBLE_WINDOW = "no_visible_window"          # 无可见时间窗
    WINDOW_TOO_SHORT = "window_too_short"            # 可见窗口太短
    TIME_CONFLICT = "time_conflict"                  # 与其他任务时间冲突
    DEADLINE_VIOLATION = "deadline_violation"        # 超出截止时间

    # 能力约束
    SAT_CAPABILITY_MISMATCH = "sat_capability_mismatch"  # 卫星能力不匹配
    MODE_NOT_SUPPORTED = "mode_not_supported"        # 不支持所需成像模式
    OFF_NADIR_EXCEEDED = "off_nadir_exceeded"        # 超出最大侧摆角

    # 协同约束
    GROUND_STATION_UNAVAILABLE = "ground_station_unavailable"  # 地面站不可用
    ANTENNA_CONFLICT = "antenna_conflict"            # 天线资源冲突

    # 其他
    UNKNOWN = "unknown"                              # 未知原因
    ALGORITHM_TIMEOUT = "algorithm_timeout"          # 算法超时
```

### 14.3 增强的数据结构

```python
@dataclass
class TaskFailure:
    """单个任务失败记录"""
    task_id: str                           # 任务ID
    failure_reason: TaskFailureReason      # 失败原因枚举
    failure_detail: str                    # 详细描述

    # 可选的上下文信息
    satellite_id: Optional[str] = None     # 尝试分配的卫星
    attempted_time: Optional[datetime] = None  # 尝试分配的时间
    constraint_value: Optional[float] = None   # 约束值
    limit_value: Optional[float] = None        # 限制值
    context: Dict[str, Any] = None         # 额外上下文

    def to_dict(self) -> Dict[str, Any]:
        """转换为字典（用于数据库存储）"""
        return {
            'task_id': self.task_id,
            'failure_reason': self.failure_reason.value,
            'failure_detail': self.failure_detail,
            'satellite_id': self.satellite_id,
            'attempted_time': self.attempted_time.isoformat() if self.attempted_time else None,
            'constraint_value': self.constraint_value,
            'limit_value': self.limit_value,
            'context': self.context
        }


@dataclass
class ScheduleResult:
    """增强的调度结果"""
    scheduled_tasks: List[Dict]              # 被成功执行的任务
    unscheduled_tasks: Dict[str, TaskFailure]  # 未调度任务及其失败原因

    makespan: float                          # 总完成时间
    computation_time: float                  # 算法求解用时
    iterations: int                          # 迭代次数
    convergence_curve: List[float]           # 收敛曲线

    # 失败原因统计
    failure_summary: Dict[TaskFailureReason, int] = None

    def __post_init__(self):
        """初始化后计算失败原因统计"""
        if self.failure_summary is None and self.unscheduled_tasks:
            self.failure_summary = {}
            for failure in self.unscheduled_tasks.values():
                reason = failure.failure_reason
                self.failure_summary[reason] = self.failure_summary.get(reason, 0) + 1

    def get_failure_rate_by_reason(self) -> Dict[str, float]:
        """按原因计算失败比例"""
        if not self.unscheduled_tasks:
            return {}
        total = len(self.unscheduled_tasks)
        return {
            reason.value: count / total
            for reason, count in self.failure_summary.items()
        }
```

### 14.4 调度器中的失败记录

```python
class BaseScheduler(ABC):
    """增强的调度器基类，支持失败原因追踪"""

    def __init__(self, name: str, config: Dict[str, Any] = None):
        self.name = name
        self.config = config or {}
        self.window_cache: Optional[VisibilityWindowCache] = None
        self.state_trackers: Dict[str, SatelliteStateTracker] = {}
        self._failure_log: List[TaskFailure] = []

    def _record_failure(self,
                        task_id: str,
                        reason: TaskFailureReason,
                        detail: str,
                        satellite_id: str = None,
                        attempted_time: datetime = None,
                        constraint_value: float = None,
                        limit_value: float = None,
                        context: Dict = None) -> None:
        """记录任务失败原因"""
        failure = TaskFailure(
            task_id=task_id,
            failure_reason=reason,
            failure_detail=detail,
            satellite_id=satellite_id,
            attempted_time=attempted_time,
            constraint_value=constraint_value,
            limit_value=limit_value,
            context=context or {}
        )
        self._failure_log.append(failure)

    def _try_schedule_task(self, task: Task, satellite: Satellite) -> bool:
        """尝试调度任务，失败时自动记录原因"""
        windows = self.window_cache.get_windows(satellite.id, task.target_id)
        if not windows:
            self._record_failure(
                task_id=task.id,
                reason=TaskFailureReason.NO_VISIBLE_WINDOW,
                detail=f"卫星 {satellite.id} 对目标 {task.target_id} 无可见窗口",
                satellite_id=satellite.id
            )
            return False

        # 检查资源约束
        tracker = self.state_trackers.get(satellite.id)
        for window in windows:
            is_feasible, reason = self._validate_resource_feasibility(
                satellite.id, window, task
            )
            if is_feasible:
                return True

            # 记录具体失败原因
            if "power" in reason.lower():
                self._record_failure(
                    task_id=task.id,
                    reason=TaskFailureReason.POWER_CONSTRAINT,
                    detail=f"电量不足: {reason}",
                    satellite_id=satellite.id,
                    attempted_time=window.start_time,
                    constraint_value=tracker.initial_state.power_level if tracker else None,
                    limit_value=satellite.capabilities.power_capacity
                )
            elif "storage" in reason.lower():
                self._record_failure(
                    task_id=task.id,
                    reason=TaskFailureReason.STORAGE_CONSTRAINT,
                    detail=f"存储溢出: {reason}",
                    satellite_id=satellite.id,
                    attempted_time=window.start_time
                )
        return False
```

### 14.5 与数据库的对应

```python
def save_schedule_result_to_db(result: ScheduleResult, run_id: int, db_connection) -> None:
    """将调度结果写入数据库"""
    cursor = db_connection.cursor()

    # 写入成功调度的任务
    for task in result.scheduled_tasks:
        cursor.execute("""
            INSERT INTO schedule_tasks
            (run_id, target_id, satellite_id, imaging_start, imaging_end)
            VALUES (%s, %s, %s, %s, %s)
        """, (run_id, task['target_id'], task['satellite_id'], ...))

    # 写入失败任务到 constraint_violations 表
    for task_id, failure in result.unscheduled_tasks.items():
        cursor.execute("""
            INSERT INTO constraint_violations
            (run_id, violation_type, satellite_id, violation_time,
             expected_value, limit_value, description)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
        """, (
            run_id,
            failure.failure_reason.value,
            failure.satellite_id,
            failure.attempted_time,
            failure.constraint_value,
            failure.limit_value,
            failure.failure_detail
        ))

    db_connection.commit()
```

### 14.6 失败分析接口

```python
class FailureAnalyzer:
    """失败原因分析器，用于分析调度失败模式"""

    def __init__(self, results: List[ScheduleResult]):
        self.results = results

    def analyze_failure_patterns(self) -> Dict[str, Any]:
        """分析失败模式并生成改进建议"""
        all_failures: List[TaskFailure] = []
        for result in self.results:
            all_failures.extend(result.unscheduled_tasks.values())

        # 统计各原因数量
        reason_counts = {}
        for failure in all_failures:
            reason = failure.failure_reason.value
            reason_counts[reason] = reason_counts.get(reason, 0) + 1

        # 生成改进建议
        recommendations = []
        top_reason = max(reason_counts, key=reason_counts.get)

        if top_reason == 'power_constraint':
            recommendations.append("建议增加卫星电池容量或优化能源调度策略")
        elif top_reason == 'storage_constraint':
            recommendations.append("建议增加星上存储或优化数传调度")
        elif top_reason == 'no_visible_window':
            recommendations.append("建议调整卫星轨道或增加卫星数量")

        return {
            'most_common_reason': top_reason,
            'reason_distribution': reason_counts,
            'recommendations': recommendations
        }
```

### 14.7 关键设计要点

| 设计点 | 实现方式 | 用途 |
|--------|----------|------|
| 失败原因分类 | TaskFailureReason 枚举 | 标准化失败类型，便于统计 |
| 详细上下文 | TaskFailure 数据类 | 记录失败时的资源状态、时间、卫星等信息 |
| 结果统计 | ScheduleResult.failure_summary | 快速获取各类失败数量 |
| 数据库存储 | constraint_violations 表 | 持久化失败记录，支持后续分析 |
| 分析接口 | FailureAnalyzer | 生成失败模式报告和改进建议 |

---

**文档版本**: 1.3 (已更新)
**更新日期**: 2026-02-19
**更新内容**:
- 新增数据持久化与存储设计（第10章）
- 新增目标分解模块设计（第11章）
- 新增连续状态演化跟踪器设计（第12章）
- 新增性能优化：时间窗口缓存设计（第13章）
- 新增失败原因追踪设计（第14章）

---

## 15. 强化学习/AI Agent 接口设计

### 15.1 设计目标

为未来引入深度强化学习（DRL）和基于大语言模型（LLM）的AI Agent预留标准化接口。通过统一的状态空间（Observation）和动作空间（Action）抽象，使传统算法与智能算法能够无缝切换和对比。

```
┌─────────────────────────────────────────────────────────────┐
│                    统一的调度器抽象层                          │
│                                                              │
│   传统算法 (GA/PSO)          DRL算法 (PPO/SAC)              │
│        │                           │                        │
│        ▼                           ▼                        │
│   ┌─────────┐                ┌─────────────┐               │
│   │ schedule│                │  reset()    │               │
│   │   ()    │                │  step()     │               │
│   └─────────┘                │  observe()  │               │
│                                └─────────────┘               │
│                                        │                     │
│        ▲                               ▲                     │
│        │                               │                     │
│   ┌─────────┐                ┌─────────────┐               │
│   │ Base    │◄───────────────│ RLScheduler │               │
│   │Scheduler│   统一接口      │  Interface  │               │
│   └─────────┘                └─────────────┘               │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### 15.2 Observation Space（观测空间）

```python
@dataclass
class Observation:
    """
    强化学习观测空间

    包含完整的调度状态信息，支持向量化（用于神经网络输入）
    """

    # 全局时间特征
    current_time: datetime           # 当前仿真时间
    planning_horizon: datetime       # 规划截止时间
    time_progress: float             # 时间进度 0-1

    # 任务特征矩阵 (num_tasks, task_feature_dim)
    task_features: np.ndarray        # 每个任务的特征向量
    # 特征包括：优先级、剩余观测次数、截止时间倒计时、
    #         目标类型(one-hot)、所需分辨率、位置(经度/纬度)

    # 卫星特征矩阵 (num_satellites, sat_feature_dim)
    satellite_features: np.ndarray   # 每个卫星的特征向量
    # 特征包括：电量水平(0-1)、存储使用(0-1)、当前位置、
    #         是否地影区(0/1)、卫星类型(one-hot)、当前状态

    # 可见性窗口矩阵 Dict[(sat_id, task_id)] -> List[WindowFeatures]
    visibility_matrix: Dict[Tuple[str, str], List[np.ndarray]]
    # 窗口特征：开始时间、持续时间、质量评分、最大仰角、最小侧摆角

    # 调度历史特征 (num_satellites, history_length, history_feature_dim)
    recent_schedule_history: np.ndarray

    # 动作掩码 (num_satellites, num_tasks, max_windows)
    valid_action_mask: np.ndarray    # 有效动作掩码

    def to_vector(self) -> np.ndarray:
        """将观测转换为扁平化向量（用于神经网络）"""
        pass

    def to_dict(self) -> Dict[str, Any]:
        """转换为字典（用于LLM Agent）"""
        pass
```

### 15.3 Action Space（动作空间）

```python
@dataclass
class Action:
    """
    强化学习动作空间（中粒度）

    定义一次完整的调度决策
    """

    # 核心决策
    task_id: str                     # 要调度的任务ID
    satellite_id: str                # 分配给哪个卫星
    window_index: int                # 选择第几个可见窗口
    action_type: str                 # 动作类型: 'schedule', 'skip', 'wait'

    # 详细配置（中粒度扩展）
    imaging_mode: Optional[str] = None       # 成像模式
    slew_angle: Optional[float] = None       # 侧摆角度
    downlink_immediate: Optional[bool] = None  # 是否立即数传

    # 在轨处理决策（第20章扩展）
    processing_decision: Optional[str] = None  # 'onboard', 'downlink', 'auto'
    ai_model_type: Optional[str] = None        # AI模型类型（轻量/重型）
    compression_level: Optional[str] = None    # 压缩级别（high/medium/low）

    # 动作置信度（可选，用于分析）
    confidence: Optional[float] = None

    def is_valid(self) -> bool:
        """验证动作是否完整"""
        pass

    def to_dict(self) -> Dict[str, Any]:
        """转换为字典"""
        pass
```

### 15.4 RL Scheduler 接口

```python
class RLSchedulerInterface(ABC):
    """
    强化学习调度器接口

    遵循OpenAI Gym风格的API设计
    支持单智能体和多智能体场景
    """

    @abstractmethod
    def reset(self, scenario: 'Scenario') -> Observation:
        """重置环境，开始新的调度 episode"""
        pass

    @abstractmethod
    def step(self, action: Action) -> Tuple[Observation, float, bool, Dict]:
        """
        执行一个动作，返回新的状态和奖励

        Returns: observation, reward, done, info
        """
        pass

    @abstractmethod
    def observe(self) -> Observation:
        """获取当前观测（不执行动作）"""
        pass

    @abstractmethod
    def get_valid_actions(self) -> List[Action]:
        """获取当前所有有效动作（用于动作掩码）"""
        pass

    @abstractmethod
    def calculate_reward(self, action: Action,
                         previous_state: 'State',
                         current_state: 'State') -> float:
        """
        计算奖励函数

        可定制的奖励设计：
        - 完成任务奖励
        - 资源效率奖励
        - 时间效率奖励
        - 约束违反惩罚
        """
        pass

    @abstractmethod
    def get_state_vector(self) -> np.ndarray:
        """获取状态向量化表示（用于神经网络）"""
        pass
```

### 15.5 增强的 BaseScheduler

```python
class BaseScheduler(BaseScheduler, RLSchedulerInterface):
    """
    增强的调度器基类

    同时支持传统算法和强化学习接口
    """

    def __init__(self, name: str, config: Dict[str, Any] = None):
        super().__init__(name, config)

        # RL相关状态
        self._current_observation: Optional[Observation] = None
        self._episode_history: List[Tuple[Observation, Action, float]] = []
        self._current_scenario: Optional['Scenario'] = None
        self._step_count: int = 0

        # 奖励函数配置
        self.reward_weights = {
            'task_completion': 10.0,      # 完成任务奖励
            'resource_efficiency': 1.0,    # 资源效率奖励
            'time_efficiency': 0.5,        # 时间效率奖励
            'constraint_violation': -10.0, # 约束违反惩罚
            'idle_penalty': -0.1,          # 空闲惩罚
        }

    def reset(self, scenario: 'Scenario') -> Observation:
        """重置环境"""
        self._current_scenario = scenario
        self._step_count = 0
        self._episode_history = []

        # 初始化所有组件
        self.initialize(scenario.mission,
                       scenario.satellite_pool,
                       scenario.ground_station_pool)

        # 构建初始观测
        self._current_observation = self._build_observation()

        return self._current_observation

    def step(self, action: Action) -> Tuple[Observation, float, bool, Dict]:
        """执行动作"""
        # 记录执行前的状态
        previous_state = self._capture_state()

        # 执行调度动作
        if action.action_type == 'schedule':
            success = self._execute_schedule_action(action)
        elif action.action_type == 'skip':
            success = self._execute_skip_action(action)
        elif action.action_type == 'wait':
            success = self._execute_wait_action(action)
        else:
            success = False

        # 计算奖励
        reward = self.calculate_reward(action, previous_state,
                                      self._capture_state())

        # 构建新观测
        observation = self._build_observation()
        self._current_observation = observation

        # 检查是否结束
        done = self._is_episode_done()

        # 记录历史
        self._episode_history.append((previous_state, action, reward))
        self._step_count += 1

        info = {
            'step': self._step_count,
            'action_success': success,
            'scheduled_tasks': len(self._scheduled_tasks),
            'remaining_tasks': len(self._pending_tasks),
        }

        return observation, reward, done, info

    def calculate_reward(self, action: Action, previous_state: 'State',
                        current_state: 'State') -> float:
        """计算奖励（可定制的多目标奖励函数）"""
        reward = 0.0

        # 1. 任务完成奖励
        if action.action_type == 'schedule':
            reward += self.reward_weights['task_completion']

        # 2. 资源效率奖励
        power_efficiency = self._calculate_power_efficiency(current_state)
        reward += power_efficiency * self.reward_weights['resource_efficiency']

        # 3. 时间效率奖励
        time_efficiency = self._calculate_time_efficiency(action)
        reward += time_efficiency * self.reward_weights['time_efficiency']

        # 4. 约束违反惩罚
        if self._has_constraint_violation(current_state):
            reward += self.reward_weights['constraint_violation']

        # 5. 空闲惩罚
        if action.action_type == 'wait':
            reward += self.reward_weights['idle_penalty']

        return reward

    def schedule(self) -> ScheduleResult:
        """
        传统调度接口（向后兼容）

        通过循环调用step()实现
        """
        observation = self.reset(self._current_scenario)
        done = False

        while not done:
            # 这里可以接入RL策略网络
            # action = policy_network.select_action(observation)

            # 或者使用传统启发式选择动作
            action = self._select_action_heuristic(observation)

            observation, reward, done, info = self.step(action)

        # 构建ScheduleResult
        return self._build_schedule_result()
```

### 15.6 DRL算法示例（PPO）

```python
# scheduler/custom/ppo_scheduler.py

import torch
import torch.nn as nn
from scheduler.rl_interface import BaseScheduler, Action, Observation

class PPOScheduler(BaseScheduler):
    """
    基于PPO的深度强化学习调度器

    使用Actor-Critic架构
    """

    def __init__(self, config: Dict = None):
        super().__init__("PPO", config)

        # 神经网络参数
        self.state_dim = config.get('state_dim', 256)
        self.action_dim = config.get('action_dim', 128)
        self.hidden_dim = config.get('hidden_dim', 256)

        # 创建策略网络
        self.actor = ActorNetwork(self.state_dim, self.action_dim, self.hidden_dim)
        self.critic = CriticNetwork(self.state_dim, self.hidden_dim)

        # PPO超参数
        self.clip_epsilon = config.get('clip_epsilon', 0.2)
        self.gamma = config.get('gamma', 0.99)
        self.lam = config.get('lam', 0.95)

    def schedule(self) -> ScheduleResult:
        """PPO训练/推理循环"""
        observation = self.reset(self._current_scenario)
        done = False
        trajectory = []

        while not done:
            # 获取状态向量
            state_vec = self.get_state_vector()

            # Actor选择动作
            with torch.no_grad():
                action_probs = self.actor(torch.FloatTensor(state_vec))
                action_idx = torch.multinomial(action_probs, 1).item()

            # 转换动作索引为Action对象
            action = self._index_to_action(action_idx, observation)

            # 执行动作
            next_observation, reward, done, info = self.step(action)

            # 存储transition
            trajectory.append({
                'state': state_vec,
                'action': action_idx,
                'reward': reward,
                'done': done,
                'value': self.critic(torch.FloatTensor(state_vec)).item()
            })

            observation = next_observation

        # PPO更新（训练模式）
        if self.config.get('training', False):
            self._update_ppo(trajectory)

        return self._build_schedule_result()


class ActorNetwork(nn.Module):
    """策略网络（Actor）"""

    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int):
        super().__init__()

        self.fc = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, action_dim),
            nn.Softmax(dim=-1)
        )

    def forward(self, state):
        return self.fc(state)
```

### 15.7 LLM Agent 接口

```python
# scheduler/custom/llm_agent_scheduler.py

from scheduler.rl_interface import BaseScheduler, Action, Observation

class LLMAgentScheduler(BaseScheduler):
    """
    基于大语言模型的智能体调度器

    使用LLM进行决策，通过自然语言描述状态
    """

    def __init__(self, config: Dict = None):
        super().__init__("LLM_Agent", config)
        self.llm_client = config.get('llm_client')
        self.prompt_template = self._load_prompt_template()

    def _select_action(self, observation: Observation) -> Action:
        """使用LLM选择动作"""
        # 构建prompt
        prompt = self._build_prompt(observation)

        # 调用LLM
        response = self.llm_client.generate(prompt)

        # 解析LLM输出为Action
        action = self._parse_llm_response(response)

        return action

    def _build_prompt(self, observation: Observation) -> str:
        """构建LLM prompt"""
        state_dict = observation.to_dict()

        prompt = f"""
你是一个卫星任务调度专家。当前调度状态如下：

当前时间: {state_dict['current_time']}
时间进度: {state_dict['time_progress']:.1%}
待调度任务数: {state_dict['num_pending_tasks']}

卫星状态:
{self._format_satellites(state_dict['satellite_status'])}

即将到达的可见窗口:
{self._format_windows(state_dict['upcoming_windows'])}

请选择一个最优的调度动作。可选动作包括:
1. schedule(task_id, satellite_id, window_index) - 安排任务
2. skip(task_id) - 跳过任务
3. wait() - 等待下一个时间窗口

请用JSON格式返回你的决策:
{{
    "action_type": "schedule",
    "task_id": "TASK-001",
    "satellite_id": "SAT-01",
    "window_index": 0,
    "reasoning": "选择原因..."
}}
"""
        return prompt
```

### 15.8 接口兼容性说明

| 接口 | 传统算法 | DRL (PPO/SAC) | LLM Agent |
|------|----------|---------------|-----------|
| `schedule()` | ✅ 直接调用 | ✅ 内部循环 | ✅ 内部循环 |
| `reset()` | ❌ 不需要 | ✅ Episode开始 | ✅ Episode开始 |
| `step()` | ❌ 不需要 | ✅ 训练核心 | ✅ 决策循环 |
| `observe()` | ❌ 不需要 | ✅ 状态获取 | ✅ 状态描述 |
| `calculate_reward()` | ❌ 不需要 | ✅ 训练需要 | ❌ 不需要 |

**关键设计优势**：
- 向后兼容：传统算法无需修改即可运行
- 向前扩展：新增DRL/Agent算法只需实现RL接口
- 统一对比：所有算法通过相同的`schedule()`接口输出`ScheduleResult`，便于横向对比

---

## 16. 深度物理与硬件约束设计

### 16.1 热控约束（Thermal Constraint）

#### 问题背景
SAR卫星在聚束模式下峰值功耗可达数百瓦，远超过散热能力。即使电量充足，温度超限也会强制关机。需要在状态跟踪器中增加热量积分器，建立一阶RC热阻尼模型。

#### 热模型设计

```python
# simulator/thermal_model.py

@dataclass
class ThermalParameters:
    """卫星热控参数 - 一阶RC热阻尼模型"""

    thermal_capacity: float = 5000.0     # 热容 (J/K)
    thermal_resistance: float = 0.5      # 热阻 (K/W)
    ambient_temperature: float = 273.15  # 环境温度 (K)

    # 温度限制
    max_operating_temp: float = 333.15   # 60°C
    min_operating_temp: float = 253.15   # -20°C
    emergency_shutdown_temp: float = 343.15  # 70°C

    # 各模式的产热功率 (W)
    heat_generation: Dict[str, float] = None

    def __post_init__(self):
        if self.heat_generation is None:
            self.heat_generation = {
                'idle': 10.0,
                'slewing': 20.0,
                'imaging_stripmap': 80.0,
                'imaging_sliding_spotlight': 120.0,
                'imaging_spotlight': 200.0,
                'downlink': 50.0,
            }

    @property
    def time_constant(self) -> float:
        """热时间常数 τ = R * C (秒)"""
        return self.thermal_resistance * self.thermal_capacity


class ThermalIntegrator:
    """
    热量积分器 - 实现一阶RC热阻尼模型

    dT/dt = (P_in * R - (T - T_ambient)) / τ
    """

    def __init__(self, params: ThermalParameters, initial_temp: float = None):
        self.params = params
        self.temperature = initial_temp or params.ambient_temperature
        self.last_update_time: Optional[datetime] = None
        self.temperature_history: List[Tuple[datetime, float]] = []

    def update(self, current_time: datetime, activity: str) -> float:
        """更新温度状态"""
        if self.last_update_time is None:
            self.last_update_time = current_time
            return self.temperature

        dt = (current_time - self.last_update_time).total_seconds()
        power_in = self.params.heat_generation.get(activity, 10.0)

        # 一阶RC模型离散化（欧拉法）
        tau = self.params.time_constant
        r = self.params.thermal_resistance
        t_amb = self.params.ambient_temperature

        temperature_change = dt * (power_in * r - (self.temperature - t_amb)) / tau
        self.temperature += temperature_change

        self.temperature_history.append((current_time, self.temperature))
        self.last_update_time = current_time

        return self.temperature

    def predict_temperature(self, duration: float, activity: str) -> float:
        """
        预测执行某活动后的温度（用于调度决策）

        使用解析解: T(t) = T_ss + (T_0 - T_ss) * exp(-t/τ)
        其中 T_ss = T_ambient + P_in * R 是稳态温度
        """
        power_in = self.params.heat_generation.get(activity, 10.0)
        t_ss = self.params.ambient_temperature + power_in * self.params.thermal_resistance

        tau = self.params.time_constant
        temp_final = t_ss + (self.temperature - t_ss) * math.exp(-duration / tau)

        return temp_final

    def is_temperature_valid(self, activity: str, duration: float) -> Tuple[bool, float]:
        """检查是否可以执行某活动（不超出温度限制）"""
        predicted_temp = self.predict_temperature(duration, activity)
        safety_margin = 5.0  # K
        max_allowed = self.params.max_operating_temp - safety_margin

        return predicted_temp <= max_allowed, predicted_temp

    def get_cooldown_time(self, target_temp: float = None) -> float:
        """计算降温到目标温度所需时间（用于决定何时可再次开机）"""
        if target_temp is None:
            target_temp = self.params.ambient_temperature + 10.0

        if self.temperature <= target_temp:
            return 0.0

        tau = self.params.time_constant
        t_amb = self.params.ambient_temperature

        time_needed = -tau * math.log(
            (target_temp - t_amb) / (self.temperature - t_amb)
        )

        return max(0.0, time_needed)
```

#### 与SatelliteStateTracker集成

```python
class SatelliteStateTracker:
    """增强的状态跟踪器，集成热控"""

    def __init__(self, ...):
        # ... 原有初始化 ...
        self.thermal_integrator: Optional[ThermalIntegrator] = None

    def set_thermal_parameters(self, params: ThermalParameters,
                               initial_temp: float = None):
        """设置热控参数（SAR卫星需要）"""
        self.thermal_integrator = ThermalIntegrator(params, initial_temp)

    def check_thermal_feasibility(self, activity: str,
                                   duration: float) -> Tuple[bool, float]:
        """检查热控可行性"""
        if self.thermal_integrator is None:
            return True, 0.0

        return self.thermal_integrator.is_temperature_valid(activity, duration)

    def integrate(self, start_time, end_time, activities) -> ResourceState:
        """增强的积分器，包含温度演化"""
        # ... 原有电量和存储积分 ...

        # 新增：温度积分
        if self.thermal_integrator:
            for i in range(len(events) - 1):
                t_start = events[i][0]
                activity = events[i][1]
                self.thermal_integrator.update(t_start, activity.value)

        # ...
```

---

### 16.2 太阳规避角（Sun Exclusion Angle）

#### 问题背景
光学相机镜头极其脆弱，视轴必须避开太阳一定角度（通常30°以上），否则会烧毁焦平面探测器。

#### 太阳规避角计算

```python
# simulator/sun_exclusion_calculator.py

class SunExclusionCalculator:
    """太阳规避角计算器 - 确保光学卫星成像时视轴不指向太阳附近"""

    def __init__(self, exclusion_angle: float = 30.0):
        """
        Args:
            exclusion_angle: 规避角（度），默认30度
        """
        self.exclusion_angle = math.radians(exclusion_angle)

    def calculate_sun_position(self, t: datetime) -> Tuple[float, float, float]:
        """计算太阳在地心惯性系(ECI)中的位置"""
        # 儒略日计算
        jd = self._datetime_to_julian_day(t)
        n = (jd - 2451545.0) / 36525.0

        # 太阳几何平黄经
        L0 = (280.460 + 36000.770 * n) % 360.0
        if L0 < 0:
            L0 += 360.0

        # 太阳平近点角
        M = (357.529 + 35999.050 * n) % 360.0
        if M < 0:
            M += 360.0

        # 太阳黄经（考虑偏心率）
        M_rad = math.radians(M)
        C = (1.9146 - 0.004817 * n) * math.sin(M_rad) + \
            0.019993 * math.sin(2 * M_rad) + \
            0.000289 * math.sin(3 * M_rad)

        sun_lon = (L0 + C) % 360.0
        obliquity = math.radians(23.44)
        sun_lat = math.degrees(math.asin(math.sin(obliquity) *
                                          math.sin(math.radians(sun_lon))))

        # 转换为笛卡尔坐标
        AU = 149597870700  # 米
        sun_lon_rad = math.radians(sun_lon)
        sun_lat_rad = math.radians(sun_lat)

        x = AU * math.cos(sun_lat_rad) * math.cos(sun_lon_rad)
        y = AU * math.cos(sun_lat_rad) * math.sin(sun_lon_rad)
        z = AU * math.sin(sun_lat_rad)

        return (x, y, z)

    def check_sun_exclusion(self,
                           satellite_pos: Tuple[float, float, float],
                           target_pos: Tuple[float, float, float],
                           t: datetime) -> Tuple[bool, float]:
        """
        检查是否满足太阳规避角约束

        Returns:
            (是否满足约束, 实际夹角(度))
        """
        sun_pos = self.calculate_sun_position(t)

        # 计算视轴向量（卫星指向目标）
        los_vector = (
            target_pos[0] - satellite_pos[0],
            target_pos[1] - satellite_pos[1],
            target_pos[2] - satellite_pos[2]
        )
        los_norm = math.sqrt(sum(x**2 for x in los_vector))
        los_unit = tuple(x / los_norm for x in los_vector)

        # 计算太阳方向向量（卫星指向太阳）
        sun_vector = (
            sun_pos[0] - satellite_pos[0],
            sun_pos[1] - satellite_pos[1],
            sun_pos[2] - satellite_pos[2]
        )
        sun_norm = math.sqrt(sum(x**2 for x in sun_vector))
        sun_unit = tuple(x / sun_norm for x in sun_vector)

        # 计算两向量夹角
        dot_product = sum(los_unit[i] * sun_unit[i] for i in range(3))
        angle = math.acos(max(-1.0, min(1.0, dot_product)))

        is_valid = angle >= self.exclusion_angle

        return is_valid, math.degrees(angle)
```

#### 与可见性计算集成

```python
class VisibilityWindow:
    """增强的可见窗口，包含太阳规避信息"""

    def __init__(self, ...):
        # ... 原有属性 ...
        self.sun_exclusion_valid: bool = True
        self.sun_separation_angle: float = 90.0


class OpticalVisibilityCalculator:
    """光学卫星可见性计算器（考虑太阳规避）"""

    def __init__(self, sun_exclusion_angle: float = 30.0):
        self.sun_calculator = SunExclusionCalculator(sun_exclusion_angle)

    def compute_satellite_target_windows(self, satellite, target, start_time, end_time):
        """计算可见窗口，过滤掉太阳规避角不满足的"""
        base_windows = self._compute_geometric_windows(satellite, target, start_time, end_time)

        valid_windows = []
        for window in base_windows:
            sat_pos = satellite.get_position(window.start_time)
            target_pos = target.get_position(window.start_time)

            is_valid, angle = self.sun_calculator.check_sun_exclusion(
                sat_pos, target_pos, window.start_time
            )

            if is_valid:
                window.sun_exclusion_valid = True
                window.sun_separation_angle = angle
                valid_windows.append(window)

        return valid_windows
```

---

### 16.3 存储碎片化模型

#### 问题背景
星上固态存储存在文件系统开销，频繁的小文件写入和删除导致碎片化，实际可用容量低于理论值。

#### 碎片化存储模型

```python
# simulator/storage_model.py

@dataclass
class StorageBlock:
    """存储块（模拟文件系统块）"""
    start_address: int
    size: int
    is_allocated: bool
    file_id: Optional[str]
    created_time: datetime
    last_accessed: datetime


class FragmentedStorageModel:
    """碎片化的存储模型 - 模拟真实星上固态存储"""

    def __init__(self,
                 total_capacity: int,
                 block_size: int = 4096,
                 filesystem_overhead: float = 0.15,
                 metadata_size: int = 256):
        """
        Args:
            total_capacity: 存储总容量（字节）
            block_size: 文件系统块大小
            filesystem_overhead: 文件系统预留比例（默认15%）
            metadata_size: 每个文件的元数据大小
        """
        self.total_capacity = total_capacity
        self.block_size = block_size
        self.metadata_size = metadata_size

        # 有效容量 = 总容量 * (1 - 开销比例)
        self.effective_capacity = int(total_capacity * (1 - filesystem_overhead))

        # 初始化为一个大空闲块
        num_blocks = self.effective_capacity // block_size
        self.blocks: List[StorageBlock] = [
            StorageBlock(
                start_address=i * block_size,
                size=block_size,
                is_allocated=False,
                file_id=None,
                created_time=datetime.now(),
                last_accessed=datetime.now()
            )
            for i in range(num_blocks)
        ]

        # 文件索引
        self.files: Dict[str, List[int]] = {}

    @property
    def used_space(self) -> int:
        """已使用空间（包括元数据）"""
        used_blocks = sum(1 for block in self.blocks if block.is_allocated)
        metadata_overhead = len(self.files) * self.metadata_size
        return used_blocks * self.block_size + metadata_overhead

    @property
    def free_space(self) -> int:
        """空闲空间"""
        return self.effective_capacity - self.used_space

    @property
    def fragmentation_ratio(self) -> float:
        """
        碎片化率

        定义为空闲块不连续的比例
        """
        free_blocks = [b for b in self.blocks if not b.is_allocated]
        if not free_blocks:
            return 0.0

        fragmented_free = 0
        for i in range(len(free_blocks) - 1):
            if free_blocks[i].start_address + free_blocks[i].size != free_blocks[i + 1].start_address:
                fragmented_free += 1

        return fragmented_free / len(free_blocks)

    def allocate(self, file_id: str, size: int) -> Tuple[bool, int]:
        """
        分配存储空间 - 使用首次适应（First-Fit）算法

        Returns:
            (是否成功, 实际分配大小)
        """
        num_blocks_needed = (size + self.block_size - 1) // self.block_size
        total_size = num_blocks_needed * self.block_size + self.metadata_size

        if self.used_space + total_size > self.effective_capacity:
            return False, 0

        # 寻找连续的空闲块
        allocated_blocks = []
        consecutive_free = 0
        start_idx = -1

        for i, block in enumerate(self.blocks):
            if not block.is_allocated:
                if consecutive_free == 0:
                    start_idx = i
                consecutive_free += 1

                if consecutive_free >= num_blocks_needed:
                    allocated_blocks = list(range(start_idx, start_idx + num_blocks_needed))
                    break
            else:
                consecutive_free = 0
                start_idx = -1

        # 如果没有连续空间，尝试碎片分配
        if len(allocated_blocks) < num_blocks_needed:
            free_blocks = [i for i, b in enumerate(self.blocks) if not b.is_allocated]
            if len(free_blocks) >= num_blocks_needed:
                allocated_blocks = free_blocks[:num_blocks_needed]
            else:
                return False, 0

        # 标记为已分配
        now = datetime.now()
        for idx in allocated_blocks:
            self.blocks[idx].is_allocated = True
            self.blocks[idx].file_id = file_id
            self.blocks[idx].created_time = now
            self.blocks[idx].last_accessed = now

        self.files[file_id] = allocated_blocks

        actual_size = len(allocated_blocks) * self.block_size
        return True, actual_size

    def deallocate(self, file_id: str) -> bool:
        """释放存储空间"""
        if file_id not in self.files:
            return False

        for idx in self.files[file_id]:
            self.blocks[idx].is_allocated = False
            self.blocks[idx].file_id = None

        del self.files[file_id]
        return True

    def get_storage_status(self) -> Dict:
        """获取存储状态报告"""
        total_blocks = len(self.blocks)
        used_blocks = sum(1 for b in self.blocks if b.is_allocated)

        return {
            'total_capacity_gb': self.total_capacity / (1024**3),
            'effective_capacity_gb': self.effective_capacity / (1024**3),
            'used_space_gb': self.used_space / (1024**3),
            'free_space_gb': self.free_space / (1024**3),
            'utilization_ratio': self.used_space / self.effective_capacity,
            'fragmentation_ratio': self.fragmentation_ratio,
            'file_count': len(self.files),
            'total_blocks': total_blocks,
            'used_blocks': used_blocks,
            'free_blocks': total_blocks - used_blocks,
        }
```

#### 与SatelliteStateTracker集成

```python
class SatelliteStateTracker:
    """增强的状态跟踪器，集成碎片化存储"""

    def __init__(self, ..., storage_model: Optional[FragmentedStorageModel] = None):
        # ... 原有初始化 ...
        self.storage_model = storage_model

    def check_storage_feasibility(self, task_size: int) -> Tuple[bool, int]:
        """
        检查存储可行性（考虑碎片化）

        Returns:
            (是否可行, 实际可用空间)
        """
        if self.storage_model is None:
            # 简化模型
            return (self.current_storage + task_size <= self.max_storage,
                   self.max_storage - self.current_storage)

        # 尝试虚拟分配
        test_file_id = f"test_{datetime.now().timestamp()}"
        success, allocated = self.storage_model.allocate(test_file_id, task_size)

        if success:
            self.storage_model.deallocate(test_file_id)

        return success, self.storage_model.free_space
```

---

### 16.4 关键设计要点总结

| 约束类型 | 模型 | 关键参数 | 验证方式 |
|----------|------|----------|----------|
| **热控** | 一阶RC热阻尼 | 热容、热阻、产热功率 | 预测温度是否超阈值 |
| **太阳规避** | 几何夹角计算 | 规避角（默认30°） | 视轴-太阳夹角检查 |
| **存储碎片** | 文件系统块分配 | 块大小、开销比例 | 虚拟分配测试 |

**新增失败原因类型**（对应第14章）：
- `THERMAL_CONSTRAINT`: 温度超限
- `SUN_EXCLUSION_VIOLATION`: 太阳规避角不满足
- `STORAGE_FRAGMENTATION`: 存储碎片化导致无法分配

---

## 17. 通信链路与网络拓扑设计

### 17.1 问题背景

2026年的大规模星座必然包含以下通信能力：
- **星间链路（ISL）**：卫星间激光/微波链路，支持多跳数据回传
- **指令上行（Uplink）**：任务执行前必须将指令发送给卫星
- **中继星支持**：通过中继星（如天链）实现数据回传和指令上行

这将彻底改变数据回传用时（DDT）的计算逻辑。

### 17.2 架构设计

```
core/
├── network/
│   ├── isl_topology.py         # ISL网络拓扑
│   ├── isl_visibility.py       # ISL可见性计算
│   ├── network_router.py       # 网络路由算法
│   ├── uplink_scheduler.py     # 上行指令调度
│   └── relay_satellite.py      # 中继星支持
```

### 17.3 星间链路（ISL）设计

#### ISL可见性计算

```python
# core/network/isl_visibility.py

@dataclass
class ISLLink:
    """星间链路"""
    satellite_a_id: str
    satellite_b_id: str
    start_time: datetime
    end_time: datetime
    link_quality: float           # 链路质量 0-1
    max_data_rate: float          # 最大数据速率 (Mbps)
    distance: float               # 星间距离 (km)


class ISLVisibilityCalculator:
    """星间链路可见性计算器 - 支持激光链路和微波链路"""

    def __init__(self,
                 link_type: str = 'laser',
                 max_link_distance: float = 5000.0,
                 min_elevation_angle: float = 0.0):
        self.link_type = link_type
        self.max_link_distance = max_link_distance
        self.min_elevation_angle = min_elevation_angle

        # 链路参数
        if link_type == 'laser':
            self.max_data_rate = 10000.0  # 10 Gbps
            self.attenuation_factor = 0.1
        else:  # microwave
            self.max_data_rate = 1000.0   # 1 Gbps
            self.attenuation_factor = 0.5

    def compute_isl_windows(self,
                           satellites: List['Satellite'],
                           start_time: datetime,
                           end_time: datetime,
                           time_step: int = 60) -> Dict[Tuple[str, str], List[ISLLink]]:
        """计算所有卫星间的ISL可见窗口"""
        isl_windows = {}

        for i, sat_a in enumerate(satellites):
            for sat_b in satellites[i+1:]:
                windows = self._compute_pair_windows(
                    sat_a, sat_b, start_time, end_time, time_step
                )
                if windows:
                    key = (sat_a.id, sat_b.id)
                    isl_windows[key] = windows

        return isl_windows
```

#### 网络路由模块

```python
# core/network/network_router.py

@dataclass
class RoutePath:
    """路由路径"""
    source_satellite: str
    destination: str
    hops: List[str]            # 路径上的卫星序列
    total_latency: float       # 总延迟（秒）
    available_bandwidth: float # 可用带宽（Mbps）
    path_reliability: float    # 路径可靠性 0-1


class NetworkRouter:
    """卫星网络路由器 - 支持多跳数据回传的最优路径计算"""

    def __init__(self, isl_calculator: ISLVisibilityCalculator):
        self.isl_calculator = isl_calculator
        self.isl_windows: Dict[Tuple[str, str], List[ISLLink]] = {}
        self.ground_station_windows: Dict[Tuple[str, str], List[VisibilityWindow]] = {}

    def find_best_route(self,
                       source_satellite: str,
                       destination_ground_station: str,
                       data_size: float,
                       start_time: datetime,
                       priority: str = 'latency') -> Optional[RoutePath]:
        """
        寻找最优数据回传路径

        Args:
            source_satellite: 源卫星（数据所在卫星）
            destination_ground_station: 目标地面站
            data_size: 数据大小（GB）
            start_time: 开始传输时间
            priority: 优化优先级 ('latency', 'bandwidth', 'reliability')
        """
        # 构建当前网络拓扑
        topology = self.build_network_topology(start_time)

        if source_satellite not in topology:
            return None

        # 使用Dijkstra算法找最优路径
        if priority == 'latency':
            return self._dijkstra_latency(source_satellite,
                                         f"GS:{destination_ground_station}",
                                         topology, data_size, start_time)
        elif priority == 'bandwidth':
            return self._dijkstra_bandwidth(source_satellite,
                                           f"GS:{destination_ground_station}",
                                           topology, data_size, start_time)
        else:
            return self._dijkstra_reliability(source_satellite,
                                             f"GS:{destination_ground_station}",
                                             topology, data_size, start_time)

    def _dijkstra_latency(self, source: str, target: str, topology: Dict,
                         data_size: float, start_time: datetime) -> Optional[RoutePath]:
        """基于延迟的Dijkstra路由"""
        # 优先队列: (累计延迟, 当前节点, 路径)
        queue = [(0.0, source, [source])]
        visited = set()

        while queue:
            current_latency, current_node, path = heapq.heappop(queue)

            if current_node == target:
                return RoutePath(
                    source_satellite=source,
                    destination=target.replace("GS:", ""),
                    hops=path[:-1],
                    total_latency=current_latency,
                    available_bandwidth=self._calculate_path_bandwidth(path, start_time),
                    path_reliability=self._calculate_path_reliability(path, start_time)
                )

            if current_node in visited:
                continue

            visited.add(current_node)

            # 扩展邻居
            for neighbor, quality in topology.get(current_node, []):
                if neighbor not in visited:
                    link_latency = self._estimate_link_latency(
                        current_node, neighbor, data_size, quality
                    )
                    heapq.heappush(queue, (
                        current_latency + link_latency,
                        neighbor,
                        path + [neighbor]
                    ))

        return None
```

### 17.4 指令上行（Uplink）调度

```python
# core/network/uplink_scheduler.py

@dataclass
class UplinkWindow:
    """指令上行窗口"""
    satellite_id: str
    ground_station_id: str
    start_time: datetime
    end_time: datetime
    max_commands: int
    link_type: str  # 'direct', 'relay'


class UplinkScheduler:
    """指令上行调度器 - 确保任务执行前卫星已接收必要指令"""

    def __init__(self,
                 command_prep_time: int = 300,
                 command_execution_delay: int = 10):
        self.command_prep_time = command_prep_time
        self.command_execution_delay = command_execution_delay
        self.uplink_windows: Dict[str, List[UplinkWindow]] = {}

    def check_uplink_feasibility(self,
                                  satellite_id: str,
                                  task_start_time: datetime,
                                  command_complexity: str = 'standard') -> Tuple[bool, Optional[datetime]]:
        """
        检查任务开始前是否能完成指令上行

        Args:
            satellite_id: 卫星ID
            task_start_time: 任务开始时间
            command_complexity: 指令复杂度 ('simple', 'standard', 'complex')

        Returns:
            (是否可行, 最晚指令发送时间)
        """
        # 计算所需准备时间
        prep_times = {
            'simple': 60,
            'standard': 300,
            'complex': 900
        }
        required_prep = prep_times.get(command_complexity, 300)

        # 最晚指令到达卫星的时间
        latest_command_arrival = task_start_time - timedelta(
            seconds=self.command_execution_delay
        )

        # 最晚指令发送时间
        latest_uplink_time = latest_command_arrival - timedelta(seconds=required_prep)

        # 查找可用的上行窗口
        windows = self.uplink_windows.get(satellite_id, [])

        for window in windows:
            if window.end_time >= latest_uplink_time:
                if window.start_time <= latest_uplink_time:
                    return True, latest_uplink_time

        return False, None
```

### 17.5 中继星支持

```python
# core/network/relay_satellite.py

@dataclass
class RelaySatellite:
    """中继星（如天链）"""
    id: str
    name: str
    orbit: 'Orbit'
    uplink_capacity: float        # 上行容量（Mbps）
    downlink_capacity: float      # 下行容量（Mbps）
    coverage_zones: List[str]
    supported_satellite_types: List[str]


class RelayNetwork:
    """中继星网络 - 支持通过中继星进行数据回传和指令上行"""

    def __init__(self, relay_satellites: List[RelaySatellite]):
        self.relays = {relay.id: relay for relay in relay_satellites}
        self.relay_visibility: Dict[Tuple[str, str], List[VisibilityWindow]] = {}

    def can_relay_data(self,
                      source_satellite: str,
                      relay_id: str,
                      data_size: float,
                      start_time: datetime) -> Tuple[bool, float]:
        """
        检查是否可以通过中继星回传数据

        Returns:
            (是否可行, 传输延迟秒)
        """
        windows = self.relay_visibility.get((source_satellite, relay_id), [])

        for window in windows:
            if window.start_time <= start_time < window.end_time:
                relay = self.relays[relay_id]
                bandwidth = min(relay.uplink_capacity, relay.downlink_capacity)
                transfer_time = (data_size * 8000) / bandwidth

                if start_time + timedelta(seconds=transfer_time) <= window.end_time:
                    return True, transfer_time

        return False, float('inf')
```

### 17.6 增强的数据回传用时（DDT）计算

```python
# evaluation/metrics.py

class EnhancedMetricsCalculator:
    """增强的指标计算器 - 考虑ISL和中继星的DDT计算"""

    def calculate_ddt_with_network(self,
                                    task: 'Task',
                                    schedule: 'Schedule',
                                    network_router: NetworkRouter) -> float:
        """计算考虑网络拓扑的数据回传用时"""
        # 获取成像完成时间
        imaging_end = schedule.get_imaging_end_time(task.id)
        data_size = task.data_size
        source_sat = schedule.get_imaging_satellite(task.id)

        # 尝试直接下传
        direct_route = network_router.find_best_route(
            source_sat, task.ground_station, data_size, imaging_end, 'latency'
        )

        best_ddt = float('inf')

        if direct_route:
            downlink_end = imaging_end + timedelta(seconds=direct_route.total_latency)
            best_ddt = (downlink_end - task.start_time).total_seconds()

        # 尝试通过中继星
        for relay_id in self.available_relays:
            can_relay, relay_latency = self.relay_network.can_relay_data(
                source_sat, relay_id, data_size, imaging_end
            )

            if can_relay and relay_latency < best_ddt:
                best_ddt = relay_latency

        return best_ddt
```

### 17.7 数据库表扩展

```sql
-- 星间链路窗口
CREATE TABLE isl_windows (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    scenario_id INT NOT NULL COMMENT '场景ID',
    satellite_a_id VARCHAR(32) NOT NULL COMMENT '卫星A',
    satellite_b_id VARCHAR(32) NOT NULL COMMENT '卫星B',
    start_time TIMESTAMP NOT NULL COMMENT '窗口开始',
    end_time TIMESTAMP NOT NULL COMMENT '窗口结束',
    link_quality DECIMAL(3,2) COMMENT '链路质量 0-1',
    max_data_rate DECIMAL(10,2) COMMENT '最大数据速率(Mbps)',
    distance DECIMAL(10,2) COMMENT '星间距离(km)',
    FOREIGN KEY (scenario_id) REFERENCES scenarios(id) ON DELETE CASCADE,
    INDEX idx_satellites (satellite_a_id, satellite_b_id),
    INDEX idx_time (start_time, end_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='星间链路窗口表';

-- 数据回传路径
CREATE TABLE data_routing_paths (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '运行ID',
    task_id VARCHAR(32) NOT NULL COMMENT '任务ID',
    source_satellite VARCHAR(32) COMMENT '源卫星',
    destination_gs VARCHAR(32) COMMENT '目标地面站',
    route_hops JSON COMMENT '路径跳数 [sat1, sat2, ...]',
    total_latency DECIMAL(10,3) COMMENT '总延迟(秒)',
    used_relay BOOLEAN DEFAULT FALSE COMMENT '是否使用中继',
    relay_satellite_id VARCHAR(32) COMMENT '中继星ID',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    INDEX idx_run_task (run_id, task_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='数据回传路径表';

-- 指令上行记录
CREATE TABLE uplink_commands (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    run_id INT NOT NULL COMMENT '运行ID',
    satellite_id VARCHAR(32) NOT NULL COMMENT '卫星ID',
    command_type VARCHAR(64) COMMENT '指令类型',
    uplink_time TIMESTAMP COMMENT '实际上行时间',
    scheduled_task_id VARCHAR(32) COMMENT '对应的调度任务',
    link_type ENUM('direct', 'relay') COMMENT '上行链路类型',
    ground_station_id VARCHAR(32) COMMENT '地面站ID',
    relay_satellite_id VARCHAR(32) COMMENT '中继星ID',
    FOREIGN KEY (run_id) REFERENCES experiment_runs(id) ON DELETE CASCADE,
    INDEX idx_run_satellite (run_id, satellite_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='指令上行记录表';

-- 中继星配置
CREATE TABLE relay_satellites (
    id VARCHAR(32) PRIMARY KEY COMMENT '中继星ID',
    name VARCHAR(64) COMMENT '名称',
    orbit_type VARCHAR(32) COMMENT '轨道类型',
    longitude DECIMAL(9,6) COMMENT '定点经度',
    uplink_capacity DECIMAL(10,2) COMMENT '上行容量(Mbps)',
    downlink_capacity DECIMAL(10,2) COMMENT '下行容量(Mbps)',
    coverage_zones JSON COMMENT '覆盖区域列表'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='中继星配置表';
```

### 17.8 关键设计要点总结

| 功能模块 | 核心能力 | 关键技术 |
|----------|----------|----------|
| **ISL可见性** | 激光/微波链路计算 | 星间距离、仰角、链路质量 |
| **网络路由** | 多跳路径优化 | Dijkstra算法、延迟/带宽权衡 |
| **指令上行** | 任务前指令下发 | 窗口计算、延迟预留 |
| **中继星** | GEO中继支持 | 覆盖范围、容量规划 |

**新增失败原因类型**：
- `NO_ISL_PATH`: 无可用ISL路径
- `UPLINK_UNAVAILABLE`: 无指令上行窗口
- `RELAY_OVERLOAD`: 中继星容量超限

---

## 18. 混合存储架构设计

### 18.1 问题背景

`satellite_state_snapshots`（卫星状态快照）和 `convergence_data`（收敛曲线数据）在多次实验中会产生海量数据点：
- 单次实验：约100万条时序数据（50颗卫星 × 1次/分钟 × 24小时 + 10,000代 × 100个体）
- 100次实验：约1亿条数据

**MySQL的局限性**：
- 单表超过1000万条数据时性能急剧下降
- 时序数据写入是顺序IO，B+树索引不适合
- 需要定期归档或分表

### 18.2 混合存储架构

```
┌─────────────────────────────────────────────────────────────┐
│                    统一存储接口层                              │
│                    (StorageManager)                           │
├────────────────────┬────────────────────────────────────────┤
│   关系型数据        │   时序/过程数据                         │
│   (配置与元数据)    │   (高频采样数据)                        │
├────────────────────┼────────────────────────────────────────┤
│  MySQL (生产)      │  Parquet (推荐)                         │
│  SQLite (本地测试) │  HDF5 (备选)                            │
│                    │  Prometheus (可选监控)                   │
└────────────────────┴────────────────────────────────────────┘
```

### 18.3 存储抽象层

```python
# storage/storage_manager.py

class StorageBackend(Enum):
    """存储后端类型"""
    MYSQL = "mysql"
    SQLITE = "sqlite"
    PARQUET = "parquet"
    HDF5 = "hdf5"

@dataclass
class StorageConfig:
    """存储配置"""
    relational_backend: StorageBackend = StorageBackend.MYSQL
    timeseries_backend: StorageBackend = StorageBackend.PARQUET

    # 关系型数据库配置
    mysql_host: str = "localhost"
    mysql_port: int = 3306
    mysql_database: str = "satellite_mission"

    # SQLite配置（本地测试）
    sqlite_path: str = "./data/local.db"

    # 时序数据配置
    timeseries_base_path: str = "./data/timeseries"
    parquet_compression: str = "zstd"

class StorageManager:
    """统一存储管理器 - 协调关系型存储和时序存储"""

    def __init__(self, config: StorageConfig):
        self.config = config
        self.relational: RelationalStorage = self._create_relational_storage()
        self.timeseries: TimeSeriesStorage = self._create_timeseries_storage()

    def save_experiment_result(self, result: 'ExperimentResult') -> None:
        """
        保存实验结果（统一入口）

        关系型数据 -> MySQL/SQLite
        时序数据 -> Parquet/HDF5
        """
        # 1. 保存关系型数据（实验元数据）
        self.relational.execute("""
            INSERT INTO experiments (name, scenario_id, status)
            VALUES (%s, %s, %s)
        """, (result.name, result.scenario_id, 'completed'))

        experiment_id = self.relational.fetchone("SELECT LAST_INSERT_ID()")['LAST_INSERT_ID()']

        # 2. 保存时序数据（卫星状态快照）
        for satellite_id, snapshots_df in result.satellite_snapshots.items():
            self.timeseries.write_satellite_snapshots(
                experiment_id, satellite_id, snapshots_df
            )

        # 3. 保存收敛曲线数据
        if result.convergence_data is not None:
            self.timeseries.write_convergence_data(
                experiment_id, result.algorithm_name, result.convergence_data
            )
```

### 18.4 Parquet时序存储实现（推荐）

```python
# storage/parquet_storage.py

class ParquetTimeSeriesStorage(TimeSeriesStorage):
    """
    基于Parquet的时序存储

    优势：
    - 列式存储，压缩率高（5-10倍）
    - 与Pandas无缝集成
    - 支持谓词下推（高效查询）
    - 跨语言支持（Python/R/Spark）
    """

    def __init__(self, config: StorageConfig):
        self.config = config
        self.base_path = Path(config.timeseries_base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)

    def write_satellite_snapshots(self,
                                   run_id: int,
                                   satellite_id: str,
                                   snapshots: pd.DataFrame) -> str:
        """
        写入卫星状态快照

        按卫星分文件存储，便于并行读取
        """
        run_path = self._get_run_path(run_id)
        file_path = run_path / f"snapshots_{satellite_id}.parquet"

        # 优化数据类型以减少存储空间
        optimized_df = self._optimize_dataframe(snapshots)

        # 写入Parquet
        optimized_df.to_parquet(
            file_path,
            engine='pyarrow',
            compression=self.config.parquet_compression
        )

        return str(file_path)

    def read_satellite_snapshots(self,
                                  run_id: int,
                                  satellite_id: Optional[str] = None,
                                  start_time: Optional[datetime] = None,
                                  end_time: Optional[datetime] = None) -> pd.DataFrame:
        """
        读取卫星状态快照

        支持按时间和卫星过滤（利用Parquet的谓词下推）
        """
        run_path = self._get_run_path(run_id)

        if satellite_id:
            file_path = run_path / f"snapshots_{satellite_id}.parquet"
            if not file_path.exists():
                return pd.DataFrame()

            # 构建过滤条件
            filters = None
            if start_time and end_time:
                filters = [
                    ('timestamp', '>=', pd.Timestamp(start_time)),
                    ('timestamp', '<=', pd.Timestamp(end_time))
                ]

            return pd.read_parquet(file_path, filters=filters)
        else:
            # 读取所有卫星
            all_dfs = []
            for file_path in run_path.glob("snapshots_*.parquet"):
                all_dfs.append(pd.read_parquet(file_path))

            return pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()

    def _optimize_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        优化DataFrame的存储效率

        - 压缩float64到float32
        - 使用category类型
        - 优化int类型
        """
        df = df.copy()

        for col in df.columns:
            col_type = df[col].dtype

            # 优化浮点数
            if col_type == 'float64':
                df[col] = df[col].astype('float32')

            # 优化整数
            elif col_type == 'int64':
                if df[col].min() >= 0 and df[col].max() < 65535:
                    df[col] = df[col].astype('uint16')
                else:
                    df[col] = df[col].astype('int32')

        return df
```

### 18.5 SQLite本地测试支持

```python
# storage/sqlite_storage.py

class SQLiteStorage(RelationalStorage):
    """
    SQLite本地测试存储

    优势：
    - 零配置，开箱即用
    - 单文件，易于分享和版本控制
    - 适合本地开发和单元测试
    """

    def __init__(self, config: StorageConfig):
        self.config = config
        self.db_path = Path(config.sqlite_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = None

    def connect(self) -> None:
        """建立连接"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
        self.cursor = self.conn.cursor()

        # 启用外键约束
        self.cursor.execute("PRAGMA foreign_keys = ON")

        # 优化性能
        self.cursor.execute("PRAGMA journal_mode = WAL")
        self.cursor.execute("PRAGMA synchronous = NORMAL")

    def execute(self, sql: str, params: tuple = None) -> Any:
        """执行SQL"""
        # MySQL的%s占位符转换为SQLite的?
        sql = sql.replace('%s', '?')
        if params:
            return self.cursor.execute(sql, params)
        else:
            return self.cursor.execute(sql)

    def fetchone(self, sql: str, params: tuple = None) -> Optional[Dict]:
        """查询单条"""
        self.execute(sql, params)
        row = self.cursor.fetchone()
        return dict(row) if row else None

    def close(self) -> None:
        """关闭连接"""
        if self.conn:
            self.conn.close()
```

### 18.6 配置示例

```yaml
# config/storage.yaml

storage:
  # 关系型数据库配置
  relational:
    backend: sqlite  # 可选: mysql, sqlite

    mysql:
      host: localhost
      port: 3306
      database: satellite_mission
      user: root
      password: ${MYSQL_PASSWORD}

    sqlite:
      path: ./data/experiments.db

  # 时序数据存储配置
  timeseries:
    backend: parquet  # 可选: parquet, hdf5

    parquet:
      base_path: ./data/timeseries
      compression: zstd  # zstd, snappy, gzip

    hdf5:
      base_path: ./data/timeseries
      compression: gzip

  # 数据保留策略
  retention:
    keep_raw_timeseries: true
    archive_after_days: 30
    delete_after_days: 365
```

### 18.7 关键设计要点总结

| 数据类型 | 存储方案 | 优势 |
|----------|----------|------|
| **关系型数据** | MySQL (生产) / SQLite (本地) | 事务支持、易于查询 |
| **时序数据** | Parquet (推荐) | 列式存储、压缩率高 (5-10x)、Pandas友好 |
| **大文件** | HDF5 (备选) | 支持复杂数据结构、科学计算生态 |

**性能对比**：

| 存储方案 | 写入速度 | 查询速度 | 压缩率 | 适用场景 |
|----------|----------|----------|--------|----------|
| MySQL (时序) | 慢 | 慢 | 低 | ❌ 不推荐 |
| Parquet | 快 | 快 | 高 (5-10x) | ✅ 推荐 |
| HDF5 | 中等 | 中等 | 中等 | 科学计算 |
| CSV | 慢 | 慢 | 无 | ❌ 不推荐 |

### 18.8 更新后的数据库表清单

**关系型数据库（MySQL/SQLite）**：
- 配置层：satellites, ground_stations, antennas, targets, scenarios（5表）
- 场景实例层：scenario_satellites, scenario_targets, scenario_ground_stations（3表）
- 目标分解层：decomposition_configs, sub_targets（2表）
- 实验层：experiments, experiment_runs, algorithm_params（3表，移除convergence_data）
- 结果层：schedule_tasks, performance_metrics, task_sequences（3表）
- 状态层：constraint_violations（1表，移除satellite_state_snapshots）
- 网络层：isl_windows, data_routing_paths, uplink_commands, relay_satellites（4表）
- **总计：21表**

**时序存储（Parquet/HDF5）**：
- 卫星状态快照：snapshots_{satellite_id}.parquet
- 收敛曲线数据：convergence.parquet

---

## 19. 业务闭环与动态调度设计

### 19.1 问题背景

研究平台通常假设所有任务在T0时刻一次性输入并得到全局最优解（Offline Scheduling），但工业场景是实时流动的：
- **滚动时间窗与重调度**：应对突发高优紧急任务（如灾害响应）
- **卫星故障恢复**：某颗卫星突然故障时的计划修复
- **指令序列生成（SOE）**：调度的最终产物是卫星可执行的时间事件序列

### 19.2 架构设计

```
core/
├── dynamic_scheduler/
│   ├── event_driven_scheduler.py   # 事件驱动调度器
│   ├── rolling_horizon.py          # 滚动时间窗管理
│   ├── plan_repair.py              # 计划修复算法
│   └── disruption_analyzer.py      # 扰动分析器
└── telecommand/
    ├── soe_generator.py            # SOE序列生成器
    ├── telecommand_compiler.py     # 指令编译器
    └── guard_time_validator.py     # 保护时间验证

utils/
└── soe_exporter.py                 # SOE文件导出
```

### 19.3 事件驱动调度器

```python
# core/dynamic_scheduler/event_driven_scheduler.py

class EventType(Enum):
    """调度事件类型"""
    NEW_URGENT_TASK = auto()          # 新的紧急任务
    TASK_CANCELLED = auto()           # 任务取消
    SATELLITE_FAILURE = auto()        # 卫星故障
    RESOURCE_DEGRADATION = auto()     # 资源降级
    ROLLING_HORIZON_TRIGGER = auto()  # 滚动时间窗触发

@dataclass
class ScheduleEvent:
    """调度事件"""
    event_type: EventType
    timestamp: datetime
    priority: int                      # 1-10，10为最高
    description: str
    payload: Dict                      # 事件详细信息
    affected_satellites: List[str] = None
    affected_tasks: List[str] = None

class EventDrivenScheduler:
    """事件驱动调度器 - 响应实时事件，触发动态重调度"""

    def __init__(self, base_scheduler: BaseScheduler):
        self.base_scheduler = base_scheduler
        self.current_plan: Optional[ScheduleResult] = None
        self.event_queue: List[ScheduleEvent] = []
        self.plan_history: List[tuple] = []  # (timestamp, plan, events)

    def submit_event(self, event: ScheduleEvent) -> bool:
        """提交调度事件，高优先级事件立即触发重调度"""
        self.event_queue.append(event)
        self.event_queue.sort(key=lambda e: (-e.priority, e.timestamp))

        # 高优先级事件立即触发
        if event.priority >= 8:
            self.trigger_reschedule()
            return True
        return False

    def reschedule(self,
                   current_plan: ScheduleResult,
                   new_events: List[ScheduleEvent]) -> ScheduleResult:
        """
        重调度接口（核心方法）

        基于当前计划和新事件，进行局部修复而非全盘重算
        """
        # 1. 分析事件影响
        impact = self._analyze_impact(current_plan, new_events)

        # 2. 决定重调度策略
        if impact.severity == 'minor':
            return self._local_repair(current_plan, impact)
        elif impact.severity == 'moderate':
            return self._rolling_reoptimize(current_plan, impact)
        else:
            return self._global_reschedule(current_plan, impact)

    def _analyze_impact(self,
                        current_plan: ScheduleResult,
                        events: List[ScheduleEvent]) -> 'DisruptionImpact':
        """分析事件对当前计划的影响"""
        affected_satellites = set()
        affected_tasks = set()

        for event in events:
            if event.affected_satellites:
                affected_satellites.update(event.affected_satellites)
            if event.affected_tasks:
                affected_tasks.update(event.affected_tasks)

        # 判断严重程度
        total_tasks = len(current_plan.scheduled_tasks)
        affected_ratio = len(affected_tasks) / max(total_tasks, 1)

        if affected_ratio < 0.1 and len(affected_satellites) <= 1:
            severity = 'minor'
        elif affected_ratio < 0.3 and len(affected_satellites) <= 3:
            severity = 'moderate'
        else:
            severity = 'major'

        return DisruptionImpact(
            severity=severity,
            affected_satellites=list(affected_satellites),
            affected_tasks=list(affected_tasks)
        )

    def _local_repair(self,
                      current_plan: ScheduleResult,
                      impact: 'DisruptionImpact') -> ScheduleResult:
        """局部修复：只调整受影响的部分任务"""
        # 1. 移除受影响的任务
        repaired_plan = self._remove_affected_tasks(current_plan, impact.affected_tasks)

        # 2. 尝试重新调度这些任务
        for task_id in impact.affected_tasks:
            task = self._get_task_by_id(task_id)
            if task:
                success = self._insert_task_greedily(repaired_plan, task)
                if not success:
                    self._record_repair_failure(task_id, "Local repair failed")

        return repaired_plan

    def _rolling_reoptimize(self,
                           current_plan: ScheduleResult,
                           impact: 'DisruptionImpact') -> ScheduleResult:
        """滚动优化：在滚动时间窗内重新优化"""
        now = datetime.now()
        horizon_end = now + timedelta(hours=2)

        # 1. 冻结已执行或即将执行的任务（不可更改）
        frozen_tasks = self._get_frozen_tasks(current_plan, now + timedelta(minutes=5))

        # 2. 在滚动窗内重新调度
        window_tasks = self._get_tasks_in_window(current_plan, now, horizon_end)
        window_tasks = [t for t in window_tasks if t['task_id'] not in frozen_tasks]

        # 3. 移除窗内任务并重新优化
        partial_plan = self._remove_tasks(current_plan, [t['task_id'] for t in window_tasks])

        # 4. 对窗内任务进行局部优化
        for task in window_tasks:
            self._insert_task_optimized(partial_plan, task)

        return partial_plan
```

### 19.4 滚动时间窗管理

```python
# core/dynamic_scheduler/rolling_horizon.py

@dataclass
class RollingHorizonConfig:
    """滚动时间窗配置"""
    window_size: timedelta = timedelta(hours=2)      # 窗口大小
    shift_interval: timedelta = timedelta(minutes=15)  # 滚动间隔
    freeze_duration: timedelta = timedelta(minutes=5)  # 冻结时间
    optimization_method: str = 'fast_heuristic'  # 'fast_heuristic', 'metaheuristic'
    max_optimization_time: int = 30  # 秒

class RollingHorizonManager:
    """滚动时间窗管理器 - 周期性触发重优化"""

    def __init__(self, config: RollingHorizonConfig):
        self.config = config
        self.last_optimization_time: Optional[datetime] = None

    def should_trigger_optimization(self, current_time: datetime) -> bool:
        """检查是否应该触发优化"""
        if self.last_optimization_time is None:
            return True
        elapsed = current_time - self.last_optimization_time
        return elapsed >= self.config.shift_interval

    def get_optimization_window(self, current_time: datetime) -> tuple:
        """
        获取当前优化窗口

        Returns:
            (window_start, window_end, frozen_tasks)
        """
        freeze_until = current_time + self.config.freeze_duration
        window_start = freeze_until
        window_end = current_time + self.config.window_size

        return window_start, window_end, freeze_until
```

### 19.5 SOE (Sequence of Events) 生成器

```python
# core/telecommand/soe_generator.py

class SOEActionType(Enum):
    """SOE动作类型"""
    PAYLOAD_POWER_ON = "PAYLOAD_POWER_ON"
    PAYLOAD_WARMUP = "PAYLOAD_WARMUP"
    SLEW_START = "SLEW_START"
    SLEW_COMPLETE = "SLEW_COMPLETE"
    SHUTTER_OPEN = "SHUTTER_OPEN"
    IMAGING_START = "IMAGING_START"
    IMAGING_COMPLETE = "IMAGING_COMPLETE"
    SHUTTER_CLOSE = "SHUTTER_CLOSE"
    DOWNLINK_START = "DOWNLINK_START"
    DOWNLINK_COMPLETE = "DOWNLINK_COMPLETE"

@dataclass
class SOEEntry:
    """SOE条目"""
    timestamp: datetime
    action_type: SOEActionType
    satellite_id: str
    task_id: Optional[str]
    duration: Optional[timedelta]
    parameters: Dict
    guard_time_before: timedelta = timedelta(seconds=0)
    guard_time_after: timedelta = timedelta(seconds=0)

class SOEGenerator:
    """
    SOE (Sequence of Events) 生成器

    将调度计划转换为卫星可执行的时间事件序列
    例如：转码器开机 -> 预热 -> 姿态机动 -> 开快门 -> 关快门 -> 姿态恢复
    """

    # 动作模板配置
    ACTION_TEMPLATES = {
        'optical_imaging': [
            (timedelta(seconds=-300), SOEActionType.PAYLOAD_POWER_ON, timedelta(seconds=60)),
            (timedelta(seconds=-240), SOEActionType.PAYLOAD_WARMUP, timedelta(seconds=120)),
            (timedelta(seconds=-60), SOEActionType.SLEW_START, timedelta(seconds=55)),
            (timedelta(seconds=0), SOEActionType.SHUTTER_OPEN, timedelta(seconds=1)),
            (timedelta(seconds=0), SOEActionType.IMAGING_START, None),
        ],
        'sar_imaging': [
            (timedelta(seconds=-180), SOEActionType.PAYLOAD_POWER_ON, timedelta(seconds=60)),
            (timedelta(seconds=-120), SOEActionType.PAYLOAD_WARMUP, timedelta(seconds=90)),
            (timedelta(seconds=-30), SOEActionType.SLEW_START, timedelta(seconds=25)),
            (timedelta(seconds=0), SOEActionType.IMAGING_START, None),
        ],
    }

    # 保护时间配置
    GUARD_TIMES = {
        SOEActionType.PAYLOAD_POWER_ON: (timedelta(seconds=10), timedelta(seconds=5)),
        SOEActionType.SLEW_START: (timedelta(seconds=5), timedelta(seconds=5)),
        SOEActionType.SHUTTER_OPEN: (timedelta(seconds=2), timedelta(seconds=2)),
    }

    def generate_soe(self, schedule: ScheduleResult) -> List[SOEEntry]:
        """从调度计划生成SOE序列"""
        soe_entries = []

        for task in schedule.scheduled_tasks:
            task_soe = self._generate_task_soe(task)
            soe_entries.extend(task_soe)

        # 按时间排序
        soe_entries.sort(key=lambda e: e.timestamp)

        # 验证保护时间
        self._validate_guard_times(soe_entries)

        return soe_entries

    def _generate_task_soe(self, task: Dict) -> List[SOEEntry]:
        """为单个任务生成SOE"""
        entries = []
        task_type = self._determine_task_type(task)
        template = self.ACTION_TEMPLATES.get(task_type, [])

        imaging_start = task['imaging_start']
        imaging_end = task['imaging_end']
        imaging_duration = imaging_end - imaging_start

        for offset, action_type, duration in template:
            timestamp = imaging_start + offset
            actual_duration = duration if duration else imaging_duration

            guard_before, guard_after = self.GUARD_TIMES.get(
                action_type, (timedelta(0), timedelta(0))
            )

            entry = SOEEntry(
                timestamp=timestamp,
                action_type=action_type,
                satellite_id=task['satellite_id'],
                task_id=task['task_id'],
                duration=actual_duration,
                parameters={
                    'target_id': task.get('target_id'),
                    'imaging_mode': task.get('imaging_mode'),
                    'slew_angle': task.get('slew_angle'),
                },
                guard_time_before=guard_before,
                guard_time_after=guard_after
            )
            entries.append(entry)

        # 添加结束动作
        entries.extend(self._generate_completion_actions(task))

        return entries

    def _validate_guard_times(self, entries: List[SOEEntry]) -> bool:
        """验证保护时间是否合理"""
        violations = []

        for i, entry in enumerate(entries):
            if i > 0:
                prev_entry = entries[i - 1]
                min_interval = prev_entry.guard_time_after + entry.guard_time_before
                actual_interval = entry.timestamp - (
                    prev_entry.timestamp + (prev_entry.duration or timedelta(0))
                )

                if actual_interval < min_interval:
                    violations.append({
                        'entry_a': prev_entry,
                        'entry_b': entry,
                        'required_interval': min_interval,
                        'actual_interval': actual_interval
                    })

        if violations:
            raise GuardTimeViolationError(f"Found {len(violations)} guard time violations", violations)

        return True
```

### 19.6 指令编译器与保护时间验证

```python
# core/telecommand/telecommand_compiler.py

class TelecommandCompiler:
    """
    指令编译器

    将SOE条目编译为卫星可执行的工程级指令
    """

    def __init__(self, satellite_configs: Dict[str, Dict]):
        self.satellite_configs = satellite_configs

    def compile_soe(self, soe_entries: List[SOEEntry]) -> Dict[str, List[Dict]]:
        """
        编译SOE为各卫星的指令序列

        Returns:
            {satellite_id: [command1, command2, ...], ...}
        """
        satellite_commands = {}

        for entry in soe_entries:
            sat_id = entry.satellite_id
            if sat_id not in satellite_commands:
                satellite_commands[sat_id] = []

            command = self._compile_entry(entry, sat_id)
            if command:
                satellite_commands[sat_id].append(command)

        # 验证指令序列
        for sat_id, commands in satellite_commands.items():
            self._validate_command_sequence(sat_id, commands)

        return satellite_commands

    def export_to_file(self,
                      satellite_commands: Dict[str, List[Dict]],
                      output_dir: str,
                      format: str = 'json') -> List[str]:
        """
        导出指令序列到文件

        Args:
            satellite_commands: 各卫星的指令序列
            output_dir: 输出目录
            format: 输出格式 ('json', 'xml', 'ccsds')
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        exported_files = []

        for sat_id, commands in satellite_commands.items():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{sat_id}_commands_{timestamp}.{format}"
            filepath = output_path / filename

            if format == 'json':
                self._export_json(commands, filepath)
            elif format == 'xml':
                self._export_xml(commands, filepath)
            elif format == 'ccsds':
                self._export_ccsds(commands, filepath)

            exported_files.append(str(filepath))

        return exported_files

    def _export_json(self, commands: List[Dict], filepath: Path):
        """导出为JSON格式"""
        import json
        with open(filepath, 'w') as f:
            json.dump({
                'satellite_id': commands[0].get('satellite_id'),
                'generation_time': datetime.now().isoformat(),
                'command_count': len(commands),
                'commands': commands
            }, f, indent=2)


# core/telecommand/guard_time_validator.py

@dataclass
class GuardTimeRule:
    """保护时间规则"""
    action_a: SOEActionType
    action_b: SOEActionType
    min_interval: timedelta
    reason: str

class GuardTimeValidator:
    """保护时间验证器 - 验证动作之间的保护时间是否满足工程约束"""

    DEFAULT_RULES = [
        GuardTimeRule(
            SOEActionType.PAYLOAD_POWER_OFF,
            SOEActionType.PAYLOAD_POWER_ON,
            timedelta(seconds=60),
            "Power supply capacitor discharge time"
        ),
        GuardTimeRule(
            SOEActionType.SLEW_COMPLETE,
            SOEActionType.IMAGING_START,
            timedelta(seconds=5),
            "Attitude stabilization time"
        ),
        GuardTimeRule(
            SOEActionType.IMAGING_COMPLETE,
            SOEActionType.DOWNLINK_START,
            timedelta(seconds=10),
            "Data buffering and shutter closure time"
        ),
    ]

    def validate_soe(self, soe_entries: List[SOEEntry]) -> List[Dict]:
        """验证SOE序列的保护时间"""
        violations = []

        # 按卫星分组验证
        by_satellite = {}
        for entry in soe_entries:
            sat_id = entry.satellite_id
            if sat_id not in by_satellite:
                by_satellite[sat_id] = []
            by_satellite[sat_id].append(entry)

        for sat_id, entries in by_satellite.items():
            sorted_entries = sorted(entries, key=lambda e: e.timestamp)
            sat_violations = self._validate_sequence(sorted_entries)
            violations.extend(sat_violations)

        return violations

    def auto_fix(self, soe_entries: List[SOEEntry]) -> List[SOEEntry]:
        """自动修复保护时间违规"""
        violations = self.validate_soe(soe_entries)

        if not violations:
            return soe_entries

        fixed_entries = soe_entries.copy()

        for violation in violations:
            entry_b = violation['entry_b']
            required_delay = violation['required'] - violation['actual']

            # 延迟entry_b及其后续所有条目
            for entry in fixed_entries:
                if entry.timestamp >= entry_b.timestamp:
                    entry.timestamp += required_delay

        return fixed_entries
```

### 19.7 完整工作流集成

```python
# utils/soe_exporter.py

class SOEExporter:
    """SOE导出工具 - 完整的调度计划到SOE文件导出流程"""

    def __init__(self, config: Dict):
        self.soe_generator = SOEGenerator()
        self.telecommand_compiler = TelecommandCompiler(
            config.get('satellite_configs', {})
        )
        self.guard_validator = GuardTimeValidator()

    def export_schedule(self,
                       schedule: ScheduleResult,
                       output_dir: str,
                       validate: bool = True) -> Dict:
        """
        导出调度计划为SOE文件

        Returns:
            {
                'soe_entries': [...],
                'satellite_commands': {...},
                'exported_files': [...],
                'validation_result': {...}
            }
        """
        # 1. 生成SOE
        soe_entries = self.soe_generator.generate_soe(schedule)

        # 2. 验证保护时间
        validation_result = {'valid': True, 'violations': []}
        if validate:
            violations = self.guard_validator.validate_soe(soe_entries)
            if violations:
                validation_result['valid'] = False
                validation_result['violations'] = violations

                # 自动修复
                soe_entries = self.guard_validator.auto_fix(soe_entries)
                validation_result['auto_fixed'] = True

        # 3. 编译为卫星指令
        satellite_commands = self.telecommand_compiler.compile_soe(soe_entries)

        # 4. 导出到文件
        exported_files = self.telecommand_compiler.export_to_file(
            satellite_commands, output_dir, format='json'
        )

        return {
            'soe_entries': soe_entries,
            'satellite_commands': satellite_commands,
            'exported_files': exported_files,
            'validation_result': validation_result
        }
```

### 19.8 关键设计要点总结

| 功能模块 | 核心能力 | 关键特性 |
|----------|----------|----------|
| **事件驱动调度** | 实时响应突发事件 | 优先级队列、三级重调度策略 |
| **滚动时间窗** | 周期性局部优化 | 冻结机制、快速启发式 |
| **SOE生成** | 工程级指令序列 | 动作模板、保护时间验证 |
| **指令编译** | 多格式导出 | JSON/XML/CCSDS、自动修复 |

**新增失败原因类型**：
- `GUARD_TIME_VIOLATION`: 保护时间违规
- `COMMAND_SEQUENCE_ERROR`: 指令序列错误
- `DYNAMIC_RESCHEDULE_FAILED`: 动态重调度失败

---

**文档版本**: 1.9 (已更新)
**更新日期**: 2026-02-19
**更新内容**:
- 新增数据持久化与存储设计（第10章）
- 新增目标分解模块设计（第11章）
- 新增连续状态演化跟踪器设计（第12章）
- 新增性能优化：时间窗口缓存设计（第13章）
- 新增失败原因追踪设计（第14章）
- 新增强化学习/AI Agent接口设计（第15章）
- 新增深度物理与硬件约束设计（第16章）
- 新增通信链路与网络拓扑设计（第17章）
- 新增混合存储架构设计（第18章）
- 新增业务闭环与动态调度设计（第19章）
- 新增星载边缘计算设计（第20章）

---

## 20. 星载边缘计算（Edge Computing on Orbit）

### 20.1 设计背景与颠覆性

2026年工业界前沿实践表明，遥感卫星已普遍装备抗辐照AI芯片（如NVIDIA Jetson边缘计算平台）。这一能力的引入将**彻底颠覆**第17章的NetworkRouter逻辑：

**传统模式**：
- 5GB SAR原始图像 → 直接下传 → 地面处理
- 瓶颈：数传带宽受限、地面处理延迟高

**星载边缘计算模式**：
- 5GB SAR原始图像 → 星上AI处理（目标检测）→ 1KB特征文本（船只坐标、航向、型号）→ 下传
- 优势：数据压缩率99.99998%、端到端延迟从小时级降至分钟级

**新的多目标帕累托优化空间**：

| 维度 | 星上处理 | 原始数据下传 |
|------|----------|--------------|
| **能耗** | 高（AI推理耗电） | 低（仅存储） |
| **时间** | 长（在轨处理耗时） | 短（直接下传） |
| **带宽** | 极低（压缩后数据） | 极高（原始数据） |
| **存储** | 临时占用 | 持续占用至下传完成 |
| **精度** | 可能损失（AI模型局限） | 完整保留 |

### 20.2 在轨处理模型（OnboardProcessingModel）

```python
# core/processing/onboard_processing_model.py

from enum import Enum, auto
from dataclasses import dataclass
from typing import Optional, List, Dict
from datetime import datetime, timedelta


class AIAcceleratorType(Enum):
    """AI加速器类型"""
    NVIDIA_JETSON_AGX = auto()      # 抗辐照版本，32 TOPS
    NVIDIA_JETSON_ORIN = auto()     # 抗辐照版本，275 TOPS
    XILINX_VERSAL = auto()          # 自适应计算平台
    CUSTOM_FPGA = auto()            # 定制化FPGA方案


class ProcessingTaskType(Enum):
    """处理任务类型"""
    VESSEL_DETECTION = auto()       # 舰船检测
    VEHICLE_DETECTION = auto()      # 车辆检测
    CHANGE_DETECTION = auto()       # 变化检测
    CLOUD_DETECTION = auto()        # 云检测（光学）
    IMAGE_CLASSIFICATION = auto()   # 图像分类
    FEATURE_EXTRACTION = auto()     # 特征提取


@dataclass
class AIAcceleratorSpec:
    """AI加速器硬件规格"""
    accelerator_type: AIAcceleratorType
    compute_tops: float             # 算力（Tera Operations Per Second）
    power_consumption_w: float      # 功耗（W）
    power_idle_w: float             # 空闲功耗（W）
    memory_gb: float                #  onboard memory
    radiation_hardened: bool        # 是否抗辐照
    operational_temp_range: tuple   # 工作温度范围（℃）

    # 抗辐照特性
    tid_tolerance_krad: float       # 总电离剂量耐受（krad）
    see_immune: bool                # 单粒子效应免疫


@dataclass
class ProcessingTaskSpec:
    """处理任务规格"""
    task_type: ProcessingTaskType
    input_data_size_gb: float       # 输入数据大小（GB）
    output_data_size_kb: float      # 输出数据大小（KB）
    compute_requirement_tops: float # 计算需求（TOPS-seconds）
    min_confidence: float           # 最低置信度要求

    @property
    def compression_ratio(self) -> float:
        """数据压缩比"""
        return (self.input_data_size_gb * 1e6) / self.output_data_size_kb

    @property
    def processing_time_seconds(self, accelerator: AIAcceleratorSpec) -> float:
        """估算处理时间"""
        return self.compute_requirement_tops / accelerator.compute_tops


@dataclass
class ProcessingResult:
    """处理结果"""
    task_id: str
    success: bool
    detected_objects: List[Dict]    # 检测到的目标列表
    processing_time_seconds: float  # 实际处理耗时
    energy_consumption_wh: float    # 能耗（Wh）
    confidence_score: float         # 整体置信度
    output_data_size_kb: float      # 实际输出大小
    failure_reason: Optional[str]   # 失败原因（如有）
```

### 20.3 在轨处理管理器（OnboardProcessingManager）

```python
# scheduler/processing/onboard_processing_manager.py

from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import numpy as np


class ProcessingDecision(Enum):
    """处理决策类型"""
    PROCESS_ONBOARD = auto()        # 在轨处理
    DOWNLINK_RAW = auto()           # 原始数据下传
    HYBRID = auto()                 # 混合策略（先存储，后决策）


@dataclass
class SatelliteResourceState:
    """
    卫星资源状态（用于决策）

    注意：与第12章的 SatelliteState 枚举区分
    - SatelliteState: 卫星运行状态（IDLE/IMAGING/SLEWING等）
    - SatelliteResourceState: 卫星资源状态（电量/存储/热控等）
    """
    battery_soc: float              # 电池电量（0-1）
    storage_free_gb: float          # 剩余存储空间
    thermal_headroom_c: float       # 热余量（℃）
    ai_accelerator_idle: bool       # AI加速器是否空闲
    upcoming_windows: List[Dict]    # 即将到来的可见窗口


@dataclass
class DecisionContext:
    """决策上下文"""
    imaging_task: Dict              # 成像任务信息
    satellite_state: SatelliteResourceState  # 卫星资源状态
    mission_priority: int           # 任务优先级
    latency_requirement: timedelta  # 延迟要求
    accuracy_requirement: float     # 精度要求


class OnboardProcessingManager:
    """
    在轨处理管理器

    核心职责：
    1. 对每个成像任务决策：在轨处理 vs 原始数据下传
    2. 管理帕累托前沿存档
    3. 动态适应卫星状态变化
    4. 处理失败回退机制
    """

    def __init__(self,
                 accelerator_specs: Dict[str, AIAcceleratorSpec],
                 processing_specs: Dict[ProcessingTaskType, ProcessingTaskSpec]):
        self.accelerator_specs = accelerator_specs
        self.processing_specs = processing_specs
        self.decision_history: List[Dict] = []

        # 帕累托前沿存档
        self.pareto_archive: Dict[str, List[Dict]] = {}

    def make_processing_decision(
        self,
        context: DecisionContext
    ) -> Tuple[ProcessingDecision, Dict]:
        """
        做出处理决策

        Returns:
            (决策类型, 决策元数据)
        """
        sat_id = context.imaging_task['satellite_id']
        accelerator = self.accelerator_specs.get(sat_id)

        if not accelerator:
            # 卫星无AI芯片，只能下传原始数据
            return ProcessingDecision.DOWNLINK_RAW, {
                'reason': 'No AI accelerator onboard',
                'estimated_downlink_time': self._estimate_downlink_time(context)
            }

        task_type = self._infer_task_type(context.imaging_task)
        processing_spec = self.processing_specs.get(task_type)

        # 计算两种策略的代价
        onboard_cost = self._calculate_onboard_cost(context, accelerator, processing_spec)
        downlink_cost = self._calculate_downlink_cost(context)

        # 帕累托决策分析
        pareto_analysis = self._pareto_analysis(onboard_cost, downlink_cost)

        # 基于当前卫星状态动态调整
        adjusted_decision = self._apply_state_constraints(
            pareto_analysis, context.satellite_state
        )

        # 记录决策
        self._log_decision(context, adjusted_decision, onboard_cost, downlink_cost)

        return adjusted_decision['decision'], adjusted_decision['metadata']

    def _calculate_onboard_cost(
        self,
        context: DecisionContext,
        accelerator: AIAcceleratorSpec,
        processing_spec: ProcessingTaskType
    ) -> Dict:
        """计算在轨处理代价"""
        processing_time = processing_spec.processing_time_seconds(accelerator)
        energy_wh = (accelerator.power_consumption_w * processing_time) / 3600

        return {
            'energy_wh': energy_wh,
            'time_seconds': processing_time,
            'storage_gb': processing_spec.input_data_size_gb,  # 临时存储
            'bandwidth_kb': processing_spec.output_data_size_kb,
            'thermal_load_c': self._estimate_thermal_load(accelerator, processing_time),
            'confidence': processing_spec.min_confidence
        }

    def _calculate_downlink_cost(self, context: DecisionContext) -> Dict:
        """计算原始数据下传代价"""
        data_size_gb = context.imaging_task['data_size_gb']

        # 估算下传时间（基于平均带宽）
        avg_bandwidth_mbps = 450  # X波段典型值
        downlink_time_seconds = (data_size_gb * 8000) / avg_bandwidth_mbps

        return {
            'energy_wh': 50,  # 数传设备功耗估算
            'time_seconds': downlink_time_seconds,
            'storage_gb': data_size_gb,  # 持续占用直到下传完成
            'bandwidth_kb': data_size_gb * 1e6,
            'thermal_load_c': 5.0,
            'confidence': 1.0  # 原始数据无精度损失
        }

    def _pareto_analysis(
        self,
        onboard_cost: Dict,
        downlink_cost: Dict
    ) -> Dict:
        """
        帕累托分析：判断哪个方案在帕累托前沿上占优

        目标（最小化）：能耗、时间、存储占用、带宽占用、热负载
        """
        objectives = ['energy_wh', 'time_seconds', 'storage_gb', 'bandwidth_kb', 'thermal_load_c']

        onboard_vector = np.array([onboard_cost[o] for o in objectives])
        downlink_vector = np.array([downlink_cost[o] for o in objectives])

        # 归一化（使用对数压缩大范围差异）
        onboard_norm = np.log1p(onboard_vector)
        downlink_norm = np.log1p(downlink_vector)

        # 计算支配关系
        onboard_dominates = np.all(onboard_norm <= downlink_norm) and np.any(onboard_norm < downlink_norm)
        downlink_dominates = np.all(downlink_norm <= onboard_norm) and np.any(downlink_norm < onboard_norm)

        if onboard_dominates:
            decision = ProcessingDecision.PROCESS_ONBOARD
            dominance_factor = np.sum(downlink_norm - onboard_norm)
        elif downlink_dominates:
            decision = ProcessingDecision.DOWNLINK_RAW
            dominance_factor = np.sum(onboard_norm - downlink_norm)
        else:
            # 互不占优，进入权衡决策
            decision = self._trade_off_decision(onboard_cost, downlink_cost)
            dominance_factor = 0.0

        return {
            'decision': decision,
            'onboard_score': float(np.sum(onboard_norm)),
            'downlink_score': float(np.sum(downlink_norm)),
            'dominance_factor': float(dominance_factor),
            'metadata': {
                'onboard_cost': onboard_cost,
                'downlink_cost': downlink_cost
            }
        }

    def _trade_off_decision(
        self,
        onboard_cost: Dict,
        downlink_cost: Dict
    ) -> ProcessingDecision:
        """
        权衡决策：当两种方案互不占优时使用

        策略：基于数据压缩收益与能耗代价的比值
        """
        # 数据压缩收益
        compression_gain = downlink_cost['bandwidth_kb'] / onboard_cost['bandwidth_kb']

        # 能耗代价比
        energy_ratio = onboard_cost['energy_wh'] / downlink_cost['energy_wh']

        # 综合收益比
        efficiency_ratio = compression_gain / energy_ratio

        if efficiency_ratio > 100:  # 压缩收益显著大于能耗代价
            return ProcessingDecision.PROCESS_ONBOARD
        else:
            return ProcessingDecision.DOWNLINK_RAW

    def _apply_state_constraints(
        self,
        pareto_analysis: Dict,
        satellite_state: SatelliteResourceState
    ) -> Dict:
        """
        应用卫星状态约束

        根据实时状态动态调整决策
        """
        decision = pareto_analysis['decision']
        metadata = pareto_analysis['metadata']

        # 约束1：低电量强制下传原始数据（避免AI处理耗电）
        if satellite_state.battery_soc < 0.3:
            return {
                'decision': ProcessingDecision.DOWNLINK_RAW,
                'metadata': {
                    **metadata,
                    'override_reason': 'Low battery (SOC < 30%)',
                    'original_decision': decision
                }
            }

        # 约束2：热余量不足时避免AI处理
        if decision == ProcessingDecision.PROCESS_ONBOARD and satellite_state.thermal_headroom_c < 10:
            return {
                'decision': ProcessingDecision.DOWNLINK_RAW,
                'metadata': {
                    **metadata,
                    'override_reason': 'Insufficient thermal headroom',
                    'original_decision': decision
                }
            }

        # 约束3：AI加速器忙时排队或下传
        if decision == ProcessingDecision.PROCESS_ONBOARD and not satellite_state.ai_accelerator_idle:
            # 检查是否有即将到来的紧急任务
            urgent_coming = any(
                w['priority'] > 8 and w['time_to_window'] < timedelta(minutes=30)
                for w in satellite_state.upcoming_windows
            )

            if urgent_coming:
                return {
                    'decision': ProcessingDecision.DOWNLINK_RAW,
                    'metadata': {
                        **metadata,
                        'override_reason': 'AI accelerator busy + urgent task upcoming',
                        'original_decision': decision
                    }
                }

        # 约束4：存储紧张时优先处理（释放空间）
        if satellite_state.storage_free_gb < 10 and decision == ProcessingDecision.DOWNLINK_RAW:
            return {
                'decision': ProcessingDecision.PROCESS_ONBOARD,
                'metadata': {
                    **metadata,
                    'override_reason': 'Storage critically low, compress to free space',
                    'original_decision': decision
                }
            }

        return pareto_analysis

    def update_pareto_archive(
        self,
        scenario_id: str,
        decision_record: Dict
    ):
        """
        更新帕累托前沿存档

        用于离线分析和算法改进
        """
        if scenario_id not in self.pareto_archive:
            self.pareto_archive[scenario_id] = []

        self.pareto_archive[scenario_id].append({
            'timestamp': datetime.now(),
            'decision': decision_record['decision'].name,
            'objectives': decision_record['onboard_cost'] if decision_record['decision'] == ProcessingDecision.PROCESS_ONBOARD else decision_record['downlink_cost'],
            'satellite_state': decision_record.get('satellite_state')
        })
```

### 20.4 网络路由器增强（NetworkRouter V2）

```python
# core/network/network_router_v2.py

from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
from enum import Enum


class DataPayloadType(Enum):
    """数据载荷类型"""
    RAW_IMAGERY = auto()            # 原始影像
    COMPRESSED_FEATURES = auto()    # 压缩特征
    AI_MODEL_UPDATE = auto()        # AI模型更新
    TELEMETRY = auto()              # 遥测数据


@dataclass
class DataPacket:
    """数据包（支持混合载荷）"""
    packet_id: str
    source_satellite: str
    payload_type: DataPayloadType
    size_kb: float
    priority: int
    generation_time: datetime
    expiry_time: Optional[datetime]  # 数据过期时间
    processing_metadata: Optional[Dict]  # 在轨处理元数据


@dataclass
class RoutingPath:
    """路由路径（增强版）"""
    path_id: str
    hops: List[str]                  # 节点序列
    total_latency_seconds: float     # 总延迟
    available_bandwidth_kbps: float  # 可用带宽
    energy_cost_wh: float            # 能耗成本

    # 新增：数据压缩感知
    supports_compression: bool       # 路径是否支持压缩数据优先
    compression_benefit_factor: float # 压缩收益系数


class NetworkRouterV2:
    """
    网络路由器V2 - 支持边缘计算的数据流优化

    核心增强：
    1. 区分原始数据流与压缩特征流
    2. 压缩数据优先路由（利用小数据包优势）
    3. 混合路由策略：原始数据接力 vs 压缩结果直达
    """

    def __init__(self, isl_network: ISLNetwork, ground_stations: List[GroundStation]):
        self.isl_network = isl_network
        self.ground_stations = ground_stations
        self.processing_manager: Optional[OnboardProcessingManager] = None

    def set_processing_manager(self, manager: OnboardProcessingManager):
        """注入在轨处理管理器"""
        self.processing_manager = manager

    def route_imaging_data(
        self,
        imaging_task: Dict,
        satellite_state: SatelliteResourceState,
        network_state: NetworkState
    ) -> RoutingDecision:
        """
        路由成像数据（核心决策入口）

        整合在轨处理决策与网络路由决策
        """
        if not self.processing_manager:
            # 无在轨处理能力，使用传统路由
            return self._route_raw_data(imaging_task, network_state)

        # 获取处理决策
        decision_context = DecisionContext(
            imaging_task=imaging_task,
            satellite_state=satellite_state,
            mission_priority=imaging_task.get('priority', 5),
            latency_requirement=imaging_task.get('latency_requirement', timedelta(hours=4)),
            accuracy_requirement=imaging_task.get('accuracy_requirement', 0.95)
        )

        processing_decision, metadata = self.processing_manager.make_processing_decision(
            decision_context
        )

        # 根据处理决策选择路由策略
        if processing_decision == ProcessingDecision.PROCESS_ONBOARD:
            return self._route_compressed_data(imaging_task, metadata, network_state)
        else:
            return self._route_raw_data(imaging_task, network_state)

    def _route_compressed_data(
        self,
        imaging_task: Dict,
        processing_metadata: Dict,
        network_state: NetworkState
    ) -> RoutingDecision:
        """
        路由压缩数据（在轨处理后）

        策略：利用数据量极小的优势，选择最低延迟路径
        """
        source_sat = imaging_task['satellite_id']
        compressed_size_kb = processing_metadata['onboard_cost']['bandwidth_kb']

        # 压缩数据可以使用"机会路由" - 利用任何可用链路
        candidates = []

        for gs in self.ground_stations:
            # 检查直接下传窗口
            direct_windows = self._find_downlink_windows(source_sat, gs, network_state)

            for window in direct_windows:
                # 压缩数据可以在窗口间隙传输
                if window['duration_seconds'] > 1:  # 1KB数据只需要秒级窗口
                    candidates.append({
                        'type': 'direct',
                        'target': gs.station_id,
                        'window': window,
                        'latency': window['start_time'] - datetime.now(),
                        'bandwidth_required_kbps': 8  # 极低带宽需求
                    })

        # ISL快速中继选项
        isl_paths = self._find_fast_isl_paths(source_sat, compressed_size_kb)
        candidates.extend(isl_paths)

        # 选择最小延迟路径
        best = min(candidates, key=lambda x: x['latency'])

        return RoutingDecision(
            decision_type='compressed_fast_track',
            path=best,
            estimated_delivery=best['window']['start_time'] + timedelta(seconds=10),
            energy_cost=5.0,  # 极低能耗
            confidence=processing_metadata['onboard_cost']['confidence']
        )

    def _route_raw_data(
        self,
        imaging_task: Dict,
        network_state: NetworkState
    ) -> RoutingDecision:
        """
        路由原始数据（传统方式）

        调用第17章的原始NetworkRouter逻辑
        """
        # 委托给原始路由器
        from core.network.network_router import NetworkRouter
        legacy_router = NetworkRouter(self.isl_network, self.ground_stations)

        return legacy_router.route_data(
            DataPayload(
                source=imaging_task['satellite_id'],
                size_gb=imaging_task['data_size_gb'],
                priority=imaging_task.get('priority', 5)
            ),
            network_state
        )

    def _find_fast_isl_paths(
        self,
        source_sat: str,
        data_size_kb: float
    ) -> List[Dict]:
        """
        查找快速ISL中继路径（专门针对压缩数据优化）

        压缩数据可以利用间歇性ISL链路
        """
        paths = []

        # 获取所有中继卫星
        relay_sats = self.isl_network.get_relay_satellites()

        for relay in relay_sats:
            # 计算到中继卫星的ISL路径
            path = self.isl_network.find_path(source_sat, relay.satellite_id)

            if path and len(path.hops) <= 3:  # 限制跳数
                # 压缩数据可以在ISL链路间歇时缓存
                paths.append({
                    'type': 'isl_relay',
                    'target': relay.satellite_id,
                    'hops': path.hops,
                    'latency': path.total_latency_seconds,
                    'buffer_required_kb': data_size_kb,  # 极小缓存需求
                    'bandwidth_required_kbps': 1  # 可以容忍极低带宽
                })

        return paths

    def optimize_network_with_processing(
        self,
        schedule: ScheduleResult,
        network_state: NetworkState
    ) -> OptimizedNetworkSchedule:
        """
        联合优化：调度计划 + 网络路由 + 在轨处理

        这是核心创新点：将三个决策层整合为统一优化问题
        """
        optimized_tasks = []

        for task in schedule.tasks:
            # 获取成像任务数据
            imaging_task = {
                'satellite_id': task.satellite_id,
                'data_size_gb': task.data_size_gb,
                'priority': task.priority,
                'imaging_time': task.start_time
            }

            # 获取卫星状态（假设可以查询）
            satellite_state = self._get_satellite_state(task.satellite_id)

            # 综合决策
            routing_decision = self.route_imaging_data(
                imaging_task, satellite_state, network_state
            )

            optimized_tasks.append({
                **task.__dict__,
                'processing_decision': routing_decision.decision_type,
                'delivery_time': routing_decision.estimated_delivery,
                'energy_total': task.energy_cost + routing_decision.energy_cost
            })

        return OptimizedNetworkSchedule(
            tasks=optimized_tasks,
            total_compressed_data_kb=sum(
                t['compressed_size_kb'] for t in optimized_tasks
                if t['processing_decision'] == 'compressed_fast_track'
            ),
            total_raw_data_gb=sum(
                t['data_size_gb'] for t in optimized_tasks
                if t['processing_decision'] == 'raw_downlink'
            )
        )
```

### 20.5 任务调度器扩展

```python
# scheduler/integration/processing_aware_scheduler.py

from typing import Dict, List, Optional
from datetime import datetime, timedelta


class ProcessingAwareScheduler:
    """
    处理感知调度器

    将成像任务与在轨处理任务联合调度
    """

    def __init__(self,
                 base_scheduler: BaseScheduler,
                 processing_manager: OnboardProcessingManager,
                 satellite_pool: SatellitePool):
        self.base_scheduler = base_scheduler
        self.processing_manager = processing_manager
        self.satellite_pool = satellite_pool

    def schedule_with_processing(
        self,
        imaging_tasks: List[ImagingTask],
        time_horizon: timedelta
    ) -> ScheduleResult:
        """
        联合调度成像任务与处理任务

        关键约束：
        1. AI处理必须在成像完成后开始
        2. AI处理窗口不能与后续成像冲突
        3. 处理任务需要占用卫星存储
        4. 处理功耗影响后续任务电量
        """
        # 第一阶段：基础成像调度
        base_schedule = self.base_scheduler.schedule(imaging_tasks, time_horizon)

        # 第二阶段：为每个成像任务规划处理窗口
        processing_windows = self._plan_processing_windows(base_schedule)

        # 第三阶段：资源冲突消解
        resolved_schedule = self._resolve_processing_conflicts(
            base_schedule, processing_windows
        )

        return resolved_schedule

    def _plan_processing_windows(
        self,
        schedule: ScheduleResult
    ) -> Dict[str, List[ProcessingWindow]]:
        """
        规划处理窗口

        对每个成像任务，规划AI处理的时间窗口
        """
        windows = {}

        for task in schedule.tasks:
            sat_id = task.satellite_id

            if sat_id not in windows:
                windows[sat_id] = []

            # 获取处理时间需求
            processing_time = self._estimate_processing_time(task)

            # 处理窗口必须在成像完成后
            earliest_start = task.end_time + timedelta(seconds=30)

            # 查找下一个成像任务（作为处理窗口的结束边界）
            next_task = self._find_next_task(schedule, sat_id, task.end_time)
            latest_end = next_task.start_time if next_task else schedule.horizon_end

            available_duration = (latest_end - earliest_start).total_seconds()

            if available_duration >= processing_time:
                windows[sat_id].append(ProcessingWindow(
                    imaging_task_id=task.task_id,
                    satellite_id=sat_id,
                    earliest_start=earliest_start,
                    latest_end=latest_end,
                    required_duration_seconds=processing_time,
                    assigned_start=None,  # 待分配
                    assigned_end=None
                ))
            else:
                # 时间不足，标记为需下传原始数据
                task.force_raw_downlink = True

        return windows

    def _resolve_processing_conflicts(
        self,
        schedule: ScheduleResult,
        processing_windows: Dict[str, List[ProcessingWindow]]
    ) -> ScheduleResult:
        """
        消解处理窗口冲突

        考虑功耗、存储、热约束
        """
        for sat_id, windows in processing_windows.items():
            satellite = self.satellite_pool.get_satellite(sat_id)

            for window in sorted(windows, key=lambda w: w.priority, reverse=True):
                # 检查卫星状态是否支持处理
                state_at_window = satellite.predict_state(window.earliest_start)

                if not self._can_process(state_at_window, window):
                    # 无法处理，改为原始数据下传
                    self._convert_to_raw_downlink(schedule, window)
                    continue

                # 分配具体处理时间
                assigned_start = window.earliest_start
                assigned_end = assigned_start + timedelta(
                    seconds=window.required_duration_seconds
                )

                window.assigned_start = assigned_start
                window.assigned_end = assigned_end

                # 更新卫星状态预测
                satellite.simulate_processing(
                    start=assigned_start,
                    duration=window.required_duration_seconds
                )

        # 将处理窗口合并到调度结果
        schedule.processing_windows = processing_windows

        return schedule

    def _can_process(self, state: SatelliteState, window: ProcessingWindow) -> bool:
        """检查卫星状态是否支持处理"""
        return (
            state.battery_soc > 0.35 and  # 足够电量
            state.storage_free_gb > window.required_storage_gb and  # 足够存储
            state.thermal_headroom_c > 15 and  # 足够热余量
            not state.ai_accelerator_busy  # AI加速器空闲
        )
```

### 20.6 数据库Schema扩展

```sql
-- 20.6.1 AI加速器硬件配置表
CREATE TABLE ai_accelerators (
    id INT PRIMARY KEY AUTO_INCREMENT,
    satellite_id VARCHAR(50) NOT NULL,
    accelerator_type ENUM('NVIDIA_JETSON_AGX', 'NVIDIA_JETSON_ORIN', 'XILINX_VERSAL', 'CUSTOM_FPGA'),
    compute_tops FLOAT COMMENT '算力(TOPS)',
    power_consumption_w FLOAT COMMENT '工作功耗(W)',
    power_idle_w FLOAT COMMENT '空闲功耗(W)',
    memory_gb FLOAT COMMENT '板载内存(GB)',
    radiation_hardened BOOLEAN DEFAULT FALSE COMMENT '是否抗辐照',
    tid_tolerance_krad FLOAT COMMENT '总电离剂量耐受(krad)',
    operational_temp_min_c FLOAT COMMENT '最低工作温度',
    operational_temp_max_c FLOAT COMMENT '最高工作温度',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (satellite_id) REFERENCES satellites(id) ON DELETE CASCADE,
    INDEX idx_satellite (satellite_id)
) COMMENT='AI加速器硬件配置表';

-- 20.6.2 在轨处理任务表
CREATE TABLE onboard_processing_tasks (
    id INT PRIMARY KEY AUTO_INCREMENT,
    task_id VARCHAR(100) NOT NULL UNIQUE,
    imaging_task_id VARCHAR(100) NOT NULL COMMENT '关联的成像任务',
    satellite_id VARCHAR(50) NOT NULL,
    task_type ENUM('VESSEL_DETECTION', 'VEHICLE_DETECTION', 'CHANGE_DETECTION',
                   'CLOUD_DETECTION', 'IMAGE_CLASSIFICATION', 'FEATURE_EXTRACTION'),

    -- 输入输出规格
    input_data_size_gb FLOAT COMMENT '输入数据大小(GB)',
    output_data_size_kb FLOAT COMMENT '输出数据大小(KB)',
    compression_ratio FLOAT GENERATED ALWAYS AS ((input_data_size_gb * 1000000) / output_data_size_kb) STORED,

    -- 执行状态
    status ENUM('PENDING', 'SCHEDULED', 'RUNNING', 'COMPLETED', 'FAILED', 'FALLBACK_TO_RAW'),
    scheduled_start_time TIMESTAMP NULL,
    actual_start_time TIMESTAMP NULL,
    completion_time TIMESTAMP NULL,
    processing_duration_seconds FLOAT,

    -- 资源消耗
    energy_consumption_wh FLOAT COMMENT '能耗(Wh)',
    peak_temperature_c FLOAT COMMENT '峰值温度(℃)',

    -- 结果质量
    detected_objects_count INT COMMENT '检测到的目标数量',
    confidence_score FLOAT COMMENT '整体置信度',
    failure_reason VARCHAR(500),

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    FOREIGN KEY (imaging_task_id) REFERENCES tasks(id) ON DELETE CASCADE,
    FOREIGN KEY (satellite_id) REFERENCES satellites(id) ON DELETE CASCADE,
    INDEX idx_imaging_task (imaging_task_id),
    INDEX idx_satellite_status (satellite_id, status),
    INDEX idx_status (status)
) COMMENT='在轨处理任务记录表';

-- 20.6.3 处理决策记录表
CREATE TABLE processing_decisions (
    id INT PRIMARY KEY AUTO_INCREMENT,
    decision_id VARCHAR(100) NOT NULL UNIQUE,
    scenario_id VARCHAR(100) NOT NULL,
    imaging_task_id VARCHAR(100) NOT NULL,
    satellite_id VARCHAR(50) NOT NULL,

    -- 决策结果
    decision ENUM('PROCESS_ONBOARD', 'DOWNLINK_RAW', 'HYBRID'),
    decision_reason VARCHAR(500) COMMENT '决策原因',
    was_overridden BOOLEAN DEFAULT FALSE COMMENT '是否被状态约束覆盖',
    override_reason VARCHAR(500),

    -- 决策时的卫星状态
    battery_soc_at_decision FLOAT,
    storage_free_gb_at_decision FLOAT,
    thermal_headroom_c_at_decision FLOAT,
    ai_accelerator_idle_at_decision BOOLEAN,

    -- 代价分析
    onboard_energy_wh FLOAT COMMENT '在轨处理能耗估算',
    onboard_time_seconds FLOAT COMMENT '在轨处理时间估算',
    downlink_energy_wh FLOAT COMMENT '下传能耗估算',
    downlink_time_seconds FLOAT COMMENT '下传时间估算',

    -- 帕累托分析
    onboard_pareto_score FLOAT,
    downlink_pareto_score FLOAT,
    dominance_factor FLOAT,

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY (imaging_task_id) REFERENCES tasks(id) ON DELETE CASCADE,
    FOREIGN KEY (satellite_id) REFERENCES satellites(id) ON DELETE CASCADE,
    INDEX idx_scenario (scenario_id),
    INDEX idx_imaging_task (imaging_task_id),
    INDEX idx_decision (decision)
) COMMENT='处理决策记录表（用于离线分析）';

-- 20.6.4 帕累托前沿存档表
CREATE TABLE pareto_frontiers (
    id INT PRIMARY KEY AUTO_INCREMENT,
    archive_id VARCHAR(100) NOT NULL,
    scenario_id VARCHAR(100) NOT NULL,
    generation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- 帕累托点
    solution_index INT COMMENT '解的索引',
    objective_energy FLOAT COMMENT '目标：能耗',
    objective_time FLOAT COMMENT '目标：时间',
    objective_storage FLOAT COMMENT '目标：存储',
    objective_bandwidth FLOAT COMMENT '目标：带宽',

    -- 解的详情
    decision_distribution JSON COMMENT '决策分布统计',
    avg_confidence FLOAT COMMENT '平均置信度',

    FOREIGN KEY (scenario_id) REFERENCES scenarios(id) ON DELETE CASCADE,
    INDEX idx_scenario (scenario_id),
    INDEX idx_archive (archive_id)
) COMMENT='帕累托前沿存档表';

-- 20.6.5 处理策略配置表
CREATE TABLE processing_strategies (
    id INT PRIMARY KEY AUTO_INCREMENT,
    strategy_name VARCHAR(100) NOT NULL UNIQUE,
    strategy_type ENUM('ENERGY_PRIORITY', 'TIME_PRIORITY', 'BALANCED', 'CUSTOM'),

    -- 权重配置
    weight_energy FLOAT DEFAULT 0.2 COMMENT '能耗权重',
    weight_time FLOAT DEFAULT 0.2 COMMENT '时间权重',
    weight_storage FLOAT DEFAULT 0.2 COMMENT '存储权重',
    weight_bandwidth FLOAT DEFAULT 0.2 COMMENT '带宽权重',
    weight_thermal FLOAT DEFAULT 0.2 COMMENT '热负载权重',

    -- 阈值配置
    min_battery_soc_threshold FLOAT DEFAULT 0.3 COMMENT '最低电量阈值',
    min_thermal_headroom_threshold FLOAT DEFAULT 10.0 COMMENT '最低热余量阈值',
    compression_benefit_threshold FLOAT DEFAULT 100.0 COMMENT '压缩收益阈值',

    -- 约束
    force_onboard_when_storage_low_gb FLOAT DEFAULT 10.0 COMMENT '存储低于此值强制在轨处理',
    disable_onboard_when_battery_low_soc FLOAT DEFAULT 0.25 COMMENT '电量低于此值禁用在轨处理',

    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    INDEX idx_type (strategy_type),
    INDEX idx_active (is_active)
) COMMENT='在轨处理策略配置表';

-- 初始化默认策略
INSERT INTO processing_strategies
(strategy_name, strategy_type, weight_energy, weight_time, weight_storage, weight_bandwidth, weight_thermal)
VALUES
('balanced_default', 'BALANCED', 0.2, 0.2, 0.2, 0.2, 0.2),
('energy_priority', 'ENERGY_PRIORITY', 0.4, 0.1, 0.2, 0.2, 0.1),
('time_priority', 'TIME_PRIORITY', 0.1, 0.4, 0.1, 0.3, 0.1);
```

### 20.7 评估指标扩展

```python
# evaluation/metrics/edge_computing_metrics.py

from typing import Dict, List
from dataclasses import dataclass
import numpy as np


@dataclass
class EdgeComputingMetrics:
    """星载边缘计算专项评估指标"""

    # 数据压缩指标
    total_raw_data_gb: float
    total_compressed_data_kb: float
    avg_compression_ratio: float
    max_compression_ratio: float

    # 延迟指标
    avg_end_to_end_latency_minutes: float
    compressed_data_latency_minutes: float
    raw_data_latency_minutes: float
    latency_reduction_percent: float

    # 能耗指标
    total_energy_onboard_wh: float
    total_energy_downlink_wh: float
    energy_efficiency_kb_per_wh: float

    # 网络效率指标
    bandwidth_savings_percent: float
    avg_ground_station_utilization: float
    isl_usage_count: int

    # 质量指标
    avg_confidence_score: float
    detection_accuracy_vs_ground_truth: float
    false_positive_rate: float

    # 决策统计
    onboard_decision_count: int
    downlink_decision_count: int
    override_count: int


class EdgeComputingEvaluator:
    """边缘计算评估器"""

    def __init__(self, decisions: List[Dict], results: List[Dict]):
        self.decisions = decisions
        self.results = results

    def calculate_metrics(self) -> EdgeComputingMetrics:
        """计算完整指标集"""

        # 数据压缩
        raw_sizes = [d['input_data_size_gb'] for d in self.results]
        compressed_sizes = [d['output_data_size_kb'] for d in self.results if d['compressed']]

        compression_ratios = [
            (raw * 1e6) / comp for raw, comp in zip(raw_sizes, compressed_sizes)
        ]

        # 延迟对比
        onboard_latencies = [r['delivery_time'] for r in self.results if r['onboard_processed']]
        raw_latencies = [r['delivery_time'] for r in self.results if not r['onboard_processed']]

        avg_onboard_latency = np.mean(onboard_latencies) if onboard_latencies else 0
        avg_raw_latency = np.mean(raw_latencies) if raw_latencies else 0
        latency_reduction = ((avg_raw_latency - avg_onboard_latency) / avg_raw_latency * 100) if avg_raw_latency > 0 else 0

        # 决策统计
        onboard_count = sum(1 for d in self.decisions if d['decision'] == 'PROCESS_ONBOARD')
        downlink_count = sum(1 for d in self.decisions if d['decision'] == 'DOWNLINK_RAW')
        override_count = sum(1 for d in self.decisions if d.get('was_overridden'))

        return EdgeComputingMetrics(
            total_raw_data_gb=sum(raw_sizes),
            total_compressed_data_kb=sum(compressed_sizes),
            avg_compression_ratio=np.mean(compression_ratios) if compression_ratios else 0,
            max_compression_ratio=max(compression_ratios) if compression_ratios else 0,

            avg_end_to_end_latency_minutes=np.mean(onboard_latencies + raw_latencies),
            compressed_data_latency_minutes=avg_onboard_latency,
            raw_data_latency_minutes=avg_raw_latency,
            latency_reduction_percent=latency_reduction,

            total_energy_onboard_wh=sum(r['energy_wh'] for r in self.results if r['onboard_processed']),
            total_energy_downlink_wh=sum(r['energy_wh'] for r in self.results if not r['onboard_processed']),
            energy_efficiency_kb_per_wh=sum(compressed_sizes) / sum(r['energy_wh'] for r in self.results),

            bandwidth_savings_percent=(1 - sum(compressed_sizes)/(sum(raw_sizes)*1e6)) * 100,
            avg_ground_station_utilization=0.0,  # 需要网络数据
            isl_usage_count=sum(1 for r in self.results if r.get('used_isl')),

            avg_confidence_score=np.mean([r['confidence'] for r in self.results]),
            detection_accuracy_vs_ground_truth=0.0,  # 需要地面真值
            false_positive_rate=0.0,  # 需要地面真值

            onboard_decision_count=onboard_count,
            downlink_decision_count=downlink_count,
            override_count=override_count
        )

    def generate_pareto_report(self) -> Dict:
        """生成帕累托分析报表"""

        # 提取所有决策的目标向量
        objectives = []
        for d in self.decisions:
            obj = [
                d['onboard_cost']['energy_wh'] if d['decision'] == 'PROCESS_ONBOARD' else d['downlink_cost']['energy_wh'],
                d['onboard_cost']['time_seconds'] if d['decision'] == 'PROCESS_ONBOARD' else d['downlink_cost']['time_seconds'],
                d['onboard_cost']['bandwidth_kb'] if d['decision'] == 'PROCESS_ONBOARD' else d['downlink_cost']['bandwidth_kb']
            ]
            objectives.append(obj)

        # 计算帕累托前沿
        pareto_front = self._compute_pareto_front(objectives)

        return {
            'pareto_front_size': len(pareto_front),
            'pareto_front_points': pareto_front,
            'hypervolume_indicator': self._calculate_hypervolume(pareto_front),
            'sparsity': self._calculate_sparsity(pareto_front)
        }

    def _compute_pareto_front(self, objectives: List[List[float]]) -> List[List[float]]:
        """计算帕累托前沿"""
        pareto = []
        for i, obj in enumerate(objectives):
            dominated = False
            for j, other in enumerate(objectives):
                if i != j:
                    if all(o <= obj[k] for k, o in enumerate(other)) and any(o < obj[k] for k, o in enumerate(other)):
                        dominated = True
                        break
            if not dominated:
                pareto.append(obj)
        return pareto
```

### 20.8 帕累托优化框架

```python
# optimization/pareto/multi_objective_optimizer.py

from typing import List, Dict, Callable
from dataclasses import dataclass
import numpy as np
from scipy.optimize import minimize


@dataclass
class ObjectiveFunction:
    """目标函数定义"""
    name: str
    minimize: bool  # True=最小化, False=最大化
    weight: float   # 权重
    constraint_fn: Callable  # 约束函数


class ParetoOptimizer:
    """
    多目标帕累托优化器

    用于求解在轨处理 vs 原始下传的帕累托最优解集
    """

    def __init__(self, objectives: List[ObjectiveFunction]):
        self.objectives = objectives
        self.archive: List[Dict] = []

    def optimize(
        self,
        imaging_tasks: List[Dict],
        satellites: List[Dict],
        population_size: int = 100,
        generations: int = 50
    ) -> List[Dict]:
        """
        使用NSGA-II风格的多目标优化

        决策变量：每个成像任务是否在轨处理（0/1）
        """
        n_tasks = len(imaging_tasks)

        # 初始化种群
        population = np.random.randint(0, 2, size=(population_size, n_tasks))

        for gen in range(generations):
            # 评估种群
            fitness = self._evaluate_population(population, imaging_tasks, satellites)

            # 非支配排序
            fronts = self._non_dominated_sort(fitness)

            # 选择、交叉、变异
            offspring = self._genetic_operators(population, fronts)

            # 合并并精英保留
            combined = np.vstack([population, offspring])
            combined_fitness = self._evaluate_population(combined, imaging_tasks, satellites)
            combined_fronts = self._non_dominated_sort(combined_fitness)

            # 选择下一代
            population = self._select_next_generation(
                combined, combined_fitness, combined_fronts, population_size
            )

        # 返回最终帕累托前沿
        final_fitness = self._evaluate_population(population, imaging_tasks, satellites)
        final_fronts = self._non_dominated_sort(final_fitness)

        pareto_solutions = []
        for idx in final_fronts[0]:  # 第0层是帕累托前沿
            pareto_solutions.append({
                'decision_vector': population[idx].tolist(),
                'objectives': final_fitness[idx].tolist(),
                'decoded': self._decode_solution(population[idx], imaging_tasks)
            })

        return pareto_solutions

    def _evaluate_population(
        self,
        population: np.ndarray,
        tasks: List[Dict],
        satellites: List[Dict]
    ) -> np.ndarray:
        """评估种群的目标函数值"""
        fitness = np.zeros((len(population), len(self.objectives)))

        for i, solution in enumerate(population):
            fitness[i] = self._evaluate_solution(solution, tasks, satellites)

        return fitness

    def _evaluate_solution(
        self,
        solution: np.ndarray,
        tasks: List[Dict],
        satellites: List[Dict]
    ) -> np.ndarray:
        """
        评估单个解

        solution[i] = 1 表示第i个任务在轨处理
        solution[i] = 0 表示第i个任务原始下传
        """
        total_energy = 0
        total_time = 0
        total_bandwidth = 0
        total_storage = 0

        for i, (task, decision) in enumerate(zip(tasks, solution)):
            sat = next(s for s in satellites if s['id'] == task['satellite_id'])

            if decision == 1 and sat.get('has_ai_accelerator'):
                # 在轨处理代价
                total_energy += sat['ai_power_wh']
                total_time += sat['ai_processing_time']
                total_bandwidth += task['compressed_size_kb']
                total_storage += task['data_size_gb']  # 临时存储
            else:
                # 原始下传代价
                total_energy += sat['downlink_power_wh']
                total_time += task['downlink_time']
                total_bandwidth += task['data_size_gb'] * 1e6
                total_storage += task['data_size_gb']

        return np.array([total_energy, total_time, total_bandwidth, total_storage])

    def _non_dominated_sort(self, fitness: np.ndarray) -> List[List[int]]:
        """非支配排序（NSGA-II核心）"""
        n = len(fitness)
        domination_count = [0] * n
        dominated_solutions = [[] for _ in range(n)]
        fronts = [[]]

        for i in range(n):
            for j in range(i + 1, n):
                if self._dominates(fitness[i], fitness[j]):
                    dominated_solutions[i].append(j)
                    domination_count[j] += 1
                elif self._dominates(fitness[j], fitness[i]):
                    dominated_solutions[j].append(i)
                    domination_count[i] += 1

            if domination_count[i] == 0:
                fronts[0].append(i)

        i = 0
        while len(fronts[i]) > 0:
            next_front = []
            for p in fronts[i]:
                for q in dominated_solutions[p]:
                    domination_count[q] -= 1
                    if domination_count[q] == 0:
                        next_front.append(q)
            i += 1
            fronts.append(next_front)

        return fronts[:-1]  # 去除空前沿

    def _dominates(self, a: np.ndarray, b: np.ndarray) -> bool:
        """判断a是否支配b"""
        return np.all(a <= b) and np.any(a < b)
```

### 20.9 关键设计要点总结

| 功能模块 | 核心能力 | 关键特性 |
|----------|----------|----------|
| **在轨处理模型** | AI芯片硬件建模 | 算力、功耗、抗辐照特性 |
| **处理管理器** | 智能决策引擎 | 帕累托优化、状态自适应 |
| **网络路由器V2** | 压缩数据优先路由 | 机会路由、极低带宽需求 |
| **处理感知调度器** | 成像+处理联合调度 | 时序约束、资源冲突消解 |
| **帕累托优化器** | 多目标解集求解 | NSGA-II风格遗传算法 |

**新增失败原因类型**：
- `AI_PROCESSOR_UNAVAILABLE`: AI处理器不可用
- `INSUFFICIENT_COMPUTE`: 算力不足
- `PROCESSING_TIMEOUT`: 处理超时
- `MODEL_INFERENCE_FAILED`: 模型推理失败
- `COMPRESSION_QUALITY_UNACCEPTABLE`: 压缩质量不可接受

**数据压缩能力示例**：
- SAR舰船检测：5GB原始图像 → 1KB特征文本（坐标、航向、型号）
- 光学车辆检测：2GB原始图像 → 5KB特征文本（位置、类型、速度）
- 云检测（光学）：500MB图像 → 100KB云掩膜

**帕累托前沿可视化**（概念）：
```
能耗(Wh) ↑
        │
   高   │    × 原始数据下传（高能耗、高带宽）
        │   ╱
        │  ╱  帕累托前沿
        │ ╱
   低   │╱    ● 星上处理（低带宽、中等能耗）
        └────────────────→ 带宽(KB)
             低              高
```

---

**文档版本**: 2.1 (已更新)
**更新日期**: 2026-02-19
**更新内容**:
- 新增数据持久化与存储设计（第10章）
- 新增目标分解模块设计（第11章）
- 新增连续状态演化跟踪器设计（第12章）
- 新增性能优化：时间窗口缓存设计（第13章）
- 新增失败原因追踪设计（第14章）
- 新增强化学习/AI Agent接口设计（第15章）
- 新增深度物理与硬件约束设计（第16章）
- 新增通信链路与网络拓扑设计（第17章）
- 新增混合存储架构设计（第18章）
- 新增业务闭环与动态调度设计（第19章）
- 新增星载边缘计算设计（第20章）
- 新增架构衔接修复与核心流程图（第21章）

---

## 21. 架构衔接修复与核心流程图

### 21.1 架构衔接问题修复总结

在完成20章详细设计后，通过系统性审查发现了7个关键衔接问题，并已修复：

#### 修复问题清单

| 序号 | 问题类型 | 问题描述 | 修复方案 | 涉及章节 |
|------|----------|----------|----------|----------|
| 1 | 命名冲突 | `SatelliteState` 重复定义（枚举 vs 数据类） | 第20章重命名为 `SatelliteResourceState` | 第12章、第20章 |
| 2 | 接口不兼容 | `NetworkRouter` 返回 `RoutePath`，`NetworkRouterV2` 返回 `RoutingDecision` | 创建 `NetworkRouterAdapter` 统一接口 | 第17章、第20章 |
| 3 | 缺失连接 | `SatelliteStateTracker` 未集成热控 | 增加 `thermal_integrator` 可选参数 | 第12章、第16章 |
| 4 | 重复定义 | 存储模型多处定义（基础版 vs 碎片版） | 使用策略模式统一 | 第12章、第16章 |
| 5 | 扩展缺失 | RL `Action` 类不支持处理决策 | 扩展 `Action` 字段 | 第15章、第20章 |
| 6 | 时序断裂 | SOE验证未考虑热控恢复时间 | 增加热控规则到 `GuardTimeValidator` | 第16章、第19章 |
| 7 | 数据库关联 | 失败记录时序存储策略未定义 | 明确归属关系型存储 | 第14章、第18章 |

#### 命名对照表

为避免混淆，以下是易混淆术语的对照说明：

| 术语 | 所属模块 | 含义 | 数据类型 |
|------|----------|------|----------|
| `SatelliteState` | 第12章 | 卫星运行状态（IDLE/IMAGING等） | Enum |
| `SatelliteResourceState` | 第20章 | 卫星资源状态（电量/存储/热） | Dataclass |
| `TaskStatus` | 第10章 | 任务执行状态（PENDING/RUNNING等） | Enum |
| `ProcessingDecision` | 第20章 | 处理决策类型（ONBOARD/DOWNLINK） | Enum |

### 21.2 核心流程图

#### 流程图1：主调度流程（Main Scheduling Flow）

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                              主调度流程图                                          │
└─────────────────────────────────────────────────────────────────────────────────┘

[开始]
   │
   ▼
┌─────────────────────┐
│ 1. 加载场景配置      │  ← 第2章：YAML/JSON配置
│    (Scenario.load)  │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 2. 目标分解          │  ← 第11章：网格化/条带化
│ (TargetDecomposer)  │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 3. 预计算可见窗口    │  ← 第13章：VisibilityWindowCache
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 4. 初始化状态跟踪器  │  ← 第12章：电量/存储/热控
│ (StateTracker)      │     第16章：ThermalIntegrator集成
└──────────┬──────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────┐
│ 5. 执行调度算法                                          │
│   ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐   │
│   │ Greedy  │  │   GA    │  │  PPO    │  │ LLM     │   │ ← 第3/4/15章
│   │ EDD/SPT │  │ SA/ACO  │  │  SAC    │  │ Agent   │   │
│   └────┬────┘  └────┬────┘  └────┬────┘  └────┬────┘   │
└────────┼────────────┼────────────┼────────────┼─────────┘
         │            │            │            │
         └────────────┴────────────┴────────────┘
                          │
                          ▼
┌─────────────────────┐
│ 6. 资源约束验证      │  ← 第12章：integrate()验证
│   - 电量积分         │     第16章：热控约束
│   - 存储积分         │     第14章：失败追踪
│   - 热控积分         │
└──────────┬──────────┘
           │
           ▼
     ┌──────────┐
     │ 验证通过? │────否────→ [记录失败原因] ← 第14章
     └────┬─────┘               │
          │是                   │
          ▼                    │
┌─────────────────────┐       │
│ 7. 生成调度结果      │       │
│ (ScheduleResult)    │◄──────┘
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 8. 在轨处理决策      │  ← 第20章：帕累托优化
│ (ProcessingManager) │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 9. 网络路由优化      │  ← 第17章：ISL/中继/直传
│ (NetworkRouter)     │     第20章：压缩数据快速通道
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 10. 持久化存储       │  ← 第10章：MySQL/SQLite
│    第18章：Parquet   │     关系型+时序混合存储
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ 11. 可视化输出       │  ← 第6章：甘特图/星下点/热力图
└──────────┬──────────┘
           │
           ▼
         [结束]
```

#### 流程图2：动态重调度流程（Dynamic Rescheduling Flow）

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           动态重调度流程图                                         │
└─────────────────────────────────────────────────────────────────────────────────┘

                            [外部事件触发]
                                  │
           ┌──────────────────────┼──────────────────────┐
           │                      │                      │
           ▼                      ▼                      ▼
    ┌─────────────┐      ┌─────────────┐      ┌─────────────┐
    │ 紧急任务到达 │      │ 卫星故障    │      │ 地面站失效   │
    │ (priority≥8)│      │ (部分载荷)  │      │ (天线故障)   │
    └──────┬──────┘      └──────┬──────┘      └──────┬──────┘
           │                      │                      │
           └──────────────────────┼──────────────────────┘
                                  │
                                  ▼
                    ┌─────────────────────────┐
                    │ EventDrivenScheduler    │
                    │   .submit_event()       │
                    └────────────┬────────────┘
                                 │
                                 ▼
                    ┌─────────────────────────┐
                    │  事件优先级评估         │
                    │  - 立即触发 (priority≥8)│
                    │  - 延迟处理 (priority<8)│
                    └────────────┬────────────┘
                                 │
               ┌─────────────────┴─────────────────┐
               │                                   │
               ▼                                   ▼
        ┌─────────────┐                   ┌─────────────┐
        │ 立即重调度   │                   │ 加入事件队列 │
        │ reschedule()│                   │ (等待触发)   │
        └──────┬──────┘                   └─────────────┘
               │
               ▼
        ┌─────────────────────────┐
        │ 影响范围评估            │
        │ - 统计受影响任务数      │
        └────────────┬────────────┘
                     │
        ┌────────────┼────────────┐
        │            │            │
        ▼            ▼            ▼
   ┌─────────┐  ┌─────────┐  ┌─────────┐
   │ minor   │  │moderate │  │ major   │
   │(<10%)   │  │(10-30%) │  │(>30%)   │
   └────┬────┘  └────┬────┘  └────┬────┘
        │            │            │
        ▼            ▼            ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ 局部修复      │ │ 滚动优化      │ │ 全局重调度    │
│ _local_repair│ │_rolling_      │ │_global_      │
│              │ │ reoptimize() │ │ reschedule() │
│ 修复时间:    │ │              │ │              │
│ <1s          │ │ 修复时间:    │ │ 修复时间:    │
│              │ │ 1-30s        │ │ >30s         │
└──────┬───────┘ └──────┬───────┘ └──────┬───────┘
       │                │                │
       └────────────────┼────────────────┘
                        │
                        ▼
            ┌─────────────────────┐
            │ 计划修复与验证       │
            │ - 资源约束重新检查   │
            │ - 冲突消解          │
            └──────────┬──────────┘
                       │
                       ▼
            ┌─────────────────────┐
            │ SOE重新生成         │  ← 第19章
            │ (SOEGenerator)      │
            └──────────┬──────────┘
                       │
                       ▼
            ┌─────────────────────┐
            │ 保护时间验证        │
            │(GuardTimeValidator) │  ← 第19章
            │ +热控规则(新增)     │  ← 第16章集成
            └──────────┬──────────┘
                       │
            ┌──────────┴──────────┐
            │                     │
            ▼                     ▼
    ┌───────────────┐     ┌───────────────┐
    │ 验证通过      │     │ 验证失败      │
    │               │     │               │
    │ 指令编译导出  │     │ 自动修复      │
    │ (SOE导出)     │     │ (延迟时间)    │
    └───────────────┘     │ 重新验证      │
                          └───────┬───────┘
                                  │
                                  └────────→ [重新验证]
```

#### 流程图3：星载边缘计算决策流程（Onboard Processing Decision Flow）

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                      星载边缘计算决策流程图                                        │
└─────────────────────────────────────────────────────────────────────────────────┘

[成像任务完成]
      │
      ▼
┌─────────────────────────────────────────┐
│ 构建决策上下文 (DecisionContext)        │
│  ├─ imaging_task: 任务信息              │
│  ├─ satellite_state: 卫星资源状态       │ ← SatelliteResourceState
│  ├─ mission_priority: 任务优先级        │
│  ├─ latency_requirement: 延迟要求       │
│  └─ accuracy_requirement: 精度要求      │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│ OnboardProcessingManager                │
│   .make_processing_decision()           │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│ 步骤1: 计算在轨处理代价                 │
│  ├─ energy_wh: AI推理能耗               │
│  ├─ time_seconds: 处理时间              │
│  ├─ storage_gb: 临时存储占用            │
│  ├─ bandwidth_kb: 输出数据大小          │ ← 5GB→1KB压缩
│  └─ thermal_load_c: 热负载              │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│ 步骤2: 计算原始下传代价                 │
│  ├─ energy_wh: 数传设备能耗             │
│  ├─ time_seconds: 下传时间              │ ← 5GB/450Mbps≈89s
│  ├─ storage_gb: 持续存储占用            │
│  ├─ bandwidth_kb: 原始数据大小          │ ← 5GB=5,000,000KB
│  └─ thermal_load_c: 热负载              │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│ 步骤3: 帕累托分析 (5目标)               │
│                                         │
│  目标向量: [能耗, 时间, 存储, 带宽, 热] │
│                                         │
│  判断:                                  │
│  ├─ 在轨处理支配原始下传? → PROCESS_ONBOARD│
│  ├─ 原始下传支配在轨处理? → DOWNLINK_RAW   │
│  └─ 互不占优? → 进入权衡决策            │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│ 步骤4: 状态约束覆盖检查                 │
│  (可能覆盖帕累托决策)                   │
│                                         │
│  IF battery_soc < 0.3:                  │
│     → 强制 DOWNLINK_RAW (低电量保护)    │
│                                         │
│  ELIF thermal_headroom_c < 10°C:        │
│     → 强制 DOWNLINK_RAW (过热保护)      │
│                                         │
│  ELIF ai_accelerator_busy:              │
│     → 检查紧急任务 → 可能DOWNLINK_RAW   │
│                                         │
│  ELIF storage_free_gb < 10GB:           │
│     → 强制 PROCESS_ONBOARD (释放空间)   │
│                                         │
│  ELSE:                                  │
│     → 维持帕累托决策                    │
└───────────────┬─────────────────────────┘
                │
      ┌─────────┴─────────┐
      │                   │
      ▼                   ▼
┌─────────────┐    ┌─────────────┐
│ PROCESS_    │    │ DOWNLINK_   │
│ ONBOARD     │    │ RAW         │
└──────┬──────┘    └──────┬──────┘
       │                  │
       ▼                  ▼
┌───────────────────────────────┐  ┌───────────────────────────────┐
│ NetworkRouterV2               │  │ NetworkRouter                 │
│ .route_compressed_data()      │  │ .route_raw_data()             │
│                               │  │                               │
│ 策略:                         │  │ 策略:                         │
│ • 压缩数据快速通道            │  │ • ISL多跳                     │
│ • 机会路由(秒级窗口)          │  │ • 中继星接力                  │
│ • 极低带宽需求                │  │ • 直接下传                    │
│                               │  │                               │
│ 延迟: 分钟级                  │  │ 延迟: 小时级                  │
└───────────────┬───────────────┘  └───────────────┬───────────────┘
                │                                  │
                └────────────────┬─────────────────┘
                                 │
                                 ▼
                    ┌─────────────────────┐
                    │ 数据到达地面站       │
                    │ DDT计算完成         │
                    └─────────────────────┘
```

#### 流程图4：数据下传路由流程（Data Downlink Routing Flow）

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                          数据下传路由流程图                                        │
└─────────────────────────────────────────────────────────────────────────────────┘

[成像任务完成/处理完成]
         │
         ▼
┌─────────────────────────────────────────┐
│ 数据类型判断                            │
│ ┌─────────────┐      ┌─────────────┐   │
│ │ 原始数据    │      │ 压缩特征    │   │
│ │ (5GB)       │      │ (1KB)       │   │
│ └──────┬──────┘      └──────┬──────┘   │
└────────┼────────────────────┼──────────┘
         │                    │
         ▼                    ▼
┌─────────────────┐  ┌─────────────────────┐
│ 大带宽需求      │  │ 小带宽需求          │
│ >100Mbps        │  │ <10Kbps             │
│ 长持续时间      │  │ 短持续时间          │
│ 分钟级          │  │ 秒级                │
└───────┬─────────┘  └──────────┬──────────┘
        │                       │
        ▼                       ▼
┌─────────────────────────────────────────┐
│         NetworkRouterV2                 │
│   (统一接口，内部根据数据类型路由)        │
└─────────────────┬───────────────────────┘
                  │
     ┌────────────┼────────────┐
     │            │            │
     ▼            ▼            ▼
┌─────────┐ ┌─────────┐ ┌─────────┐
│ ISL多跳  │ │ 中继星   │ │ 直接下传 │
│ 路径     │ │ 接力     │ │ 窗口     │
└────┬────┘ └────┬────┘ └────┬────┘
     │           │           │
     └───────────┼───────────┘
                 │
                 ▼
┌─────────────────────────────────────────┐
│ 路径选择策略                            │
│                                         │
│ 对于原始数据:                           │
│ • 最小化传输时间 → 最大带宽路径         │
│ • 考虑ISL跳数限制                       │
│                                         │
│ 对于压缩数据:                           │
│ • 最小化端到端延迟 → 最快到达路径       │
│ • 可利用间歇性链路                      │
│ • 机会路由策略                          │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│ RelayNetwork 可用性检查                 │
│ (中继星检查: 电量/存储/链路状态)        │
└───────────────┬─────────────────────────┘
                │
       ┌────────┴────────┐
       │                 │
       ▼                 ▼
┌─────────────┐   ┌─────────────┐
│ 中继可用     │   │ 中继不可用   │
└──────┬──────┘   └──────┬──────┘
       │                 │
       ▼                 ▼
┌─────────────────┐ ┌─────────────────┐
│ 计算中继路径     │ │ 寻找ISL多跳路径  │
│ • 源星→中继星    │ │ 或等待直传窗口   │
│ • 中继星→地面站  │ │                 │
└────────┬────────┘ └────────┬────────┘
         │                   │
         └─────────┬─────────┘
                   │
                   ▼
┌─────────────────────────────────────────┐
│ UplinkScheduler 数传窗口调度            │
│ • 检查地面站可见性                      │
│ • 避免天线冲突                          │
│ • 优先级排队                            │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│ 生成路由决策 (RoutingDecision)          │
│ ├─ path: 路径节点序列                   │
│ ├─ estimated_delivery: 预计交付时间     │
│ ├─ energy_cost: 能耗成本                │
│ └─ bandwidth_utilization: 带宽利用率    │
└─────────────────────────────────────────┘
```

#### 流程图5：模块依赖与数据流图（Module Dependency & Data Flow）

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                       模块依赖与数据流架构图                                       │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────────┐
│                                   用户接口层                                      │
│  ┌───────────────┐  ┌───────────────┐  ┌───────────────┐  ┌───────────────┐    │
│  │ Experiment    │  │ Scenario      │  │ Visualization │  │ SOEExporter   │    │
│  │ Runner        │  │ Loader        │  │ (第6章)       │  │ (第19章)      │    │
│  │ (第4章)       │  │ (第2章)       │  │               │  │               │    │
│  └───────┬───────┘  └───────┬───────┘  └───────┬───────┘  └───────┬───────┘    │
└──────────┼──────────────────┼──────────────────┼──────────────────┼────────────┘
           │                  │                  │                  │
           └──────────────────┼──────────────────┘                  │
                              │                                     │
                              ▼                                     ▼
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                   算法调度层                                      │
│                                                                                  │
│  ┌───────────────────────────────────────────────────────────────────────────┐  │
│  │                        BaseScheduler (第3章)                              │  │
│  │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────────────────┐ │  │
│  │  │ Greedy  │ │ GA/SA   │ │ ACO/PSO │ │ PPO/SAC │ │ LLM Agent           │ │  │
│  │  │ EDD/SPT │ │ Tabu    │ │ (元启发)│ │ (DRL)   │ │ (第15章)            │ │  │
│  │  │(第4章)  │ │(第4章)  │ │(第4章)  │ │(第15章) │ │                     │ │  │
│  │  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ └──────────┬──────────┘ │  │
│  │       └───────────┴───────────┴───────────┘                  │            │  │
│  │                           │                                  │            │  │
│  │                    ┌──────┴──────┐                           │            │  │
│  │                    ▼             ▼                           │            │  │
│  │           ┌──────────────┐ ┌──────────────┐                  │            │  │
│  │           │ ScheduleResult│ │ RLScheduler │◄─────────────────┘            │  │
│  │           │ (第3/14/20章) │ │ Interface   │                              │  │
│  │           └──────┬───────┘ └──────────────┘                              │  │
│  └──────────────────┼───────────────────────────────────────────────────────┘  │
│                     │                                                            │
│  ┌──────────────────┼───────────────────────────────────────────────────────┐  │
│  │          EventDrivenScheduler (第19章)                                    │  │
│  │  ┌────────────────┐ ┌────────────────┐ ┌────────────────┐                │  │
│  │  │ Local Repair   │ │ Rolling Horizon│ │ Global         │                │  │
│  │  │ (<10% tasks)   │ │ (10-30% tasks) │ │ Reschedule     │                │  │
│  │  │ _local_repair()│ │ _rolling_       │ │ (>30% tasks)   │                │  │
│  │  │                │ │ reoptimize()   │ │ _global_       │                │  │
│  │  │                │ │                │ │ reschedule()   │                │  │
│  │  └────────────────┘ └────────────────┘ └────────────────┘                │  │
│  └──────────────────┬───────────────────────────────────────────────────────┘  │
└─────────────────────┼──────────────────────────────────────────────────────────┘
                      │
                      ▼
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                   核心引擎层                                      │
│                                                                                  │
│  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ ┌────────────────┐ │
│  │ Visibility      │ │ StateTracker    │ │ Network         │ │ Decomposer     │ │
│  │ WindowCache     │ │ (第12章)        │ │ Router          │ │ (第11章)       │ │
│  │ (第13章)        │ │ ├─ power        │ │ ├─ ISL          │ │ ├─ Grid        │ │
│  │                 │ │ ├─ storage      │ │ ├─ Relay        │ │ └─ Strip       │ │
│  │  ┌───────────┐  │ │ ├─ thermal ◄────┼─┼─┼─ Network      │ │                │ │
│  │  │ STK/HPOP  │  │ │ │ (第16章集成)  │ │ │   RouterV2    │ │                │ │
│  │  │ Orekit    │  │ │ │               │ │ │   (第20章)    │ │                │ │
│  │  └───────────┘  │ │ │               │ │ │   ▲           │ │                │ │
│  │                 │ │ │               │ │ └───┼───────────┘ │                │ │
│  └─────────────────┘ │ │               │ │     │             │                │ │
│                      │ │               │ │  ┌──┴──────────┐  │                │ │
│  ┌─────────────────┐ │ │               │ │  │ Network     │  │                │ │
│  │ Failure         │ │ │               │ │  │ Router      │  │                │ │
│  │ Analyzer        │ │ │               │ │  │ Adapter     │  │                │ │
│  │ (第14章)        │ │ │               │ │  │ (新增)      │  │                │ │
│  └────────┬────────┘ │ │               │ │  └─────────────┘  │                │ │
│           │          │ │               │ └───────────────────┘                │ │
│           │          │ │               │                                     │ │
│           │          │ │  ┌────────────┴────────────┐                         │ │
│           │          │ │  │ ThermalIntegrator       │                         │ │
│           │          │ └──┤ (第16章)                │                         │ │
│           │          │    │ SunExclusionCalculator  │                         │ │
│           │          │    └─────────────────────────┘                         │ │
│           │          └────────────────────────────────────────────────────────┘ │
│           │                                                                     │
│           ▼                                                                     │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │                         ProcessingManager (第20章)                      │   │
│  │  ├─ Pareto Optimizer                                                    │   │
│  │  ├─ Cost Calculator (onboard vs downlink)                               │   │
│  │  └─ State Constraint Checker                                            │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘

                                    ▲ │ ▲
                                    │ │ │
                                    │ │ └─────────────────────┐
                                    │ │                       │
                                    │ └──────────┐            │
                                    │            │            │
                                    ▼            ▼            ▼

┌─────────────────────────────────────────────────────────────────────────────────┐
│                                   数据持久层                                      │
│                                                                                  │
│  ┌─────────────────────────┐  ┌─────────────────────────┐  ┌─────────────────┐  │
│  │ 关系型存储               │  │ 时序存储                 │  │ 配置管理         │  │
│  │ (MySQL/SQLite)          │  │ (Parquet/HDF5)          │  │ (YAML/JSON)     │  │
│  │                         │  │                         │  │                 │  │
│  │ ├─ scenarios            │  │ ├─ satellite_states     │  │ ├─ 场景配置     │  │
│  │ ├─ experiments          │  │ ├─ thermal_history      │  │ ├─ 算法参数     │  │
│  │ ├─ satellites           │  │ ├─ power_profiles       │  │ └─ 系统配置     │  │
│  │ ├─ tasks                │  │ └─ visibility_windows   │  │                 │  │
│  │ ├─ runs                 │  │                         │  │                 │  │
│  │ ├─ metrics              │  │                         │  │                 │  │
│  │ ├─ constraint_violations│  │                         │  │                 │  │
│  │ ├─ failure_reasons      │  │                         │  │                 │  │
│  │ ├─ onboard_processing   │  │                         │  │                 │  │
│  │ └─ processing_decisions │  │                         │  │                 │  │
│  │    (第20章新增)         │  │                         │  │                 │  │
│  └─────────────────────────┘  └─────────────────────────┘  └─────────────────┘  │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 21.3 完整失败原因类型汇总（26种）

```python
# 第14章 + 第16章 + 第19章 + 第20章 整合

class TaskFailureReason(Enum):
    """任务失败原因枚举（完整版）"""

    # ═══════════════════════════════════════════════════════
    # 第14章：基础失败原因
    # ═══════════════════════════════════════════════════════

    # 资源约束类
    POWER_CONSTRAINT = auto()           # 电量约束
    STORAGE_CONSTRAINT = auto()         # 存储约束
    TIME_WINDOW_EXPIRED = auto()        # 时间窗口过期

    # 冲突类
    SATELLITE_CONFLICT = auto()         # 卫星冲突
    GROUND_STATION_CONFLICT = auto()    # 地面站冲突
    PRIORITY_PREEMPTED = auto()         # 被高优先级任务抢占

    # 外部条件类
    WEATHER_UNSUITABLE = auto()         # 天气不适宜
    TARGET_NOT_VISIBLE = auto()         # 目标不可见
    COMMUNICATION_FAILURE = auto()      # 通信故障

    # 系统类
    SCHEDULER_ERROR = auto()            # 调度器内部错误
    TIMEOUT = auto()                    # 超时

    # ═══════════════════════════════════════════════════════
    # 第16章：物理约束失败原因
    # ═══════════════════════════════════════════════════════

    THERMAL_CONSTRAINT = auto()         # 热控约束
    SUN_EXCLUSION_VIOLATION = auto()    # 太阳规避角违规
    STORAGE_FRAGMENTATION = auto()      # 存储碎片化
    STORAGE_OVERFLOW_RISK = auto()      # 存储溢出风险

    # ═══════════════════════════════════════════════════════
    # 第19章：业务闭环失败原因
    # ═══════════════════════════════════════════════════════

    GUARD_TIME_VIOLATION = auto()       # 保护时间违规
    COMMAND_SEQUENCE_ERROR = auto()     # 指令序列错误
    DYNAMIC_RESCHEDULE_FAILED = auto()  # 动态重调度失败
    TELEMETRY_ANOMALY = auto()          # 遥测异常
    PLAN_INFEASIBLE = auto()            # 计划不可行

    # ═══════════════════════════════════════════════════════
    # 第20章：边缘计算失败原因
    # ═══════════════════════════════════════════════════════

    AI_PROCESSOR_UNAVAILABLE = auto()         # AI处理器不可用
    INSUFFICIENT_COMPUTE = auto()             # 算力不足
    PROCESSING_TIMEOUT = auto()               # 处理超时
    MODEL_INFERENCE_FAILED = auto()           # 模型推理失败
    COMPRESSION_QUALITY_UNACCEPTABLE = auto() # 压缩质量不可接受
    ONBOARD_PROCESSING_CANCELLED = auto()     # 在轨处理被取消
```

### 21.4 数据库存储策略映射

| 数据类型 | 存储方式 | 具体位置 | 说明 |
|----------|----------|----------|------|
| 场景/实验元数据 | 关系型 | `scenarios`, `experiments` | 实验配置 |
| 任务调度结果 | 关系型 | `tasks`, `runs` | 调度计划 |
| 约束违反记录 | 关系型 | `constraint_violations` | 失败追踪（第14章） |
| 在轨处理任务 | 关系型 | `onboard_processing_tasks` | 第20章新增 |
| 处理决策记录 | 关系型 | `processing_decisions` | 帕累托分析 |
| 卫星状态快照 | 时序存储 | `satellite_states.parquet` | 第18章 |
| 热控历史 | 时序存储 | `thermal_history.parquet` | 第16章 |
| 电量曲线 | 时序存储 | `power_profiles.parquet` | 第12章 |
| 可见性窗口 | 时序存储 | `visibility_windows.parquet` | 第13章 |

### 21.5 关键接口契约

#### NetworkRouterAdapter 接口

```python
class NetworkRouterAdapter:
    """
    网络路由适配器

    统一 NetworkRouter(第17章) 和 NetworkRouterV2(第20章) 的接口
    """

    def __init__(self,
                 router_v1: Optional[NetworkRouter] = None,
                 router_v2: Optional[NetworkRouterV2] = None):
        self.router_v1 = router_v1
        self.router_v2 = router_v2

    def route(self,
              data_payload: DataPayload,
              satellite_state: SatelliteResourceState,
              network_state: NetworkState) -> RoutingDecision:
        """
        统一路由接口

        根据数据类型自动选择路由器：
        - 原始数据 -> router_v1
        - 压缩数据 -> router_v2
        """
        if data_payload.is_compressed:
            if not self.router_v2:
                raise RuntimeError("NetworkRouterV2 required for compressed data")
            return self.router_v2.route_compressed_data(...)
        else:
            if not self.router_v1:
                raise RuntimeError("NetworkRouter required for raw data")
            return self.router_v1.find_best_route(...)
```

#### StorageModel 策略接口

```python
from abc import ABC, abstractmethod

class StorageModelStrategy(ABC):
    """存储模型策略基类"""

    @abstractmethod
    def allocate(self, size_gb: float, duration_hours: float) -> bool:
        """分配存储空间"""
        pass

    @abstractmethod
    def get_fragmentation_ratio(self) -> float:
        """获取碎片率"""
        pass

class SimpleStorageModel(StorageModelStrategy):
    """简化存储模型（第12章）- 用于基础调度"""
    # ... 实现 ...

class FragmentedStorageModel(StorageModelStrategy):
    """碎片化存储模型（第16章）- 用于精细仿真"""
    # ... 实现 ...
```

---

**文档版本**: 2.1 (已更新)
**更新日期**: 2026-02-19
**更新内容**:
- 新增数据持久化与存储设计（第10章）
- 新增目标分解模块设计（第11章）
- 新增连续状态演化跟踪器设计（第12章）
- 新增性能优化：时间窗口缓存设计（第13章）
- 新增失败原因追踪设计（第14章）
- 新增强化学习/AI Agent接口设计（第15章）
- 新增深度物理与硬件约束设计（第16章）
- 新增通信链路与网络拓扑设计（第17章）
- 新增混合存储架构设计（第18章）
- 新增业务闭环与动态调度设计（第19章）
- 新增星载边缘计算设计（第20章）
- 新增架构衔接修复与核心流程图（第21章）

---

## 22. 地面站天线调度、数据加密与渐进式优化

### 22.1 地面站天线状态机（Antenna State Machine）

```python
# core/resources/antenna_state_machine.py

from enum import Enum, auto
from dataclasses import dataclass
from typing import Optional, List, Dict
from datetime import datetime, timedelta


class AntennaState(Enum):
    """地面站天线状态"""
    IDLE = auto()              # 空闲
    ACQUIRING = auto()         # 捕获卫星（天线指向调整中）
    TRACKING = auto()          # 跟踪卫星（数据传输中）
    SWEEPING = auto()          # 扫描/切换目标
    MAINTENANCE = auto()       # 维护中
    OFFLINE = auto()           # 离线


class AntennaMode(Enum):
    """天线工作模式"""
    RX_ONLY = auto()           # 仅接收
    TX_ONLY = auto()           # 仅发射（用于指令上注）
    DUPLEX = auto()            # 全双工


@dataclass
class GroundStationAntenna:
    """地面站天线资源"""
    antenna_id: str
    station_id: str
    max_elevation_deg: float
    slew_rate_deg_per_sec: float
    max_data_rate_mbps: float
    supported_bands: List[str]  # ['X', 'S', 'Ka']
    mode: AntennaMode

    # 状态机
    current_state: AntennaState = AntennaState.IDLE
    state_entry_time: Optional[datetime] = None
    current_satellite: Optional[str] = None

    # 资源约束
    setup_time: timedelta = timedelta(seconds=30)  # 天线切换时间
    cooldown_time: timedelta = timedelta(seconds=10)  # 冷却时间


class AntennaStateMachine:
    """
    地面站天线状态机

    核心职责：
    1. 管理每个天线的状态转换
    2. 确保状态转换满足时间约束（setup/cooldown）
    3. 防止天线冲突（单天线单任务约束）
    4. 计算状态转换的能耗
    """

    # 有效状态转换规则
    VALID_TRANSITIONS = {
        AntennaState.IDLE: [AntennaState.ACQUIRING, AntennaState.MAINTENANCE, AntennaState.OFFLINE],
        AntennaState.ACQUIRING: [AntennaState.TRACKING, AntennaState.IDLE],
        AntennaState.TRACKING: [AntennaState.SWEEPING, AntennaState.IDLE],
        AntennaState.SWEEPING: [AntennaState.ACQUIRING, AntennaState.IDLE],
        AntennaState.MAINTENANCE: [AntennaState.IDLE, AntennaState.OFFLINE],
        AntennaState.OFFLINE: [AntennaState.IDLE]
    }

    def __init__(self, antennas: List[GroundStationAntenna]):
        self.antennas = {a.antenna_id: a for a in antennas}
        self.transition_history: List[Dict] = []

    def can_transition(
        self,
        antenna_id: str,
        target_state: AntennaState,
        target_satellite: Optional[str] = None
    ) -> Tuple[bool, Optional[str]]:
        """
        检查状态转换是否可行

        Returns:
            (是否可行, 失败原因)
        """
        antenna = self.antennas.get(antenna_id)
        if not antenna:
            return False, "Antenna not found"

        current = antenna.current_state

        # 检查转换规则
        if target_state not in self.VALID_TRANSITIONS.get(current, []):
            return False, f"Invalid transition: {current.name} -> {target_state.name}"

        # 检查最小持续时间
        if antenna.state_entry_time:
            elapsed = datetime.now() - antenna.state_entry_time
            if current == AntennaState.TRACKING and elapsed < timedelta(seconds=60):
                return False, "Minimum tracking duration not met"

        # 检查天线是否被占用
        if target_state in [AntennaState.ACQUIRING, AntennaState.TRACKING]:
            if antenna.current_satellite and antenna.current_satellite != target_satellite:
                return False, f"Antenna busy with satellite {antenna.current_satellite}"

        return True, None

    def transition(
        self,
        antenna_id: str,
        target_state: AntennaState,
        target_satellite: Optional[str] = None
    ) -> bool:
        """执行状态转换"""
        can_do, reason = self.can_transition(antenna_id, target_state, target_satellite)
        if not can_do:
            return False

        antenna = self.antennas[antenna_id]
        old_state = antenna.current_state

        # 执行转换
        antenna.current_state = target_state
        antenna.state_entry_time = datetime.now()

        if target_state == AntennaState.IDLE:
            antenna.current_satellite = None
        elif target_satellite:
            antenna.current_satellite = target_satellite

        # 记录历史
        self.transition_history.append({
            'antenna_id': antenna_id,
            'from_state': old_state.name,
            'to_state': target_state.name,
            'satellite': target_satellite,
            'timestamp': datetime.now()
        })

        return True


class AntennaAllocationSolver:
    """
    天线分配求解器

    解决Antenna Allocation Problem：
    - 多个卫星竞争同一天线
    - 最大化天线利用率
    - 最小化任务等待时间
    """

    def __init__(self, state_machine: AntennaStateMachine):
        self.state_machine = state_machine

    def allocate_antenna(
        self,
        satellite_id: str,
        ground_station_id: str,
        start_time: datetime,
        duration: timedelta,
        priority: int
    ) -> Optional[str]:
        """
        为卫星分配天线

        Returns:
            分配的天线ID，或None（无可用天线）
        """
        # 获取地面站的所有天线
        available_antennas = [
            a for a in self.state_machine.antennas.values()
            if a.station_id == ground_station_id
            and a.current_state in [AntennaState.IDLE, AntennaState.TRACKING]
        ]

        if not available_antennas:
            return None

        # 评分选择最佳天线
        best_antenna = None
        best_score = -float('inf')

        for antenna in available_antennas:
            score = self._score_antenna(antenna, satellite_id, start_time, duration, priority)
            if score > best_score:
                best_score = score
                best_antenna = antenna

        if best_antenna:
            # 预留天线
            self.state_machine.transition(
                best_antenna.antenna_id,
                AntennaState.ACQUIRING,
                satellite_id
            )
            return best_antenna.antenna_id

        return None

    def _score_antenna(
        self,
        antenna: GroundStationAntenna,
        satellite_id: str,
        start_time: datetime,
        duration: timedelta,
        priority: int
    ) -> float:
        """为天线评分（越高越好）"""
        score = 0.0

        # 优先空闲天线
        if antenna.current_state == AntennaState.IDLE:
            score += 100

        # 优先高带宽天线
        score += antenna.max_data_rate_mbps * 0.1

        # 优先切换时间短的
        score -= antenna.setup_time.total_seconds() * 0.5

        # 优先级加权
        score += priority * 10

        return score
```

### 22.2 数据加密动作与能耗模型

```python
# core/processing/data_encryption.py

from dataclasses import dataclass
from typing import Optional
from datetime import timedelta


@dataclass
class EncryptionSpec:
    """加密规格"""
    algorithm: str           # 'AES-256', 'SM4', 'ChaCha20'
    key_length_bits: int
    throughput_mbps: float   # 加密吞吐量
    power_consumption_w: float  # 功耗
    heat_generation_w: float    # 热量产生


# 典型加密算法规格
ENCRYPTION_SPECS = {
    'AES-256': EncryptionSpec(
        algorithm='AES-256-GCM',
        key_length_bits=256,
        throughput_mbps=500,      # 硬件加速
        power_consumption_w=15,   # 加密芯片功耗
        heat_generation_w=12      # 约80%转化为热量
    ),
    'SM4': EncryptionSpec(
        algorithm='SM4-GCM',
        key_length_bits=128,
        throughput_mbps=400,
        power_consumption_w=12,
        heat_generation_w=10
    ),
    'ChaCha20': EncryptionSpec(
        algorithm='ChaCha20-Poly1305',
        key_length_bits=256,
        throughput_mbps=600,
        power_consumption_w=18,
        heat_generation_w=14
    )
}


class DataEncryptionModel:
    """
    数据加密模型

    计算加密动作的能耗和热负载
    """

    def __init__(self, spec: EncryptionSpec):
        self.spec = spec

    def calculate_encryption_cost(
        self,
        data_size_gb: float
    ) -> Dict[str, float]:
        """
        计算加密代价

        Returns:
            {
                'duration_seconds': 加密耗时,
                'energy_wh': 能耗(Wh),
                'heat_load_wh': 热负载(Wh)
            }
        """
        # 加密时间 = 数据量 / 吞吐量
        data_size_mb = data_size_gb * 1024
        duration_seconds = (data_size_mb * 8) / self.spec.throughput_mbps

        # 能耗 = 功耗 × 时间
        energy_wh = (self.spec.power_consumption_w * duration_seconds) / 3600

        # 热负载 = 热量产生 × 时间
        heat_load_wh = (self.spec.heat_generation_w * duration_seconds) / 3600

        return {
            'duration_seconds': duration_seconds,
            'energy_wh': energy_wh,
            'heat_load_wh': heat_load_wh
        }
```

#### SOEActionType扩展

```python
# core/telecommand/soe_types.py (扩展)

class SOEActionType(Enum):
    """SOE动作类型（扩展）"""

    # 原有动作...（第19章）
    SLEW_START = auto()
    SLEW_COMPLETE = auto()
    IMAGING_START = auto()
    IMAGING_COMPLETE = auto()
    DOWNLINK_START = auto()
    DOWNLINK_COMPLETE = auto()

    # 新增：加密相关动作
    ENCRYPTION_PREPARE = auto()    # 加密准备（加载密钥）
    ENCRYPTION_START = auto()      # 开始加密
    ENCRYPTION_COMPLETE = auto()   # 加密完成

    # 新增：天线相关动作
    ANTENNA_ACQUIRING = auto()     # 天线捕获卫星
    ANTENNA_TRACKING = auto()      # 天线跟踪
    ANTENNA_RELEASE = auto()       # 天线释放
```

### 22.3 "骨架优先"实现策略

```python
# config/feature_flags.py

"""
特性开关配置

采用"骨架优先"策略：
1. Phase 1: 关闭复杂约束，跑通GA/PSO + MySQL数据流
2. Phase 2: 逐步开启高级特性
3. Phase 3: 全功能运行
"""

from dataclasses import dataclass


@dataclass
class FeatureFlags:
    """特性开关"""

    # Phase 1: 骨架功能（必须开启）
    GEOMETRY_CONSTRAINTS: bool = True      # 几何约束（可见性窗口）
    POWER_CONSTRAINTS: bool = True         # 电量约束（简化版）
    BASIC_STORAGE: bool = True             # 基础存储约束
    MYSQL_PERSISTENCE: bool = True         # MySQL数据持久化

    # Phase 2: 可选高级约束（默认关闭）
    THERMAL_CONSTRAINTS: bool = False      # 热控约束（第16章）
    STORAGE_FRAGMENTATION: bool = False    # 存储碎片化（第16章）
    EDGE_COMPUTING: bool = False           # 边缘计算（第20章）
    DYNAMIC_RESCHEDULING: bool = False     # 动态重调度（第19章）
    ENCRYPTION_OVERHEAD: bool = False      # 加密能耗（第22章）

    # Phase 3: 优化特性
    HIGH_FIDELITY_INTEGRATOR: bool = False # 高保真积分器
    MULTI_OBJECTIVE_PARETO: bool = False   # 多目标帕累托优化


# 预定义配置
SKELETON_CONFIG = FeatureFlags(
    # Phase 1 only
    THERMAL_CONSTRAINTS=False,
    STORAGE_FRAGMENTATION=False,
    EDGE_COMPUTING=False,
    DYNAMIC_RESCHEDULING=False,
    ENCRYPTION_OVERHEAD=False,
    HIGH_FIDELITY_INTEGRATOR=False,
    MULTI_OBJECTIVE_PARETO=False
)

FULL_CONFIG = FeatureFlags(
    # All features enabled
    THERMAL_CONSTRAINTS=True,
    STORAGE_FRAGMENTATION=True,
    EDGE_COMPUTING=True,
    DYNAMIC_RESCHEDULING=True,
    ENCRYPTION_OVERHEAD=True,
    HIGH_FIDELITY_INTEGRATOR=True,
    MULTI_OBJECTIVE_PARETO=True
)
```

### 22.4 性能压测脚本设计

```python
# tests/performance/benchmark_cache.py

"""
缓存性能压测脚本

目标：验证 VisibilityWindowCache 和 StateTracker
在 10万次/秒 调用下的表现
"""

import time
import psutil
import os
from typing import List, Dict, Tuple
import statistics


class CacheBenchmark:
    """缓存性能压测"""

    def __init__(self):
        self.process = psutil.Process(os.getpid())
        self.results = {}

    def benchmark_visibility_cache(
        self,
        num_satellites: int = 50,
        num_targets: int = 100,
        calls_per_second: int = 100_000,
        duration_seconds: int = 10
    ) -> Dict:
        """
        压测 VisibilityWindowCache

        Args:
            num_satellites: 卫星数量
            num_targets: 目标数量
            calls_per_second: 目标QPS
            duration_seconds: 测试持续时间
        """
        print(f"\n{'='*60}")
        print(f"VisibilityWindowCache 压测")
        print(f"配置: {num_satellites}卫星, {num_targets}目标, {calls_per_second} QPS")
        print(f"{'='*60}")

        # 初始化缓存
        from core.visibility.visibility_window_cache import VisibilityWindowCache

        cache = VisibilityWindowCache(max_size=10000)

        # 预加载数据
        self._preload_cache(cache, num_satellites, num_targets)

        # 记录初始内存
        initial_memory = self.process.memory_info().rss / 1024 / 1024  # MB
        print(f"初始内存: {initial_memory:.2f} MB")

        # 执行压测
        total_calls = calls_per_second * duration_seconds
        latencies = []

        start_time = time.perf_counter()
        calls_completed = 0

        while calls_completed < total_calls:
            batch_start = time.perf_counter()

            # 批量执行查询
            for _ in range(1000):
                sat_id = f"SAT_{calls_completed % num_satellites}"
                target_id = f"TARGET_{calls_completed % num_targets}"

                query_start = time.perf_counter()
                cache.get(sat_id, target_id)
                query_end = time.perf_counter()

                latencies.append((query_end - query_start) * 1000)  # ms
                calls_completed += 1

                if calls_completed >= total_calls:
                    break

            # 控制速率
            batch_elapsed = time.perf_counter() - batch_start
            expected_batch_time = 1000 / calls_per_second
            if batch_elapsed < expected_batch_time:
                time.sleep(expected_batch_time - batch_elapsed)

        end_time = time.perf_counter()

        # 记录最终内存
        final_memory = self.process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory

        # 计算指标
        actual_duration = end_time - start_time
        actual_qps = total_calls / actual_duration
        avg_latency = statistics.mean(latencies)
        p99_latency = sorted(latencies)[int(len(latencies) * 0.99)]
        max_latency = max(latencies)

        results = {
            'test_name': 'VisibilityWindowCache',
            'configuration': {
                'num_satellites': num_satellites,
                'num_targets': num_targets,
                'target_qps': calls_per_second,
                'duration_seconds': duration_seconds
            },
            'performance': {
                'total_calls': total_calls,
                'actual_duration_seconds': actual_duration,
                'actual_qps': actual_qps,
                'avg_latency_ms': avg_latency,
                'p99_latency_ms': p99_latency,
                'max_latency_ms': max_latency
            },
            'memory': {
                'initial_mb': initial_memory,
                'final_mb': final_memory,
                'increase_mb': memory_increase,
                'per_call_bytes': (memory_increase * 1024 * 1024) / total_calls
            }
        }

        self._print_results(results)
        return results

    def _preload_cache(self, cache, num_satellites, num_targets):
        """预加载缓存数据"""
        print("预加载缓存数据...")
        for sat_idx in range(num_satellites):
            for target_idx in range(num_targets):
                sat_id = f"SAT_{sat_idx}"
                target_id = f"TARGET_{target_idx}"
                # 模拟可见性窗口
                cache.set(sat_id, target_id, [])
        print(f"预加载完成: {num_satellites * num_targets} 条记录")

    def _print_results(self, results: Dict):
        """打印结果"""
        print(f"\n{'-'*60}")
        print(f"压测结果: {results['test_name']}")
        print(f"{'-'*60}")

        perf = results.get('performance', {})
        print(f"总调用次数: {perf.get('total_calls', 'N/A'):,}")
        print(f"实际QPS: {perf.get('actual_qps', 'N/A'):.2f}")
        print(f"平均延迟: {perf.get('avg_latency_ms', 'N/A'):.3f} ms")
        print(f"P99延迟: {perf.get('p99_latency_ms', 'N/A'):.3f} ms")
        print(f"最大延迟: {perf.get('max_latency_ms', 'N/A'):.3f} ms")

        mem = results.get('memory', {})
        print(f"内存增长: {mem.get('increase_mb', 'N/A'):.2f} MB")
        print(f"{'='*60}\n")


if __name__ == '__main__':
    benchmark = CacheBenchmark()

    # 执行压测
    cache_results = benchmark.benchmark_visibility_cache()

    # 判定是否达标
    print("\n" + "="*60)
    print("达标判定")
    print("="*60)

    cache_qps = cache_results['performance']['actual_qps']

    if cache_qps >= 100_000:
        print(f"✓ VisibilityWindowCache: {cache_qps:.0f} QPS (达标)")
    else:
        print(f"✗ VisibilityWindowCache: {cache_qps:.0f} QPS (未达标，目标: 100,000)")
```

### 22.5 插件化复杂约束

```python
# core/constraints/constraint_plugin.py

from abc import ABC, abstractmethod
from typing import Dict, Any, List
from dataclasses import dataclass


@dataclass
class ConstraintCheckResult:
    """约束检查结果"""
    feasible: bool
    violation_degree: float  # 0.0 = 满足, >0 = 违反程度
    message: str
    metadata: Dict[str, Any]


class ConstraintPlugin(ABC):
    """
    约束插件基类

    所有复杂约束（热控、存储碎片化、边缘计算等）
    都以插件形式实现，可按需加载
    """

    @property
    @abstractmethod
    def name(self) -> str:
        """插件名称"""
        pass

    @property
    @abstractmethod
    def priority(self) -> int:
        """
        插件优先级
        数值越小优先级越高（先检查）
        """
        pass

    @abstractmethod
    def initialize(self, config: Dict[str, Any]):
        """初始化插件"""
        pass

    @abstractmethod
    def check(
        self,
        task: 'Task',
        satellite_state: 'SatelliteState',
        context: Dict[str, Any]
    ) -> ConstraintCheckResult:
        """
        检查约束

        Returns:
            ConstraintCheckResult
        """
        pass


class ConstraintPluginManager:
    """约束插件管理器"""

    def __init__(self):
        self.plugins: Dict[str, ConstraintPlugin] = {}
        self.enabled_plugins: List[str] = []

    def register(self, plugin: ConstraintPlugin):
        """注册插件"""
        self.plugins[plugin.name] = plugin

    def enable(self, plugin_name: str, config: Dict[str, Any] = None):
        """启用插件"""
        if plugin_name not in self.plugins:
            raise ValueError(f"Unknown plugin: {plugin_name}")

        plugin = self.plugins[plugin_name]
        plugin.initialize(config or {})
        self.enabled_plugins.append(plugin_name)

        # 按优先级排序
        self.enabled_plugins.sort(
            key=lambda name: self.plugins[name].priority
        )

    def check_all(
        self,
        task: 'Task',
        satellite_state: 'SatelliteState',
        context: Dict[str, Any]
    ) -> List[ConstraintCheckResult]:
        """检查所有启用的约束"""
        results = []

        for plugin_name in self.enabled_plugins:
            plugin = self.plugins[plugin_name]
            result = plugin.check(task, satellite_state, context)
            results.append(result)

            # 硬约束违反时立即返回
            if not result.feasible and result.violation_degree > 1.0:
                break

        return results
```

### 22.6 低保真度代理模型

```python
# scheduler/metaheuristic/surrogate_model.py

from typing import List, Dict
import numpy as np


class FidelityLevel(Enum):
    """保真度级别"""
    LOW = auto()      # 低保真：快速估算
    MEDIUM = auto()   # 中保真：部分约束
    HIGH = auto()     # 高保真：完整约束


class SurrogateConstraintModel:
    """
    代理约束模型

    在元启发式算法不同阶段使用不同保真度的约束检查
    """

    def __init__(self, plugin_manager: ConstraintPluginManager):
        self.plugin_manager = plugin_manager

    def evaluate(
        self,
        solution: 'ScheduleSolution',
        fidelity: FidelityLevel
    ) -> Dict[str, Any]:
        """评估解的质量"""
        if fidelity == FidelityLevel.LOW:
            return self._low_fidelity_evaluate(solution)
        elif fidelity == FidelityLevel.MEDIUM:
            return self._medium_fidelity_evaluate(solution)
        else:
            return self._high_fidelity_evaluate(solution)

    def _low_fidelity_evaluate(self, solution: 'ScheduleSolution') -> Dict:
        """低保真评估 - 仅基本几何和电量平衡"""
        violations = 0
        total_energy_violation = 0.0

        for task in solution.tasks:
            estimated_energy = task.power_consumption_w * task.duration_seconds / 3600
            available_energy = task.battery_capacity_wh * 0.8

            if estimated_energy > available_energy:
                violations += 1
                total_energy_violation += estimated_energy - available_energy

        return {
            'feasible': violations == 0,
            'constraint_violations': violations,
            'total_violation': total_energy_violation,
            'objective_value': solution.total_revenue - violations * 1000,
            'computation_time_ms': 0.1
        }

    def _high_fidelity_evaluate(self, solution: 'ScheduleSolution') -> Dict:
        """高保真评估 - 完整约束检查"""
        violations = 0
        detailed_violations = []

        for task in solution.tasks:
            results = self.plugin_manager.check_all(
                task, task.satellite_state, {}
            )

            for result in results:
                if not result.feasible:
                    violations += 1
                    detailed_violations.append({
                        'task_id': task.id,
                        'constraint': result.message,
                        'degree': result.violation_degree
                    })

        return {
            'feasible': violations == 0,
            'constraint_violations': violations,
            'detailed_violations': detailed_violations,
            'objective_value': solution.total_revenue if violations == 0 else 0,
            'computation_time_ms': 50.0
        }


class AdaptiveFidelityScheduler:
    """自适应保真度调度器"""

    def __init__(self, base_scheduler: BaseScheduler, surrogate: SurrogateConstraintModel):
        self.base_scheduler = base_scheduler
        self.surrogate = surrogate

        # 保真度切换阈值
        self.fidelity_schedule = {
            (0, 0.5): FidelityLevel.LOW,
            (0.5, 0.8): FidelityLevel.MEDIUM,
            (0.8, 1.0): FidelityLevel.HIGH
        }

    def schedule_with_adaptive_fidelity(
        self,
        tasks: List[Task],
        max_iterations: int = 1000
    ) -> ScheduleResult:
        """使用自适应保真度进行调度"""
        best_solution = None
        best_objective = -float('inf')

        for iteration in range(max_iterations):
            progress = iteration / max_iterations
            fidelity = self._get_fidelity_for_progress(progress)

            candidate = self.base_scheduler.generate_candidate(tasks)
            evaluation = self.surrogate.evaluate(candidate, fidelity)

            if evaluation['objective_value'] > best_objective:
                best_objective = evaluation['objective_value']
                best_solution = candidate

        return best_solution

    def _get_fidelity_for_progress(self, progress: float) -> FidelityLevel:
        """根据进度确定保真度"""
        for (start, end), fidelity in self.fidelity_schedule.items():
            if start <= progress < end:
                return fidelity
        return FidelityLevel.HIGH
```

### 22.7 整体架构衔接检查

#### 衔接一致性检查表

| 检查项 | 涉及章节 | 状态 | 说明 |
|--------|----------|------|------|
| 天线状态机 → SOE生成 | 第22章 → 第19章 | ✅ | 天线动作已加入SOEActionType |
| 加密模型 → 状态跟踪器 | 第22章 → 第12章 | ✅ | DataEncryptionModel可注入StateTracker |
| 特性开关 → 所有模块 | 第22章 → 全部 | ✅ | FeatureFlags统一控制 |
| 约束插件 → 元启发式 | 第22章 → 第4章 | ✅ | 通过SurrogateConstraintModel衔接 |
| 压测脚本 → 缓存模块 | 第22章 → 第13章 | ✅ | 独立测试脚本，无侵入 |
| 低保真 → 高保真切换 | 第22章内部 | ✅ | AdaptiveFidelityScheduler管理 |

#### 潜在的剩余问题

| 问题 | 风险等级 | 建议处理 |
|------|----------|----------|
| MySQL连接池在10万QPS下可能成为瓶颈 | 中 | 使用连接池 + 批量写入 |
| 多插件同时启用时性能下降 | 中 | 启用异步约束检查 |
| 低保真模型与高保真结果差异大 | 低 | 校准低保真参数 |

---

**文档版本**: 2.2 (已更新)
**更新日期**: 2026-02-19
**更新内容**:
- 新增地面站天线调度、数据加密与渐进式优化设计（第22章）
